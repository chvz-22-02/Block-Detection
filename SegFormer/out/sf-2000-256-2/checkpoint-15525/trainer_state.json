{
  "best_global_step": 8000,
  "best_metric": 0.7640625770638384,
  "best_model_checkpoint": "out/sf-2000-256-2\\checkpoint-8000",
  "epoch": 25.0,
  "eval_steps": 2000,
  "global_step": 15525,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1610305958132045,
      "grad_norm": 6.765344619750977,
      "learning_rate": 4.9681159420289857e-05,
      "loss": 0.5294,
      "step": 100
    },
    {
      "epoch": 0.322061191626409,
      "grad_norm": 3.263355255126953,
      "learning_rate": 4.935909822866345e-05,
      "loss": 0.4648,
      "step": 200
    },
    {
      "epoch": 0.4830917874396135,
      "grad_norm": 2.701138973236084,
      "learning_rate": 4.903703703703704e-05,
      "loss": 0.4733,
      "step": 300
    },
    {
      "epoch": 0.644122383252818,
      "grad_norm": 2.2331383228302,
      "learning_rate": 4.871497584541063e-05,
      "loss": 0.4686,
      "step": 400
    },
    {
      "epoch": 0.8051529790660226,
      "grad_norm": 6.8069562911987305,
      "learning_rate": 4.8392914653784224e-05,
      "loss": 0.4466,
      "step": 500
    },
    {
      "epoch": 0.966183574879227,
      "grad_norm": 5.882833480834961,
      "learning_rate": 4.807085346215781e-05,
      "loss": 0.4483,
      "step": 600
    },
    {
      "epoch": 1.1272141706924317,
      "grad_norm": 3.022916793823242,
      "learning_rate": 4.77487922705314e-05,
      "loss": 0.4235,
      "step": 700
    },
    {
      "epoch": 1.288244766505636,
      "grad_norm": 4.524843215942383,
      "learning_rate": 4.7426731078905e-05,
      "loss": 0.4464,
      "step": 800
    },
    {
      "epoch": 1.4492753623188406,
      "grad_norm": 11.41234302520752,
      "learning_rate": 4.7104669887278584e-05,
      "loss": 0.417,
      "step": 900
    },
    {
      "epoch": 1.6103059581320451,
      "grad_norm": 9.491375923156738,
      "learning_rate": 4.678260869565218e-05,
      "loss": 0.4062,
      "step": 1000
    },
    {
      "epoch": 1.7713365539452495,
      "grad_norm": 8.194260597229004,
      "learning_rate": 4.646054750402577e-05,
      "loss": 0.4043,
      "step": 1100
    },
    {
      "epoch": 1.9323671497584543,
      "grad_norm": 0.7780500650405884,
      "learning_rate": 4.613848631239936e-05,
      "loss": 0.4219,
      "step": 1200
    },
    {
      "epoch": 2.0933977455716586,
      "grad_norm": 3.902200937271118,
      "learning_rate": 4.581642512077295e-05,
      "loss": 0.4056,
      "step": 1300
    },
    {
      "epoch": 2.2544283413848634,
      "grad_norm": 7.609396457672119,
      "learning_rate": 4.549436392914654e-05,
      "loss": 0.3819,
      "step": 1400
    },
    {
      "epoch": 2.4154589371980677,
      "grad_norm": 4.38031005859375,
      "learning_rate": 4.517230273752013e-05,
      "loss": 0.3716,
      "step": 1500
    },
    {
      "epoch": 2.576489533011272,
      "grad_norm": 1.0388027429580688,
      "learning_rate": 4.4850241545893726e-05,
      "loss": 0.3633,
      "step": 1600
    },
    {
      "epoch": 2.7375201288244764,
      "grad_norm": 7.15199613571167,
      "learning_rate": 4.452818035426731e-05,
      "loss": 0.3751,
      "step": 1700
    },
    {
      "epoch": 2.898550724637681,
      "grad_norm": 2.512153387069702,
      "learning_rate": 4.42061191626409e-05,
      "loss": 0.3893,
      "step": 1800
    },
    {
      "epoch": 3.0595813204508855,
      "grad_norm": 8.147321701049805,
      "learning_rate": 4.38840579710145e-05,
      "loss": 0.3835,
      "step": 1900
    },
    {
      "epoch": 3.2206119162640903,
      "grad_norm": 1.9808119535446167,
      "learning_rate": 4.3561996779388086e-05,
      "loss": 0.3476,
      "step": 2000
    },
    {
      "epoch": 3.2206119162640903,
      "eval_f1_macro": 0.8598253310784434,
      "eval_iou_Block": 0.7159205771178072,
      "eval_iou_unlabeled": 0.7844551275382586,
      "eval_loss": 0.34712332487106323,
      "eval_macro_precision": 0.8665458518869831,
      "eval_macro_recall": 0.8532082504154999,
      "eval_mean_accuracy": 0.8532082504154999,
      "eval_mean_iou": 0.750187852328033,
      "eval_overall_accuracy": 0.8603263686757762,
      "eval_precision_Block": 0.895615131580521,
      "eval_precision_unlabeled": 0.8374765721934453,
      "eval_recall_Block": 0.7810962500053799,
      "eval_recall_unlabeled": 0.92532025082562,
      "eval_runtime": 342.8754,
      "eval_samples_per_second": 2.249,
      "eval_steps_per_second": 0.563,
      "step": 2000
    },
    {
      "epoch": 3.3816425120772946,
      "grad_norm": 1.8053356409072876,
      "learning_rate": 4.323993558776168e-05,
      "loss": 0.3633,
      "step": 2100
    },
    {
      "epoch": 3.542673107890499,
      "grad_norm": 4.390853404998779,
      "learning_rate": 4.2917874396135266e-05,
      "loss": 0.3636,
      "step": 2200
    },
    {
      "epoch": 3.7037037037037037,
      "grad_norm": 5.112001419067383,
      "learning_rate": 4.259581320450886e-05,
      "loss": 0.3561,
      "step": 2300
    },
    {
      "epoch": 3.864734299516908,
      "grad_norm": 27.492496490478516,
      "learning_rate": 4.227375201288245e-05,
      "loss": 0.3503,
      "step": 2400
    },
    {
      "epoch": 4.025764895330113,
      "grad_norm": 2.2126665115356445,
      "learning_rate": 4.195169082125604e-05,
      "loss": 0.3564,
      "step": 2500
    },
    {
      "epoch": 4.186795491143317,
      "grad_norm": 9.064826965332031,
      "learning_rate": 4.162962962962963e-05,
      "loss": 0.3619,
      "step": 2600
    },
    {
      "epoch": 4.3478260869565215,
      "grad_norm": 11.232131958007812,
      "learning_rate": 4.130756843800323e-05,
      "loss": 0.3349,
      "step": 2700
    },
    {
      "epoch": 4.508856682769727,
      "grad_norm": 0.8966064453125,
      "learning_rate": 4.0985507246376814e-05,
      "loss": 0.2981,
      "step": 2800
    },
    {
      "epoch": 4.669887278582931,
      "grad_norm": 3.573532819747925,
      "learning_rate": 4.06634460547504e-05,
      "loss": 0.317,
      "step": 2900
    },
    {
      "epoch": 4.830917874396135,
      "grad_norm": 2.6440422534942627,
      "learning_rate": 4.0341384863123994e-05,
      "loss": 0.3348,
      "step": 3000
    },
    {
      "epoch": 4.99194847020934,
      "grad_norm": 6.87618350982666,
      "learning_rate": 4.001932367149759e-05,
      "loss": 0.3626,
      "step": 3100
    },
    {
      "epoch": 5.152979066022544,
      "grad_norm": 2.3543269634246826,
      "learning_rate": 3.969726247987118e-05,
      "loss": 0.311,
      "step": 3200
    },
    {
      "epoch": 5.314009661835748,
      "grad_norm": 5.514095783233643,
      "learning_rate": 3.937520128824477e-05,
      "loss": 0.3192,
      "step": 3300
    },
    {
      "epoch": 5.475040257648954,
      "grad_norm": 3.4144067764282227,
      "learning_rate": 3.9053140096618355e-05,
      "loss": 0.3009,
      "step": 3400
    },
    {
      "epoch": 5.636070853462158,
      "grad_norm": 2.4100544452667236,
      "learning_rate": 3.8731078904991955e-05,
      "loss": 0.3593,
      "step": 3500
    },
    {
      "epoch": 5.797101449275362,
      "grad_norm": 5.0794501304626465,
      "learning_rate": 3.840901771336554e-05,
      "loss": 0.3127,
      "step": 3600
    },
    {
      "epoch": 5.958132045088567,
      "grad_norm": 2.6059927940368652,
      "learning_rate": 3.808695652173913e-05,
      "loss": 0.3059,
      "step": 3700
    },
    {
      "epoch": 6.119162640901771,
      "grad_norm": 12.363998413085938,
      "learning_rate": 3.776489533011272e-05,
      "loss": 0.2927,
      "step": 3800
    },
    {
      "epoch": 6.280193236714976,
      "grad_norm": 3.5183284282684326,
      "learning_rate": 3.7442834138486315e-05,
      "loss": 0.2985,
      "step": 3900
    },
    {
      "epoch": 6.4412238325281805,
      "grad_norm": 9.040587425231934,
      "learning_rate": 3.71207729468599e-05,
      "loss": 0.321,
      "step": 4000
    },
    {
      "epoch": 6.4412238325281805,
      "eval_f1_macro": 0.8661614708782537,
      "eval_iou_Block": 0.7373019268878391,
      "eval_iou_unlabeled": 0.7894282599623356,
      "eval_loss": 0.34177693724632263,
      "eval_macro_precision": 0.8685829416603598,
      "eval_macro_recall": 0.863753463911251,
      "eval_mean_accuracy": 0.863753463911251,
      "eval_mean_iou": 0.7633650934250873,
      "eval_overall_accuracy": 0.8676483065237794,
      "eval_precision_Block": 0.8747837841978907,
      "eval_precision_unlabeled": 0.8623820991228288,
      "eval_recall_Block": 0.8242957193498239,
      "eval_recall_unlabeled": 0.9032112084726779,
      "eval_runtime": 16.2896,
      "eval_samples_per_second": 47.331,
      "eval_steps_per_second": 11.848,
      "step": 4000
    },
    {
      "epoch": 6.602254428341385,
      "grad_norm": 1.6660524606704712,
      "learning_rate": 3.6798711755233496e-05,
      "loss": 0.2943,
      "step": 4100
    },
    {
      "epoch": 6.763285024154589,
      "grad_norm": 0.44870948791503906,
      "learning_rate": 3.647665056360708e-05,
      "loss": 0.2972,
      "step": 4200
    },
    {
      "epoch": 6.9243156199677935,
      "grad_norm": 9.836709976196289,
      "learning_rate": 3.615458937198068e-05,
      "loss": 0.2978,
      "step": 4300
    },
    {
      "epoch": 7.085346215780999,
      "grad_norm": 17.848798751831055,
      "learning_rate": 3.583252818035427e-05,
      "loss": 0.2837,
      "step": 4400
    },
    {
      "epoch": 7.246376811594203,
      "grad_norm": 3.054556131362915,
      "learning_rate": 3.5510466988727856e-05,
      "loss": 0.2738,
      "step": 4500
    },
    {
      "epoch": 7.407407407407407,
      "grad_norm": 7.981909275054932,
      "learning_rate": 3.5188405797101457e-05,
      "loss": 0.2849,
      "step": 4600
    },
    {
      "epoch": 7.568438003220612,
      "grad_norm": 4.1853203773498535,
      "learning_rate": 3.486634460547504e-05,
      "loss": 0.2986,
      "step": 4700
    },
    {
      "epoch": 7.729468599033816,
      "grad_norm": 7.659639358520508,
      "learning_rate": 3.454428341384863e-05,
      "loss": 0.2634,
      "step": 4800
    },
    {
      "epoch": 7.8904991948470204,
      "grad_norm": 1.0658667087554932,
      "learning_rate": 3.4222222222222224e-05,
      "loss": 0.2537,
      "step": 4900
    },
    {
      "epoch": 8.051529790660226,
      "grad_norm": 5.030946731567383,
      "learning_rate": 3.390016103059582e-05,
      "loss": 0.2633,
      "step": 5000
    },
    {
      "epoch": 8.21256038647343,
      "grad_norm": 0.6123162508010864,
      "learning_rate": 3.3578099838969404e-05,
      "loss": 0.2563,
      "step": 5100
    },
    {
      "epoch": 8.373590982286634,
      "grad_norm": 2.2556910514831543,
      "learning_rate": 3.3256038647343e-05,
      "loss": 0.2818,
      "step": 5200
    },
    {
      "epoch": 8.53462157809984,
      "grad_norm": 24.553028106689453,
      "learning_rate": 3.2933977455716584e-05,
      "loss": 0.2905,
      "step": 5300
    },
    {
      "epoch": 8.695652173913043,
      "grad_norm": 10.632304191589355,
      "learning_rate": 3.261191626409018e-05,
      "loss": 0.2516,
      "step": 5400
    },
    {
      "epoch": 8.856682769726248,
      "grad_norm": 3.3997974395751953,
      "learning_rate": 3.228985507246377e-05,
      "loss": 0.2722,
      "step": 5500
    },
    {
      "epoch": 9.017713365539452,
      "grad_norm": 2.947601556777954,
      "learning_rate": 3.196779388083736e-05,
      "loss": 0.2435,
      "step": 5600
    },
    {
      "epoch": 9.178743961352657,
      "grad_norm": 3.2819974422454834,
      "learning_rate": 3.164573268921095e-05,
      "loss": 0.2432,
      "step": 5700
    },
    {
      "epoch": 9.339774557165862,
      "grad_norm": 9.784402847290039,
      "learning_rate": 3.1323671497584545e-05,
      "loss": 0.2471,
      "step": 5800
    },
    {
      "epoch": 9.500805152979066,
      "grad_norm": 3.6208062171936035,
      "learning_rate": 3.100161030595813e-05,
      "loss": 0.2362,
      "step": 5900
    },
    {
      "epoch": 9.66183574879227,
      "grad_norm": 1.2730066776275635,
      "learning_rate": 3.0679549114331725e-05,
      "loss": 0.2709,
      "step": 6000
    },
    {
      "epoch": 9.66183574879227,
      "eval_f1_macro": 0.8652558996565547,
      "eval_iou_Block": 0.7341943039978763,
      "eval_iou_unlabeled": 0.7889407713022545,
      "eval_loss": 0.3984738886356354,
      "eval_macro_precision": 0.8683058964060628,
      "eval_macro_recall": 0.8622272546432952,
      "eval_mean_accuracy": 0.8622272546432952,
      "eval_mean_iou": 0.7615675376500655,
      "eval_overall_accuracy": 0.8666693889058826,
      "eval_precision_Block": 0.8784381420762203,
      "eval_precision_unlabeled": 0.8581736507359052,
      "eval_recall_Block": 0.8172250256759609,
      "eval_recall_unlabeled": 0.9072294836106295,
      "eval_runtime": 16.4573,
      "eval_samples_per_second": 46.849,
      "eval_steps_per_second": 11.727,
      "step": 6000
    },
    {
      "epoch": 9.822866344605474,
      "grad_norm": 3.32318377494812,
      "learning_rate": 3.0357487922705312e-05,
      "loss": 0.2399,
      "step": 6100
    },
    {
      "epoch": 9.98389694041868,
      "grad_norm": 4.188268184661865,
      "learning_rate": 3.003542673107891e-05,
      "loss": 0.2463,
      "step": 6200
    },
    {
      "epoch": 10.144927536231885,
      "grad_norm": 9.757486343383789,
      "learning_rate": 2.97133655394525e-05,
      "loss": 0.2172,
      "step": 6300
    },
    {
      "epoch": 10.305958132045088,
      "grad_norm": 1.1260427236557007,
      "learning_rate": 2.939130434782609e-05,
      "loss": 0.2401,
      "step": 6400
    },
    {
      "epoch": 10.466988727858293,
      "grad_norm": 17.343217849731445,
      "learning_rate": 2.9069243156199676e-05,
      "loss": 0.2273,
      "step": 6500
    },
    {
      "epoch": 10.628019323671497,
      "grad_norm": 5.865230083465576,
      "learning_rate": 2.8747181964573273e-05,
      "loss": 0.247,
      "step": 6600
    },
    {
      "epoch": 10.789049919484702,
      "grad_norm": 4.093195915222168,
      "learning_rate": 2.8425120772946863e-05,
      "loss": 0.2615,
      "step": 6700
    },
    {
      "epoch": 10.950080515297907,
      "grad_norm": 9.474352836608887,
      "learning_rate": 2.810305958132045e-05,
      "loss": 0.2185,
      "step": 6800
    },
    {
      "epoch": 11.11111111111111,
      "grad_norm": 3.944873094558716,
      "learning_rate": 2.778099838969404e-05,
      "loss": 0.2218,
      "step": 6900
    },
    {
      "epoch": 11.272141706924316,
      "grad_norm": 3.7949583530426025,
      "learning_rate": 2.7458937198067637e-05,
      "loss": 0.2,
      "step": 7000
    },
    {
      "epoch": 11.43317230273752,
      "grad_norm": 1.7830946445465088,
      "learning_rate": 2.7136876006441227e-05,
      "loss": 0.2336,
      "step": 7100
    },
    {
      "epoch": 11.594202898550725,
      "grad_norm": 2.7507107257843018,
      "learning_rate": 2.6814814814814814e-05,
      "loss": 0.2106,
      "step": 7200
    },
    {
      "epoch": 11.75523349436393,
      "grad_norm": 11.422065734863281,
      "learning_rate": 2.6492753623188404e-05,
      "loss": 0.2319,
      "step": 7300
    },
    {
      "epoch": 11.916264090177133,
      "grad_norm": 3.535789728164673,
      "learning_rate": 2.6170692431562e-05,
      "loss": 0.225,
      "step": 7400
    },
    {
      "epoch": 12.077294685990339,
      "grad_norm": 0.5218674540519714,
      "learning_rate": 2.5848631239935587e-05,
      "loss": 0.2121,
      "step": 7500
    },
    {
      "epoch": 12.238325281803542,
      "grad_norm": 60.12327194213867,
      "learning_rate": 2.5526570048309177e-05,
      "loss": 0.2273,
      "step": 7600
    },
    {
      "epoch": 12.399355877616747,
      "grad_norm": 1.129850149154663,
      "learning_rate": 2.5204508856682774e-05,
      "loss": 0.2162,
      "step": 7700
    },
    {
      "epoch": 12.560386473429952,
      "grad_norm": 6.969630241394043,
      "learning_rate": 2.4882447665056365e-05,
      "loss": 0.2239,
      "step": 7800
    },
    {
      "epoch": 12.721417069243156,
      "grad_norm": 14.709260940551758,
      "learning_rate": 2.456038647342995e-05,
      "loss": 0.2034,
      "step": 7900
    },
    {
      "epoch": 12.882447665056361,
      "grad_norm": 2.316739797592163,
      "learning_rate": 2.4238325281803545e-05,
      "loss": 0.2128,
      "step": 8000
    },
    {
      "epoch": 12.882447665056361,
      "eval_f1_macro": 0.8661634308223598,
      "eval_iou_Block": 0.7449587615660328,
      "eval_iou_unlabeled": 0.783166392561644,
      "eval_loss": 0.44056564569473267,
      "eval_macro_precision": 0.8656901538276875,
      "eval_macro_recall": 0.8666372255867448,
      "eval_mean_accuracy": 0.8666372255867448,
      "eval_mean_iou": 0.7640625770638384,
      "eval_overall_accuracy": 0.8672466352292072,
      "eval_precision_Block": 0.847319934113883,
      "eval_precision_unlabeled": 0.8840603735414921,
      "eval_recall_Block": 0.8604634382485346,
      "eval_recall_unlabeled": 0.8728110129249551,
      "eval_runtime": 16.3331,
      "eval_samples_per_second": 47.205,
      "eval_steps_per_second": 11.816,
      "step": 8000
    },
    {
      "epoch": 13.043478260869565,
      "grad_norm": 1.2257254123687744,
      "learning_rate": 2.3916264090177135e-05,
      "loss": 0.2355,
      "step": 8100
    },
    {
      "epoch": 13.20450885668277,
      "grad_norm": 3.5564510822296143,
      "learning_rate": 2.359420289855073e-05,
      "loss": 0.1751,
      "step": 8200
    },
    {
      "epoch": 13.365539452495975,
      "grad_norm": 2.1455535888671875,
      "learning_rate": 2.3272141706924315e-05,
      "loss": 0.2274,
      "step": 8300
    },
    {
      "epoch": 13.526570048309178,
      "grad_norm": 0.7668874859809875,
      "learning_rate": 2.295008051529791e-05,
      "loss": 0.192,
      "step": 8400
    },
    {
      "epoch": 13.687600644122384,
      "grad_norm": 2.3168962001800537,
      "learning_rate": 2.26280193236715e-05,
      "loss": 0.2093,
      "step": 8500
    },
    {
      "epoch": 13.848631239935587,
      "grad_norm": 9.567148208618164,
      "learning_rate": 2.230595813204509e-05,
      "loss": 0.2062,
      "step": 8600
    },
    {
      "epoch": 14.009661835748792,
      "grad_norm": 5.983890533447266,
      "learning_rate": 2.198389694041868e-05,
      "loss": 0.2286,
      "step": 8700
    },
    {
      "epoch": 14.170692431561998,
      "grad_norm": 1.8109915256500244,
      "learning_rate": 2.1661835748792273e-05,
      "loss": 0.195,
      "step": 8800
    },
    {
      "epoch": 14.331723027375201,
      "grad_norm": 1.4390097856521606,
      "learning_rate": 2.1339774557165863e-05,
      "loss": 0.2105,
      "step": 8900
    },
    {
      "epoch": 14.492753623188406,
      "grad_norm": 2.9531710147857666,
      "learning_rate": 2.1017713365539453e-05,
      "loss": 0.1934,
      "step": 9000
    },
    {
      "epoch": 14.65378421900161,
      "grad_norm": 1.2014724016189575,
      "learning_rate": 2.0695652173913043e-05,
      "loss": 0.1968,
      "step": 9100
    },
    {
      "epoch": 14.814814814814815,
      "grad_norm": 3.7388992309570312,
      "learning_rate": 2.0373590982286637e-05,
      "loss": 0.1931,
      "step": 9200
    },
    {
      "epoch": 14.97584541062802,
      "grad_norm": 1.6588530540466309,
      "learning_rate": 2.0051529790660227e-05,
      "loss": 0.1969,
      "step": 9300
    },
    {
      "epoch": 15.136876006441224,
      "grad_norm": 72.68709564208984,
      "learning_rate": 1.9729468599033817e-05,
      "loss": 0.1645,
      "step": 9400
    },
    {
      "epoch": 15.297906602254429,
      "grad_norm": 0.5647430419921875,
      "learning_rate": 1.9407407407407407e-05,
      "loss": 0.1778,
      "step": 9500
    },
    {
      "epoch": 15.458937198067632,
      "grad_norm": 4.612217903137207,
      "learning_rate": 1.9085346215781e-05,
      "loss": 0.199,
      "step": 9600
    },
    {
      "epoch": 15.619967793880837,
      "grad_norm": 8.633453369140625,
      "learning_rate": 1.876328502415459e-05,
      "loss": 0.1931,
      "step": 9700
    },
    {
      "epoch": 15.780998389694043,
      "grad_norm": 1.6186892986297607,
      "learning_rate": 1.844122383252818e-05,
      "loss": 0.1848,
      "step": 9800
    },
    {
      "epoch": 15.942028985507246,
      "grad_norm": 0.8379005789756775,
      "learning_rate": 1.811916264090177e-05,
      "loss": 0.18,
      "step": 9900
    },
    {
      "epoch": 16.10305958132045,
      "grad_norm": 19.516263961791992,
      "learning_rate": 1.7797101449275364e-05,
      "loss": 0.1865,
      "step": 10000
    },
    {
      "epoch": 16.10305958132045,
      "eval_f1_macro": 0.8616597600330462,
      "eval_iou_Block": 0.7382834114666376,
      "eval_iou_unlabeled": 0.775660634303163,
      "eval_loss": 0.49237099289894104,
      "eval_macro_precision": 0.8609433749961861,
      "eval_macro_recall": 0.862377338261838,
      "eval_mean_accuracy": 0.862377338261838,
      "eval_mean_iou": 0.7569720228849003,
      "eval_overall_accuracy": 0.8626082899041677,
      "eval_precision_Block": 0.8390996572339243,
      "eval_precision_unlabeled": 0.8827870927584479,
      "eval_recall_Block": 0.8600376208930869,
      "eval_recall_unlabeled": 0.8647170556305892,
      "eval_runtime": 16.9668,
      "eval_samples_per_second": 45.442,
      "eval_steps_per_second": 11.375,
      "step": 10000
    },
    {
      "epoch": 16.264090177133657,
      "grad_norm": 1.147159457206726,
      "learning_rate": 1.7475040257648955e-05,
      "loss": 0.17,
      "step": 10100
    },
    {
      "epoch": 16.42512077294686,
      "grad_norm": 5.423007488250732,
      "learning_rate": 1.7152979066022545e-05,
      "loss": 0.1813,
      "step": 10200
    },
    {
      "epoch": 16.586151368760063,
      "grad_norm": 3.6297054290771484,
      "learning_rate": 1.6830917874396135e-05,
      "loss": 0.1989,
      "step": 10300
    },
    {
      "epoch": 16.74718196457327,
      "grad_norm": 1.6225868463516235,
      "learning_rate": 1.6508856682769728e-05,
      "loss": 0.2241,
      "step": 10400
    },
    {
      "epoch": 16.908212560386474,
      "grad_norm": 1.698844313621521,
      "learning_rate": 1.6186795491143315e-05,
      "loss": 0.1699,
      "step": 10500
    },
    {
      "epoch": 17.06924315619968,
      "grad_norm": 2.9160492420196533,
      "learning_rate": 1.586473429951691e-05,
      "loss": 0.1966,
      "step": 10600
    },
    {
      "epoch": 17.23027375201288,
      "grad_norm": 3.380084753036499,
      "learning_rate": 1.55426731078905e-05,
      "loss": 0.1999,
      "step": 10700
    },
    {
      "epoch": 17.391304347826086,
      "grad_norm": 1.666249394416809,
      "learning_rate": 1.522061191626409e-05,
      "loss": 0.189,
      "step": 10800
    },
    {
      "epoch": 17.55233494363929,
      "grad_norm": 1.4150816202163696,
      "learning_rate": 1.4898550724637684e-05,
      "loss": 0.18,
      "step": 10900
    },
    {
      "epoch": 17.713365539452496,
      "grad_norm": 1.882428526878357,
      "learning_rate": 1.4576489533011272e-05,
      "loss": 0.156,
      "step": 11000
    },
    {
      "epoch": 17.8743961352657,
      "grad_norm": 2.003030300140381,
      "learning_rate": 1.4254428341384864e-05,
      "loss": 0.1567,
      "step": 11100
    },
    {
      "epoch": 18.035426731078903,
      "grad_norm": 1.3539316654205322,
      "learning_rate": 1.3932367149758454e-05,
      "loss": 0.167,
      "step": 11200
    },
    {
      "epoch": 18.19645732689211,
      "grad_norm": 1.102281093597412,
      "learning_rate": 1.3610305958132046e-05,
      "loss": 0.1572,
      "step": 11300
    },
    {
      "epoch": 18.357487922705314,
      "grad_norm": 2.2290408611297607,
      "learning_rate": 1.3288244766505636e-05,
      "loss": 0.1652,
      "step": 11400
    },
    {
      "epoch": 18.51851851851852,
      "grad_norm": 4.6659770011901855,
      "learning_rate": 1.2966183574879228e-05,
      "loss": 0.1839,
      "step": 11500
    },
    {
      "epoch": 18.679549114331724,
      "grad_norm": 3.4267258644104004,
      "learning_rate": 1.2644122383252818e-05,
      "loss": 0.1569,
      "step": 11600
    },
    {
      "epoch": 18.840579710144926,
      "grad_norm": 27.4092960357666,
      "learning_rate": 1.2322061191626408e-05,
      "loss": 0.1748,
      "step": 11700
    },
    {
      "epoch": 19.00161030595813,
      "grad_norm": 1.119210124015808,
      "learning_rate": 1.2e-05,
      "loss": 0.1642,
      "step": 11800
    },
    {
      "epoch": 19.162640901771336,
      "grad_norm": 13.119990348815918,
      "learning_rate": 1.167793880837359e-05,
      "loss": 0.169,
      "step": 11900
    },
    {
      "epoch": 19.32367149758454,
      "grad_norm": 5.96657133102417,
      "learning_rate": 1.1355877616747182e-05,
      "loss": 0.1888,
      "step": 12000
    },
    {
      "epoch": 19.32367149758454,
      "eval_f1_macro": 0.8643037891228349,
      "eval_iou_Block": 0.7407773633167076,
      "eval_iou_unlabeled": 0.7817633279484465,
      "eval_loss": 0.5033695101737976,
      "eval_macro_precision": 0.8642085781975233,
      "eval_macro_recall": 0.8643990210304686,
      "eval_mean_accuracy": 0.8643990210304686,
      "eval_mean_iou": 0.7612703456325771,
      "eval_overall_accuracy": 0.8655890329957163,
      "eval_precision_Block": 0.8498364077346969,
      "eval_precision_unlabeled": 0.8785807486603496,
      "eval_recall_Block": 0.8523432866090718,
      "eval_recall_unlabeled": 0.8764547554518655,
      "eval_runtime": 17.0177,
      "eval_samples_per_second": 45.306,
      "eval_steps_per_second": 11.341,
      "step": 12000
    },
    {
      "epoch": 19.484702093397747,
      "grad_norm": 2.1163806915283203,
      "learning_rate": 1.1033816425120772e-05,
      "loss": 0.1699,
      "step": 12100
    },
    {
      "epoch": 19.64573268921095,
      "grad_norm": 4.10832405090332,
      "learning_rate": 1.0711755233494364e-05,
      "loss": 0.166,
      "step": 12200
    },
    {
      "epoch": 19.806763285024154,
      "grad_norm": 1.4577451944351196,
      "learning_rate": 1.0389694041867954e-05,
      "loss": 0.1767,
      "step": 12300
    },
    {
      "epoch": 19.96779388083736,
      "grad_norm": 4.318380355834961,
      "learning_rate": 1.0067632850241548e-05,
      "loss": 0.1715,
      "step": 12400
    },
    {
      "epoch": 20.128824476650564,
      "grad_norm": 2.1267452239990234,
      "learning_rate": 9.745571658615138e-06,
      "loss": 0.166,
      "step": 12500
    },
    {
      "epoch": 20.28985507246377,
      "grad_norm": 5.723224639892578,
      "learning_rate": 9.423510466988728e-06,
      "loss": 0.1599,
      "step": 12600
    },
    {
      "epoch": 20.45088566827697,
      "grad_norm": 2.361257314682007,
      "learning_rate": 9.10144927536232e-06,
      "loss": 0.1538,
      "step": 12700
    },
    {
      "epoch": 20.611916264090176,
      "grad_norm": 0.9132885336875916,
      "learning_rate": 8.77938808373591e-06,
      "loss": 0.1985,
      "step": 12800
    },
    {
      "epoch": 20.77294685990338,
      "grad_norm": 1.7916213274002075,
      "learning_rate": 8.457326892109502e-06,
      "loss": 0.1537,
      "step": 12900
    },
    {
      "epoch": 20.933977455716587,
      "grad_norm": 4.2375006675720215,
      "learning_rate": 8.135265700483092e-06,
      "loss": 0.1833,
      "step": 13000
    },
    {
      "epoch": 21.095008051529792,
      "grad_norm": 0.7466241717338562,
      "learning_rate": 7.813204508856684e-06,
      "loss": 0.1692,
      "step": 13100
    },
    {
      "epoch": 21.256038647342994,
      "grad_norm": 1.3724216222763062,
      "learning_rate": 7.491143317230275e-06,
      "loss": 0.1552,
      "step": 13200
    },
    {
      "epoch": 21.4170692431562,
      "grad_norm": 1.5475016832351685,
      "learning_rate": 7.169082125603865e-06,
      "loss": 0.158,
      "step": 13300
    },
    {
      "epoch": 21.578099838969404,
      "grad_norm": 1.5484713315963745,
      "learning_rate": 6.847020933977456e-06,
      "loss": 0.1567,
      "step": 13400
    },
    {
      "epoch": 21.73913043478261,
      "grad_norm": 7.8599748611450195,
      "learning_rate": 6.524959742351047e-06,
      "loss": 0.1627,
      "step": 13500
    },
    {
      "epoch": 21.900161030595815,
      "grad_norm": 0.6253150701522827,
      "learning_rate": 6.202898550724638e-06,
      "loss": 0.165,
      "step": 13600
    },
    {
      "epoch": 22.061191626409016,
      "grad_norm": 3.162947177886963,
      "learning_rate": 5.880837359098229e-06,
      "loss": 0.1478,
      "step": 13700
    },
    {
      "epoch": 22.22222222222222,
      "grad_norm": 1.173148512840271,
      "learning_rate": 5.55877616747182e-06,
      "loss": 0.1623,
      "step": 13800
    },
    {
      "epoch": 22.383252818035427,
      "grad_norm": 1.1005022525787354,
      "learning_rate": 5.236714975845411e-06,
      "loss": 0.1697,
      "step": 13900
    },
    {
      "epoch": 22.544283413848632,
      "grad_norm": 27.574731826782227,
      "learning_rate": 4.914653784219002e-06,
      "loss": 0.177,
      "step": 14000
    },
    {
      "epoch": 22.544283413848632,
      "eval_f1_macro": 0.8655022790132582,
      "eval_iou_Block": 0.7436461050447865,
      "eval_iou_unlabeled": 0.7824777092580861,
      "eval_loss": 0.5630305409431458,
      "eval_macro_precision": 0.8651028017840605,
      "eval_macro_recall": 0.865902125345904,
      "eval_mean_accuracy": 0.865902125345904,
      "eval_mean_iou": 0.7630619071514363,
      "eval_overall_accuracy": 0.8666326569830551,
      "eval_precision_Block": 0.8475258372176571,
      "eval_precision_unlabeled": 0.882679766350464,
      "eval_recall_Block": 0.8585012792526554,
      "eval_recall_unlabeled": 0.8733029714391527,
      "eval_runtime": 17.1821,
      "eval_samples_per_second": 44.872,
      "eval_steps_per_second": 11.233,
      "step": 14000
    },
    {
      "epoch": 22.705314009661837,
      "grad_norm": 1.569216012954712,
      "learning_rate": 4.592592592592593e-06,
      "loss": 0.1458,
      "step": 14100
    },
    {
      "epoch": 22.86634460547504,
      "grad_norm": 2.5516836643218994,
      "learning_rate": 4.270531400966184e-06,
      "loss": 0.1638,
      "step": 14200
    },
    {
      "epoch": 23.027375201288244,
      "grad_norm": 1.8900634050369263,
      "learning_rate": 3.948470209339775e-06,
      "loss": 0.1838,
      "step": 14300
    },
    {
      "epoch": 23.18840579710145,
      "grad_norm": 1.4209258556365967,
      "learning_rate": 3.6264090177133658e-06,
      "loss": 0.1577,
      "step": 14400
    },
    {
      "epoch": 23.349436392914654,
      "grad_norm": 0.6507066488265991,
      "learning_rate": 3.3043478260869563e-06,
      "loss": 0.1414,
      "step": 14500
    },
    {
      "epoch": 23.51046698872786,
      "grad_norm": 0.7437978982925415,
      "learning_rate": 2.9822866344605477e-06,
      "loss": 0.1427,
      "step": 14600
    },
    {
      "epoch": 23.67149758454106,
      "grad_norm": 11.053792953491211,
      "learning_rate": 2.6602254428341387e-06,
      "loss": 0.1636,
      "step": 14700
    },
    {
      "epoch": 23.832528180354267,
      "grad_norm": 2.149352788925171,
      "learning_rate": 2.3381642512077297e-06,
      "loss": 0.154,
      "step": 14800
    },
    {
      "epoch": 23.993558776167472,
      "grad_norm": 3.2517545223236084,
      "learning_rate": 2.0161030595813207e-06,
      "loss": 0.1423,
      "step": 14900
    },
    {
      "epoch": 24.154589371980677,
      "grad_norm": 4.580913543701172,
      "learning_rate": 1.6940418679549114e-06,
      "loss": 0.1729,
      "step": 15000
    },
    {
      "epoch": 24.315619967793882,
      "grad_norm": 17.703813552856445,
      "learning_rate": 1.3719806763285026e-06,
      "loss": 0.1608,
      "step": 15100
    },
    {
      "epoch": 24.476650563607084,
      "grad_norm": 3.26120662689209,
      "learning_rate": 1.0499194847020934e-06,
      "loss": 0.167,
      "step": 15200
    },
    {
      "epoch": 24.63768115942029,
      "grad_norm": 3.867589235305786,
      "learning_rate": 7.278582930756844e-07,
      "loss": 0.1445,
      "step": 15300
    },
    {
      "epoch": 24.798711755233494,
      "grad_norm": 1.1963589191436768,
      "learning_rate": 4.057971014492754e-07,
      "loss": 0.1648,
      "step": 15400
    },
    {
      "epoch": 24.9597423510467,
      "grad_norm": 0.9989599585533142,
      "learning_rate": 8.373590982286635e-08,
      "loss": 0.1354,
      "step": 15500
    }
  ],
  "logging_steps": 100,
  "max_steps": 15525,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 25,
  "save_steps": 2000,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 30,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 3
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.0876096401113088e+18,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
