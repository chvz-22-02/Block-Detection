{
  "best_global_step": 30000,
  "best_metric": 0.7646302936870707,
  "best_model_checkpoint": "out/sf-2000-256-overlap\\checkpoint-30000",
  "epoch": 25.0,
  "eval_steps": 2000,
  "global_step": 37975,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06583278472679395,
      "grad_norm": 2.664527654647827,
      "learning_rate": 4.986965108624095e-05,
      "loss": 0.539,
      "step": 100
    },
    {
      "epoch": 0.1316655694535879,
      "grad_norm": 5.90831995010376,
      "learning_rate": 4.973798551678736e-05,
      "loss": 0.4834,
      "step": 200
    },
    {
      "epoch": 0.19749835418038184,
      "grad_norm": 14.406974792480469,
      "learning_rate": 4.9606319947333776e-05,
      "loss": 0.4308,
      "step": 300
    },
    {
      "epoch": 0.2633311389071758,
      "grad_norm": 4.338545799255371,
      "learning_rate": 4.9474654377880185e-05,
      "loss": 0.4569,
      "step": 400
    },
    {
      "epoch": 0.32916392363396973,
      "grad_norm": 3.2161366939544678,
      "learning_rate": 4.93429888084266e-05,
      "loss": 0.4066,
      "step": 500
    },
    {
      "epoch": 0.39499670836076367,
      "grad_norm": 1.141257882118225,
      "learning_rate": 4.921132323897301e-05,
      "loss": 0.4128,
      "step": 600
    },
    {
      "epoch": 0.4608294930875576,
      "grad_norm": 5.454710960388184,
      "learning_rate": 4.9079657669519425e-05,
      "loss": 0.4252,
      "step": 700
    },
    {
      "epoch": 0.5266622778143516,
      "grad_norm": 0.8631735444068909,
      "learning_rate": 4.8947992100065834e-05,
      "loss": 0.3642,
      "step": 800
    },
    {
      "epoch": 0.5924950625411455,
      "grad_norm": 2.3673620223999023,
      "learning_rate": 4.881632653061225e-05,
      "loss": 0.4416,
      "step": 900
    },
    {
      "epoch": 0.6583278472679395,
      "grad_norm": 3.5876762866973877,
      "learning_rate": 4.868466096115866e-05,
      "loss": 0.3925,
      "step": 1000
    },
    {
      "epoch": 0.7241606319947334,
      "grad_norm": 8.295132637023926,
      "learning_rate": 4.855299539170507e-05,
      "loss": 0.3641,
      "step": 1100
    },
    {
      "epoch": 0.7899934167215273,
      "grad_norm": 2.4241979122161865,
      "learning_rate": 4.842132982225148e-05,
      "loss": 0.417,
      "step": 1200
    },
    {
      "epoch": 0.8558262014483212,
      "grad_norm": 2.6224253177642822,
      "learning_rate": 4.828966425279789e-05,
      "loss": 0.3817,
      "step": 1300
    },
    {
      "epoch": 0.9216589861751152,
      "grad_norm": 4.990730285644531,
      "learning_rate": 4.815799868334431e-05,
      "loss": 0.4246,
      "step": 1400
    },
    {
      "epoch": 0.9874917709019092,
      "grad_norm": 2.1195054054260254,
      "learning_rate": 4.8026333113890724e-05,
      "loss": 0.3747,
      "step": 1500
    },
    {
      "epoch": 1.0533245556287032,
      "grad_norm": 1.4328383207321167,
      "learning_rate": 4.789466754443713e-05,
      "loss": 0.3791,
      "step": 1600
    },
    {
      "epoch": 1.119157340355497,
      "grad_norm": 0.811440646648407,
      "learning_rate": 4.776300197498355e-05,
      "loss": 0.351,
      "step": 1700
    },
    {
      "epoch": 1.184990125082291,
      "grad_norm": 13.327720642089844,
      "learning_rate": 4.763133640552996e-05,
      "loss": 0.3886,
      "step": 1800
    },
    {
      "epoch": 1.2508229098090848,
      "grad_norm": 3.8223328590393066,
      "learning_rate": 4.749967083607637e-05,
      "loss": 0.3728,
      "step": 1900
    },
    {
      "epoch": 1.316655694535879,
      "grad_norm": 3.94637393951416,
      "learning_rate": 4.7368005266622775e-05,
      "loss": 0.3582,
      "step": 2000
    },
    {
      "epoch": 1.316655694535879,
      "eval_f1_macro": 0.84450139433369,
      "eval_iou_Block": 0.7419419873623747,
      "eval_iou_unlabeled": 0.7150362211080018,
      "eval_loss": 0.4182544946670532,
      "eval_macro_precision": 0.842755396779216,
      "eval_macro_recall": 0.8462546415286206,
      "eval_mean_accuracy": 0.8462546415286206,
      "eval_mean_iou": 0.7284891042351882,
      "eval_overall_accuracy": 0.843366138826167,
      "eval_precision_Block": 0.8889136504751692,
      "eval_precision_unlabeled": 0.7965971430832627,
      "eval_recall_Block": 0.8177647213457298,
      "eval_recall_unlabeled": 0.8747445617115115,
      "eval_runtime": 86.795,
      "eval_samples_per_second": 4.539,
      "eval_steps_per_second": 1.141,
      "step": 2000
    },
    {
      "epoch": 1.3824884792626728,
      "grad_norm": 2.7418689727783203,
      "learning_rate": 4.723633969716919e-05,
      "loss": 0.3844,
      "step": 2100
    },
    {
      "epoch": 1.4483212639894667,
      "grad_norm": 9.095647811889648,
      "learning_rate": 4.7104674127715606e-05,
      "loss": 0.3941,
      "step": 2200
    },
    {
      "epoch": 1.5141540487162608,
      "grad_norm": 2.178921937942505,
      "learning_rate": 4.6973008558262015e-05,
      "loss": 0.3586,
      "step": 2300
    },
    {
      "epoch": 1.5799868334430547,
      "grad_norm": 5.138808727264404,
      "learning_rate": 4.684134298880843e-05,
      "loss": 0.3614,
      "step": 2400
    },
    {
      "epoch": 1.6458196181698486,
      "grad_norm": 2.1045734882354736,
      "learning_rate": 4.670967741935484e-05,
      "loss": 0.3709,
      "step": 2500
    },
    {
      "epoch": 1.7116524028966427,
      "grad_norm": 7.906860828399658,
      "learning_rate": 4.6578011849901255e-05,
      "loss": 0.3714,
      "step": 2600
    },
    {
      "epoch": 1.7774851876234363,
      "grad_norm": 2.990206003189087,
      "learning_rate": 4.6446346280447664e-05,
      "loss": 0.3354,
      "step": 2700
    },
    {
      "epoch": 1.8433179723502304,
      "grad_norm": 0.9054550528526306,
      "learning_rate": 4.631468071099408e-05,
      "loss": 0.3563,
      "step": 2800
    },
    {
      "epoch": 1.9091507570770243,
      "grad_norm": 5.2496747970581055,
      "learning_rate": 4.618301514154049e-05,
      "loss": 0.3496,
      "step": 2900
    },
    {
      "epoch": 1.9749835418038182,
      "grad_norm": 2.039069890975952,
      "learning_rate": 4.60513495720869e-05,
      "loss": 0.351,
      "step": 3000
    },
    {
      "epoch": 2.0408163265306123,
      "grad_norm": 6.150867462158203,
      "learning_rate": 4.591968400263331e-05,
      "loss": 0.3436,
      "step": 3100
    },
    {
      "epoch": 2.1066491112574064,
      "grad_norm": 10.460977554321289,
      "learning_rate": 4.578801843317972e-05,
      "loss": 0.3273,
      "step": 3200
    },
    {
      "epoch": 2.1724818959842,
      "grad_norm": 1.9922339916229248,
      "learning_rate": 4.565635286372614e-05,
      "loss": 0.3457,
      "step": 3300
    },
    {
      "epoch": 2.238314680710994,
      "grad_norm": 6.211686611175537,
      "learning_rate": 4.552468729427255e-05,
      "loss": 0.3399,
      "step": 3400
    },
    {
      "epoch": 2.3041474654377883,
      "grad_norm": 2.954831123352051,
      "learning_rate": 4.539302172481896e-05,
      "loss": 0.3188,
      "step": 3500
    },
    {
      "epoch": 2.369980250164582,
      "grad_norm": 10.675289154052734,
      "learning_rate": 4.526135615536538e-05,
      "loss": 0.3455,
      "step": 3600
    },
    {
      "epoch": 2.435813034891376,
      "grad_norm": 9.428485870361328,
      "learning_rate": 4.512969058591179e-05,
      "loss": 0.349,
      "step": 3700
    },
    {
      "epoch": 2.5016458196181697,
      "grad_norm": 6.551865577697754,
      "learning_rate": 4.49980250164582e-05,
      "loss": 0.3384,
      "step": 3800
    },
    {
      "epoch": 2.5674786043449638,
      "grad_norm": 8.759160041809082,
      "learning_rate": 4.4866359447004605e-05,
      "loss": 0.3414,
      "step": 3900
    },
    {
      "epoch": 2.633311389071758,
      "grad_norm": 6.8100361824035645,
      "learning_rate": 4.473469387755102e-05,
      "loss": 0.3835,
      "step": 4000
    },
    {
      "epoch": 2.633311389071758,
      "eval_f1_macro": 0.8423543454750652,
      "eval_iou_Block": 0.7539749728327215,
      "eval_iou_unlabeled": 0.7018778314563615,
      "eval_loss": 0.390523225069046,
      "eval_macro_precision": 0.8430660328221331,
      "eval_macro_recall": 0.841643858679491,
      "eval_mean_accuracy": 0.841643858679491,
      "eval_mean_iou": 0.7279264021445415,
      "eval_overall_accuracy": 0.844211442821522,
      "eval_precision_Block": 0.8526170346394882,
      "eval_precision_unlabeled": 0.833515031004778,
      "eval_recall_Block": 0.8669684904366916,
      "eval_recall_unlabeled": 0.8163192269222905,
      "eval_runtime": 9.272,
      "eval_samples_per_second": 42.494,
      "eval_steps_per_second": 10.677,
      "step": 4000
    },
    {
      "epoch": 2.6991441737985515,
      "grad_norm": 8.13994026184082,
      "learning_rate": 4.4603028308097436e-05,
      "loss": 0.3398,
      "step": 4100
    },
    {
      "epoch": 2.7649769585253456,
      "grad_norm": 2.9634556770324707,
      "learning_rate": 4.4471362738643845e-05,
      "loss": 0.3167,
      "step": 4200
    },
    {
      "epoch": 2.8308097432521393,
      "grad_norm": 2.164642572402954,
      "learning_rate": 4.433969716919026e-05,
      "loss": 0.321,
      "step": 4300
    },
    {
      "epoch": 2.8966425279789334,
      "grad_norm": 0.9157038331031799,
      "learning_rate": 4.420803159973667e-05,
      "loss": 0.2971,
      "step": 4400
    },
    {
      "epoch": 2.9624753127057275,
      "grad_norm": 8.481097221374512,
      "learning_rate": 4.4076366030283085e-05,
      "loss": 0.3856,
      "step": 4500
    },
    {
      "epoch": 3.0283080974325216,
      "grad_norm": 0.8687734007835388,
      "learning_rate": 4.3944700460829494e-05,
      "loss": 0.3407,
      "step": 4600
    },
    {
      "epoch": 3.0941408821593153,
      "grad_norm": 0.8857004046440125,
      "learning_rate": 4.381303489137591e-05,
      "loss": 0.3032,
      "step": 4700
    },
    {
      "epoch": 3.1599736668861094,
      "grad_norm": 1.642301321029663,
      "learning_rate": 4.368136932192232e-05,
      "loss": 0.3097,
      "step": 4800
    },
    {
      "epoch": 3.225806451612903,
      "grad_norm": 7.39539909362793,
      "learning_rate": 4.354970375246873e-05,
      "loss": 0.3243,
      "step": 4900
    },
    {
      "epoch": 3.291639236339697,
      "grad_norm": 24.31253433227539,
      "learning_rate": 4.3418038183015143e-05,
      "loss": 0.3094,
      "step": 5000
    },
    {
      "epoch": 3.3574720210664912,
      "grad_norm": 5.265100479125977,
      "learning_rate": 4.328637261356155e-05,
      "loss": 0.3286,
      "step": 5100
    },
    {
      "epoch": 3.423304805793285,
      "grad_norm": 1.891613245010376,
      "learning_rate": 4.315470704410797e-05,
      "loss": 0.335,
      "step": 5200
    },
    {
      "epoch": 3.489137590520079,
      "grad_norm": 2.078442096710205,
      "learning_rate": 4.302304147465438e-05,
      "loss": 0.3101,
      "step": 5300
    },
    {
      "epoch": 3.554970375246873,
      "grad_norm": 4.603817462921143,
      "learning_rate": 4.289137590520079e-05,
      "loss": 0.3039,
      "step": 5400
    },
    {
      "epoch": 3.6208031599736668,
      "grad_norm": 2.5228967666625977,
      "learning_rate": 4.275971033574721e-05,
      "loss": 0.3225,
      "step": 5500
    },
    {
      "epoch": 3.686635944700461,
      "grad_norm": 2.7625155448913574,
      "learning_rate": 4.262804476629362e-05,
      "loss": 0.2865,
      "step": 5600
    },
    {
      "epoch": 3.752468729427255,
      "grad_norm": 1.2234874963760376,
      "learning_rate": 4.249637919684003e-05,
      "loss": 0.3145,
      "step": 5700
    },
    {
      "epoch": 3.8183015141540486,
      "grad_norm": 0.9053913354873657,
      "learning_rate": 4.236471362738644e-05,
      "loss": 0.2877,
      "step": 5800
    },
    {
      "epoch": 3.8841342988808427,
      "grad_norm": 1.8759799003601074,
      "learning_rate": 4.223304805793285e-05,
      "loss": 0.3239,
      "step": 5900
    },
    {
      "epoch": 3.9499670836076364,
      "grad_norm": 14.138555526733398,
      "learning_rate": 4.2101382488479266e-05,
      "loss": 0.3056,
      "step": 6000
    },
    {
      "epoch": 3.9499670836076364,
      "eval_f1_macro": 0.8520690993708522,
      "eval_iou_Block": 0.7587717342678635,
      "eval_iou_unlabeled": 0.7244424510996176,
      "eval_loss": 0.45546478033065796,
      "eval_macro_precision": 0.8507123217621633,
      "eval_macro_recall": 0.8534302116681604,
      "eval_mean_accuracy": 0.8534302116681604,
      "eval_mean_iou": 0.7416070926837406,
      "eval_overall_accuracy": 0.8523866972947484,
      "eval_precision_Block": 0.8834908160761487,
      "eval_precision_unlabeled": 0.8179338274481778,
      "eval_recall_Block": 0.8431378061312181,
      "eval_recall_unlabeled": 0.8637226172051026,
      "eval_runtime": 9.2496,
      "eval_samples_per_second": 42.596,
      "eval_steps_per_second": 10.703,
      "step": 6000
    },
    {
      "epoch": 4.0157998683344305,
      "grad_norm": 1.7158697843551636,
      "learning_rate": 4.1969716919025675e-05,
      "loss": 0.2987,
      "step": 6100
    },
    {
      "epoch": 4.081632653061225,
      "grad_norm": 21.36855125427246,
      "learning_rate": 4.183805134957209e-05,
      "loss": 0.2905,
      "step": 6200
    },
    {
      "epoch": 4.147465437788019,
      "grad_norm": 2.9461612701416016,
      "learning_rate": 4.17063857801185e-05,
      "loss": 0.2857,
      "step": 6300
    },
    {
      "epoch": 4.213298222514813,
      "grad_norm": 10.304422378540039,
      "learning_rate": 4.1574720210664915e-05,
      "loss": 0.2675,
      "step": 6400
    },
    {
      "epoch": 4.279131007241606,
      "grad_norm": 1.4501451253890991,
      "learning_rate": 4.1443054641211324e-05,
      "loss": 0.2897,
      "step": 6500
    },
    {
      "epoch": 4.3449637919684,
      "grad_norm": 1.9537142515182495,
      "learning_rate": 4.131138907175774e-05,
      "loss": 0.267,
      "step": 6600
    },
    {
      "epoch": 4.410796576695194,
      "grad_norm": 2.8589653968811035,
      "learning_rate": 4.117972350230415e-05,
      "loss": 0.2806,
      "step": 6700
    },
    {
      "epoch": 4.476629361421988,
      "grad_norm": 8.20831298828125,
      "learning_rate": 4.104805793285056e-05,
      "loss": 0.2943,
      "step": 6800
    },
    {
      "epoch": 4.542462146148782,
      "grad_norm": 9.708272933959961,
      "learning_rate": 4.0916392363396973e-05,
      "loss": 0.3184,
      "step": 6900
    },
    {
      "epoch": 4.6082949308755765,
      "grad_norm": 3.5544984340667725,
      "learning_rate": 4.078472679394338e-05,
      "loss": 0.3068,
      "step": 7000
    },
    {
      "epoch": 4.67412771560237,
      "grad_norm": 0.9631656408309937,
      "learning_rate": 4.06530612244898e-05,
      "loss": 0.2997,
      "step": 7100
    },
    {
      "epoch": 4.739960500329164,
      "grad_norm": 1.7164112329483032,
      "learning_rate": 4.052139565503621e-05,
      "loss": 0.2813,
      "step": 7200
    },
    {
      "epoch": 4.805793285055958,
      "grad_norm": 1.4324288368225098,
      "learning_rate": 4.038973008558262e-05,
      "loss": 0.2694,
      "step": 7300
    },
    {
      "epoch": 4.871626069782752,
      "grad_norm": 2.0315892696380615,
      "learning_rate": 4.025806451612903e-05,
      "loss": 0.2669,
      "step": 7400
    },
    {
      "epoch": 4.937458854509546,
      "grad_norm": 8.299335479736328,
      "learning_rate": 4.012639894667545e-05,
      "loss": 0.291,
      "step": 7500
    },
    {
      "epoch": 5.003291639236339,
      "grad_norm": 11.861257553100586,
      "learning_rate": 3.999473337722186e-05,
      "loss": 0.2823,
      "step": 7600
    },
    {
      "epoch": 5.0691244239631335,
      "grad_norm": 2.165564775466919,
      "learning_rate": 3.986306780776827e-05,
      "loss": 0.2755,
      "step": 7700
    },
    {
      "epoch": 5.1349572086899276,
      "grad_norm": 2.0435972213745117,
      "learning_rate": 3.973140223831468e-05,
      "loss": 0.2549,
      "step": 7800
    },
    {
      "epoch": 5.200789993416722,
      "grad_norm": 5.982476234436035,
      "learning_rate": 3.959973666886109e-05,
      "loss": 0.2571,
      "step": 7900
    },
    {
      "epoch": 5.266622778143516,
      "grad_norm": 1.9328277111053467,
      "learning_rate": 3.9468071099407505e-05,
      "loss": 0.2594,
      "step": 8000
    },
    {
      "epoch": 5.266622778143516,
      "eval_f1_macro": 0.8597115633248371,
      "eval_iou_Block": 0.770026072756491,
      "eval_iou_unlabeled": 0.7366125147488569,
      "eval_loss": 0.42799749970436096,
      "eval_macro_precision": 0.8583617056033619,
      "eval_macro_recall": 0.8610656733009401,
      "eval_mean_accuracy": 0.8610656733009401,
      "eval_mean_iou": 0.753319293752674,
      "eval_overall_accuracy": 0.8600421169687649,
      "eval_precision_Block": 0.8900535295409522,
      "eval_precision_unlabeled": 0.8266698816657717,
      "eval_recall_Block": 0.8509701181949704,
      "eval_recall_unlabeled": 0.8711612284069098,
      "eval_runtime": 9.1399,
      "eval_samples_per_second": 43.108,
      "eval_steps_per_second": 10.832,
      "step": 8000
    },
    {
      "epoch": 5.33245556287031,
      "grad_norm": 6.543508052825928,
      "learning_rate": 3.933640552995392e-05,
      "loss": 0.2883,
      "step": 8100
    },
    {
      "epoch": 5.398288347597103,
      "grad_norm": 1.7291656732559204,
      "learning_rate": 3.920473996050033e-05,
      "loss": 0.2811,
      "step": 8200
    },
    {
      "epoch": 5.464121132323897,
      "grad_norm": 3.142181396484375,
      "learning_rate": 3.9073074391046746e-05,
      "loss": 0.2712,
      "step": 8300
    },
    {
      "epoch": 5.529953917050691,
      "grad_norm": 2.904348850250244,
      "learning_rate": 3.8941408821593154e-05,
      "loss": 0.2506,
      "step": 8400
    },
    {
      "epoch": 5.595786701777485,
      "grad_norm": 29.975709915161133,
      "learning_rate": 3.880974325213957e-05,
      "loss": 0.2662,
      "step": 8500
    },
    {
      "epoch": 5.6616194865042795,
      "grad_norm": 7.704196929931641,
      "learning_rate": 3.867807768268598e-05,
      "loss": 0.2381,
      "step": 8600
    },
    {
      "epoch": 5.727452271231073,
      "grad_norm": 11.429057121276855,
      "learning_rate": 3.8546412113232395e-05,
      "loss": 0.2719,
      "step": 8700
    },
    {
      "epoch": 5.793285055957867,
      "grad_norm": 0.9077610969543457,
      "learning_rate": 3.8414746543778804e-05,
      "loss": 0.2643,
      "step": 8800
    },
    {
      "epoch": 5.859117840684661,
      "grad_norm": 6.891399383544922,
      "learning_rate": 3.828308097432521e-05,
      "loss": 0.2471,
      "step": 8900
    },
    {
      "epoch": 5.924950625411455,
      "grad_norm": 4.0178632736206055,
      "learning_rate": 3.815141540487163e-05,
      "loss": 0.2673,
      "step": 9000
    },
    {
      "epoch": 5.990783410138249,
      "grad_norm": 0.7079195976257324,
      "learning_rate": 3.801974983541804e-05,
      "loss": 0.2425,
      "step": 9100
    },
    {
      "epoch": 6.056616194865043,
      "grad_norm": 1.1627227067947388,
      "learning_rate": 3.788808426596445e-05,
      "loss": 0.2459,
      "step": 9200
    },
    {
      "epoch": 6.122448979591836,
      "grad_norm": 3.632969379425049,
      "learning_rate": 3.775641869651086e-05,
      "loss": 0.2078,
      "step": 9300
    },
    {
      "epoch": 6.1882817643186305,
      "grad_norm": 17.90888214111328,
      "learning_rate": 3.762475312705728e-05,
      "loss": 0.2494,
      "step": 9400
    },
    {
      "epoch": 6.254114549045425,
      "grad_norm": 1.318807601928711,
      "learning_rate": 3.749308755760369e-05,
      "loss": 0.2648,
      "step": 9500
    },
    {
      "epoch": 6.319947333772219,
      "grad_norm": 15.585553169250488,
      "learning_rate": 3.73614219881501e-05,
      "loss": 0.2641,
      "step": 9600
    },
    {
      "epoch": 6.385780118499013,
      "grad_norm": 3.1145589351654053,
      "learning_rate": 3.722975641869652e-05,
      "loss": 0.2357,
      "step": 9700
    },
    {
      "epoch": 6.451612903225806,
      "grad_norm": 2.996244192123413,
      "learning_rate": 3.709809084924292e-05,
      "loss": 0.2438,
      "step": 9800
    },
    {
      "epoch": 6.5174456879526,
      "grad_norm": 5.308302879333496,
      "learning_rate": 3.6966425279789335e-05,
      "loss": 0.2444,
      "step": 9900
    },
    {
      "epoch": 6.583278472679394,
      "grad_norm": 21.716550827026367,
      "learning_rate": 3.683475971033575e-05,
      "loss": 0.2256,
      "step": 10000
    },
    {
      "epoch": 6.583278472679394,
      "eval_f1_macro": 0.8599659620703672,
      "eval_iou_Block": 0.7736147595374275,
      "eval_iou_unlabeled": 0.7350846315483449,
      "eval_loss": 0.48392295837402344,
      "eval_macro_precision": 0.8591848778650766,
      "eval_macro_recall": 0.8607484677348134,
      "eval_mean_accuracy": 0.8607484677348134,
      "eval_mean_iou": 0.7543496955428862,
      "eval_overall_accuracy": 0.8609573828992505,
      "eval_precision_Block": 0.882123561245687,
      "eval_precision_unlabeled": 0.8362461944844661,
      "eval_recall_Block": 0.862809042701474,
      "eval_recall_unlabeled": 0.8586878927681529,
      "eval_runtime": 9.1142,
      "eval_samples_per_second": 43.229,
      "eval_steps_per_second": 10.862,
      "step": 10000
    },
    {
      "epoch": 6.649111257406188,
      "grad_norm": 0.6032306551933289,
      "learning_rate": 3.670309414088216e-05,
      "loss": 0.255,
      "step": 10100
    },
    {
      "epoch": 6.7149440421329825,
      "grad_norm": 14.443254470825195,
      "learning_rate": 3.6571428571428576e-05,
      "loss": 0.2711,
      "step": 10200
    },
    {
      "epoch": 6.780776826859777,
      "grad_norm": 2.4860329627990723,
      "learning_rate": 3.6439763001974984e-05,
      "loss": 0.2265,
      "step": 10300
    },
    {
      "epoch": 6.84660961158657,
      "grad_norm": 6.543528079986572,
      "learning_rate": 3.63080974325214e-05,
      "loss": 0.2474,
      "step": 10400
    },
    {
      "epoch": 6.912442396313364,
      "grad_norm": 16.836631774902344,
      "learning_rate": 3.617643186306781e-05,
      "loss": 0.2448,
      "step": 10500
    },
    {
      "epoch": 6.978275181040158,
      "grad_norm": 1.1877285242080688,
      "learning_rate": 3.6044766293614225e-05,
      "loss": 0.2447,
      "step": 10600
    },
    {
      "epoch": 7.044107965766952,
      "grad_norm": 0.7325209379196167,
      "learning_rate": 3.5913100724160634e-05,
      "loss": 0.2237,
      "step": 10700
    },
    {
      "epoch": 7.109940750493746,
      "grad_norm": 1.469571828842163,
      "learning_rate": 3.578143515470704e-05,
      "loss": 0.247,
      "step": 10800
    },
    {
      "epoch": 7.175773535220539,
      "grad_norm": 21.321748733520508,
      "learning_rate": 3.564976958525346e-05,
      "loss": 0.199,
      "step": 10900
    },
    {
      "epoch": 7.2416063199473335,
      "grad_norm": 1.1079139709472656,
      "learning_rate": 3.551810401579987e-05,
      "loss": 0.2267,
      "step": 11000
    },
    {
      "epoch": 7.307439104674128,
      "grad_norm": 1.3046015501022339,
      "learning_rate": 3.538643844634628e-05,
      "loss": 0.2109,
      "step": 11100
    },
    {
      "epoch": 7.373271889400922,
      "grad_norm": 0.7611046433448792,
      "learning_rate": 3.525477287689269e-05,
      "loss": 0.2237,
      "step": 11200
    },
    {
      "epoch": 7.439104674127716,
      "grad_norm": 58.337745666503906,
      "learning_rate": 3.512310730743911e-05,
      "loss": 0.248,
      "step": 11300
    },
    {
      "epoch": 7.50493745885451,
      "grad_norm": 0.8857249617576599,
      "learning_rate": 3.499144173798552e-05,
      "loss": 0.2352,
      "step": 11400
    },
    {
      "epoch": 7.570770243581303,
      "grad_norm": 1.0259705781936646,
      "learning_rate": 3.485977616853193e-05,
      "loss": 0.2372,
      "step": 11500
    },
    {
      "epoch": 7.636603028308097,
      "grad_norm": 4.1803975105285645,
      "learning_rate": 3.472811059907835e-05,
      "loss": 0.237,
      "step": 11600
    },
    {
      "epoch": 7.702435813034891,
      "grad_norm": 1.5529229640960693,
      "learning_rate": 3.459644502962475e-05,
      "loss": 0.2189,
      "step": 11700
    },
    {
      "epoch": 7.768268597761685,
      "grad_norm": 2.808434247970581,
      "learning_rate": 3.4464779460171165e-05,
      "loss": 0.2282,
      "step": 11800
    },
    {
      "epoch": 7.8341013824884795,
      "grad_norm": 31.659629821777344,
      "learning_rate": 3.4333113890717574e-05,
      "loss": 0.208,
      "step": 11900
    },
    {
      "epoch": 7.899934167215273,
      "grad_norm": 5.477964878082275,
      "learning_rate": 3.420144832126399e-05,
      "loss": 0.2228,
      "step": 12000
    },
    {
      "epoch": 7.899934167215273,
      "eval_f1_macro": 0.862514067091783,
      "eval_iou_Block": 0.7707079928342668,
      "eval_iou_unlabeled": 0.7426185032926829,
      "eval_loss": 0.5173089504241943,
      "eval_macro_precision": 0.8608075770252608,
      "eval_macro_recall": 0.8642273365904876,
      "eval_mean_accuracy": 0.8642273365904876,
      "eval_mean_iou": 0.7566632480634748,
      "eval_overall_accuracy": 0.8620029972289419,
      "eval_precision_Block": 0.9006849045940069,
      "eval_precision_unlabeled": 0.8209302494565146,
      "eval_recall_Block": 0.8422882015444083,
      "eval_recall_unlabeled": 0.8861664716365669,
      "eval_runtime": 8.8237,
      "eval_samples_per_second": 44.652,
      "eval_steps_per_second": 11.22,
      "step": 12000
    },
    {
      "epoch": 7.965766951942067,
      "grad_norm": 10.571465492248535,
      "learning_rate": 3.4069782751810406e-05,
      "loss": 0.2174,
      "step": 12100
    },
    {
      "epoch": 8.031599736668861,
      "grad_norm": 0.6273064017295837,
      "learning_rate": 3.3938117182356815e-05,
      "loss": 0.2004,
      "step": 12200
    },
    {
      "epoch": 8.097432521395655,
      "grad_norm": 2.9151246547698975,
      "learning_rate": 3.380645161290323e-05,
      "loss": 0.2306,
      "step": 12300
    },
    {
      "epoch": 8.16326530612245,
      "grad_norm": 1.4977010488510132,
      "learning_rate": 3.367478604344964e-05,
      "loss": 0.193,
      "step": 12400
    },
    {
      "epoch": 8.229098090849243,
      "grad_norm": 4.736063003540039,
      "learning_rate": 3.3543120473996055e-05,
      "loss": 0.2365,
      "step": 12500
    },
    {
      "epoch": 8.294930875576037,
      "grad_norm": 0.9892051219940186,
      "learning_rate": 3.3411454904542464e-05,
      "loss": 0.2229,
      "step": 12600
    },
    {
      "epoch": 8.360763660302831,
      "grad_norm": 5.175655364990234,
      "learning_rate": 3.327978933508887e-05,
      "loss": 0.205,
      "step": 12700
    },
    {
      "epoch": 8.426596445029626,
      "grad_norm": 29.659957885742188,
      "learning_rate": 3.314812376563529e-05,
      "loss": 0.2298,
      "step": 12800
    },
    {
      "epoch": 8.492429229756418,
      "grad_norm": 0.4002167880535126,
      "learning_rate": 3.30164581961817e-05,
      "loss": 0.2234,
      "step": 12900
    },
    {
      "epoch": 8.558262014483212,
      "grad_norm": 8.601187705993652,
      "learning_rate": 3.288479262672811e-05,
      "loss": 0.2122,
      "step": 13000
    },
    {
      "epoch": 8.624094799210006,
      "grad_norm": 0.8237208127975464,
      "learning_rate": 3.275312705727452e-05,
      "loss": 0.2178,
      "step": 13100
    },
    {
      "epoch": 8.6899275839368,
      "grad_norm": 15.44037914276123,
      "learning_rate": 3.262146148782094e-05,
      "loss": 0.2214,
      "step": 13200
    },
    {
      "epoch": 8.755760368663594,
      "grad_norm": 4.828372478485107,
      "learning_rate": 3.2489795918367346e-05,
      "loss": 0.2334,
      "step": 13300
    },
    {
      "epoch": 8.821593153390388,
      "grad_norm": 1.4838128089904785,
      "learning_rate": 3.235813034891376e-05,
      "loss": 0.2065,
      "step": 13400
    },
    {
      "epoch": 8.887425938117183,
      "grad_norm": 0.48761510848999023,
      "learning_rate": 3.222646477946018e-05,
      "loss": 0.2018,
      "step": 13500
    },
    {
      "epoch": 8.953258722843977,
      "grad_norm": 1.781870722770691,
      "learning_rate": 3.2094799210006587e-05,
      "loss": 0.2264,
      "step": 13600
    },
    {
      "epoch": 9.01909150757077,
      "grad_norm": 2.5995659828186035,
      "learning_rate": 3.1963133640552995e-05,
      "loss": 0.2099,
      "step": 13700
    },
    {
      "epoch": 9.084924292297565,
      "grad_norm": 4.949694633483887,
      "learning_rate": 3.1831468071099404e-05,
      "loss": 0.2095,
      "step": 13800
    },
    {
      "epoch": 9.150757077024359,
      "grad_norm": 16.21332550048828,
      "learning_rate": 3.169980250164582e-05,
      "loss": 0.1801,
      "step": 13900
    },
    {
      "epoch": 9.216589861751151,
      "grad_norm": 4.277182579040527,
      "learning_rate": 3.1568136932192236e-05,
      "loss": 0.1887,
      "step": 14000
    },
    {
      "epoch": 9.216589861751151,
      "eval_f1_macro": 0.8608974884914055,
      "eval_iou_Block": 0.7670262553060267,
      "eval_iou_unlabeled": 0.7404601945534884,
      "eval_loss": 0.5202535390853882,
      "eval_macro_precision": 0.8591208192709385,
      "eval_macro_recall": 0.8626815212751493,
      "eval_mean_accuracy": 0.8626815212751493,
      "eval_mean_iou": 0.7537432249297575,
      "eval_overall_accuracy": 0.8600479164704453,
      "eval_precision_Block": 0.9020605845326605,
      "eval_precision_unlabeled": 0.8161810540092167,
      "eval_recall_Block": 0.8367057135961207,
      "eval_recall_unlabeled": 0.8886573289541778,
      "eval_runtime": 8.5196,
      "eval_samples_per_second": 46.246,
      "eval_steps_per_second": 11.62,
      "step": 14000
    },
    {
      "epoch": 9.282422646477945,
      "grad_norm": 2.0868759155273438,
      "learning_rate": 3.1436471362738645e-05,
      "loss": 0.2017,
      "step": 14100
    },
    {
      "epoch": 9.34825543120474,
      "grad_norm": 1.3103562593460083,
      "learning_rate": 3.130480579328506e-05,
      "loss": 0.2003,
      "step": 14200
    },
    {
      "epoch": 9.414088215931534,
      "grad_norm": 1.8906320333480835,
      "learning_rate": 3.117314022383147e-05,
      "loss": 0.2015,
      "step": 14300
    },
    {
      "epoch": 9.479921000658328,
      "grad_norm": 2.281444787979126,
      "learning_rate": 3.1041474654377885e-05,
      "loss": 0.2208,
      "step": 14400
    },
    {
      "epoch": 9.545753785385122,
      "grad_norm": 1.9435793161392212,
      "learning_rate": 3.0909809084924294e-05,
      "loss": 0.2269,
      "step": 14500
    },
    {
      "epoch": 9.611586570111916,
      "grad_norm": 4.388782501220703,
      "learning_rate": 3.07781435154707e-05,
      "loss": 0.1873,
      "step": 14600
    },
    {
      "epoch": 9.67741935483871,
      "grad_norm": 3.057002305984497,
      "learning_rate": 3.064647794601712e-05,
      "loss": 0.1859,
      "step": 14700
    },
    {
      "epoch": 9.743252139565504,
      "grad_norm": 2.8216421604156494,
      "learning_rate": 3.0514812376563527e-05,
      "loss": 0.191,
      "step": 14800
    },
    {
      "epoch": 9.809084924292298,
      "grad_norm": 3.149547576904297,
      "learning_rate": 3.038314680710994e-05,
      "loss": 0.2051,
      "step": 14900
    },
    {
      "epoch": 9.874917709019092,
      "grad_norm": 0.7551531195640564,
      "learning_rate": 3.0251481237656355e-05,
      "loss": 0.2097,
      "step": 15000
    },
    {
      "epoch": 9.940750493745885,
      "grad_norm": 2.3991894721984863,
      "learning_rate": 3.0119815668202768e-05,
      "loss": 0.2003,
      "step": 15100
    },
    {
      "epoch": 10.006583278472679,
      "grad_norm": 1.505125641822815,
      "learning_rate": 2.998815009874918e-05,
      "loss": 0.2209,
      "step": 15200
    },
    {
      "epoch": 10.072416063199473,
      "grad_norm": 12.230146408081055,
      "learning_rate": 2.9856484529295592e-05,
      "loss": 0.2008,
      "step": 15300
    },
    {
      "epoch": 10.138248847926267,
      "grad_norm": 6.350935935974121,
      "learning_rate": 2.9724818959842004e-05,
      "loss": 0.1863,
      "step": 15400
    },
    {
      "epoch": 10.204081632653061,
      "grad_norm": 6.368809700012207,
      "learning_rate": 2.9593153390388417e-05,
      "loss": 0.1768,
      "step": 15500
    },
    {
      "epoch": 10.269914417379855,
      "grad_norm": 13.347723007202148,
      "learning_rate": 2.9461487820934826e-05,
      "loss": 0.2109,
      "step": 15600
    },
    {
      "epoch": 10.33574720210665,
      "grad_norm": 1.1577579975128174,
      "learning_rate": 2.9329822251481238e-05,
      "loss": 0.2276,
      "step": 15700
    },
    {
      "epoch": 10.401579986833443,
      "grad_norm": 4.09920597076416,
      "learning_rate": 2.919815668202765e-05,
      "loss": 0.1794,
      "step": 15800
    },
    {
      "epoch": 10.467412771560237,
      "grad_norm": 2.7523467540740967,
      "learning_rate": 2.9066491112574062e-05,
      "loss": 0.1876,
      "step": 15900
    },
    {
      "epoch": 10.533245556287032,
      "grad_norm": 9.798116683959961,
      "learning_rate": 2.8934825543120475e-05,
      "loss": 0.1949,
      "step": 16000
    },
    {
      "epoch": 10.533245556287032,
      "eval_f1_macro": 0.8607208325788647,
      "eval_iou_Block": 0.7745570758296367,
      "eval_iou_unlabeled": 0.7364204523796987,
      "eval_loss": 0.506166398525238,
      "eval_macro_precision": 0.8599071701220649,
      "eval_macro_recall": 0.8615360363044975,
      "eval_mean_accuracy": 0.8615360363044975,
      "eval_mean_iou": 0.7554887641046677,
      "eval_overall_accuracy": 0.861680403578705,
      "eval_precision_Block": 0.8831908339776389,
      "eval_precision_unlabeled": 0.8366235062664908,
      "eval_recall_Block": 0.8629599616190547,
      "eval_recall_unlabeled": 0.8601121109899403,
      "eval_runtime": 9.034,
      "eval_samples_per_second": 43.613,
      "eval_steps_per_second": 10.959,
      "step": 16000
    },
    {
      "epoch": 10.599078341013826,
      "grad_norm": 0.8856887817382812,
      "learning_rate": 2.8803159973666887e-05,
      "loss": 0.176,
      "step": 16100
    },
    {
      "epoch": 10.66491112574062,
      "grad_norm": 11.02402400970459,
      "learning_rate": 2.86714944042133e-05,
      "loss": 0.21,
      "step": 16200
    },
    {
      "epoch": 10.730743910467412,
      "grad_norm": 0.7423064112663269,
      "learning_rate": 2.853982883475971e-05,
      "loss": 0.2202,
      "step": 16300
    },
    {
      "epoch": 10.796576695194206,
      "grad_norm": 7.9665846824646,
      "learning_rate": 2.8408163265306127e-05,
      "loss": 0.1825,
      "step": 16400
    },
    {
      "epoch": 10.862409479921,
      "grad_norm": 1.104081153869629,
      "learning_rate": 2.827649769585254e-05,
      "loss": 0.2039,
      "step": 16500
    },
    {
      "epoch": 10.928242264647794,
      "grad_norm": 2.661773443222046,
      "learning_rate": 2.8144832126398945e-05,
      "loss": 0.1966,
      "step": 16600
    },
    {
      "epoch": 10.994075049374588,
      "grad_norm": 2.507932186126709,
      "learning_rate": 2.8013166556945357e-05,
      "loss": 0.1845,
      "step": 16700
    },
    {
      "epoch": 11.059907834101383,
      "grad_norm": 1.6391844749450684,
      "learning_rate": 2.788150098749177e-05,
      "loss": 0.2044,
      "step": 16800
    },
    {
      "epoch": 11.125740618828177,
      "grad_norm": 1.3653714656829834,
      "learning_rate": 2.7749835418038185e-05,
      "loss": 0.1722,
      "step": 16900
    },
    {
      "epoch": 11.19157340355497,
      "grad_norm": 2.0418057441711426,
      "learning_rate": 2.7618169848584598e-05,
      "loss": 0.1901,
      "step": 17000
    },
    {
      "epoch": 11.257406188281765,
      "grad_norm": 2.4107072353363037,
      "learning_rate": 2.748650427913101e-05,
      "loss": 0.1971,
      "step": 17100
    },
    {
      "epoch": 11.323238973008559,
      "grad_norm": 36.141292572021484,
      "learning_rate": 2.7354838709677422e-05,
      "loss": 0.1727,
      "step": 17200
    },
    {
      "epoch": 11.389071757735351,
      "grad_norm": 13.422472953796387,
      "learning_rate": 2.7223173140223834e-05,
      "loss": 0.1941,
      "step": 17300
    },
    {
      "epoch": 11.454904542462145,
      "grad_norm": 3.1414411067962646,
      "learning_rate": 2.7091507570770247e-05,
      "loss": 0.1711,
      "step": 17400
    },
    {
      "epoch": 11.52073732718894,
      "grad_norm": 2.1098575592041016,
      "learning_rate": 2.695984200131666e-05,
      "loss": 0.1588,
      "step": 17500
    },
    {
      "epoch": 11.586570111915734,
      "grad_norm": 7.537332057952881,
      "learning_rate": 2.6828176431863068e-05,
      "loss": 0.1688,
      "step": 17600
    },
    {
      "epoch": 11.652402896642528,
      "grad_norm": 6.4897942543029785,
      "learning_rate": 2.669651086240948e-05,
      "loss": 0.1869,
      "step": 17700
    },
    {
      "epoch": 11.718235681369322,
      "grad_norm": 1.1434940099716187,
      "learning_rate": 2.6564845292955892e-05,
      "loss": 0.1734,
      "step": 17800
    },
    {
      "epoch": 11.784068466096116,
      "grad_norm": 12.33479118347168,
      "learning_rate": 2.6433179723502305e-05,
      "loss": 0.1709,
      "step": 17900
    },
    {
      "epoch": 11.84990125082291,
      "grad_norm": 2.750594139099121,
      "learning_rate": 2.6301514154048717e-05,
      "loss": 0.1572,
      "step": 18000
    },
    {
      "epoch": 11.84990125082291,
      "eval_f1_macro": 0.8621494652114614,
      "eval_iou_Block": 0.7763468581242507,
      "eval_iou_unlabeled": 0.7389467248100768,
      "eval_loss": 0.5894191265106201,
      "eval_macro_precision": 0.8612755351306314,
      "eval_macro_recall": 0.8630251706358353,
      "eval_mean_accuracy": 0.8630251706358353,
      "eval_mean_iou": 0.7576467914671638,
      "eval_overall_accuracy": 0.863048311417478,
      "eval_precision_Block": 0.8852098394234441,
      "eval_precision_unlabeled": 0.8373412308378188,
      "eval_recall_Block": 0.8632534131164151,
      "eval_recall_unlabeled": 0.8627969281552554,
      "eval_runtime": 8.8108,
      "eval_samples_per_second": 44.718,
      "eval_steps_per_second": 11.236,
      "step": 18000
    },
    {
      "epoch": 11.915734035549704,
      "grad_norm": 2.6203114986419678,
      "learning_rate": 2.616984858459513e-05,
      "loss": 0.1906,
      "step": 18100
    },
    {
      "epoch": 11.981566820276498,
      "grad_norm": 3.185246467590332,
      "learning_rate": 2.603818301514154e-05,
      "loss": 0.1834,
      "step": 18200
    },
    {
      "epoch": 12.047399605003292,
      "grad_norm": 2.75219988822937,
      "learning_rate": 2.5906517445687954e-05,
      "loss": 0.1557,
      "step": 18300
    },
    {
      "epoch": 12.113232389730086,
      "grad_norm": 2.992915153503418,
      "learning_rate": 2.577485187623437e-05,
      "loss": 0.1538,
      "step": 18400
    },
    {
      "epoch": 12.179065174456879,
      "grad_norm": 3.2110400199890137,
      "learning_rate": 2.5643186306780775e-05,
      "loss": 0.204,
      "step": 18500
    },
    {
      "epoch": 12.244897959183673,
      "grad_norm": 1.9865483045578003,
      "learning_rate": 2.5511520737327187e-05,
      "loss": 0.1512,
      "step": 18600
    },
    {
      "epoch": 12.310730743910467,
      "grad_norm": 1.3578156232833862,
      "learning_rate": 2.53798551678736e-05,
      "loss": 0.176,
      "step": 18700
    },
    {
      "epoch": 12.376563528637261,
      "grad_norm": 4.591263294219971,
      "learning_rate": 2.5248189598420012e-05,
      "loss": 0.2007,
      "step": 18800
    },
    {
      "epoch": 12.442396313364055,
      "grad_norm": 1.237874984741211,
      "learning_rate": 2.5116524028966428e-05,
      "loss": 0.1921,
      "step": 18900
    },
    {
      "epoch": 12.50822909809085,
      "grad_norm": 8.382662773132324,
      "learning_rate": 2.498485845951284e-05,
      "loss": 0.1734,
      "step": 19000
    },
    {
      "epoch": 12.574061882817643,
      "grad_norm": 0.944821298122406,
      "learning_rate": 2.4853192890059252e-05,
      "loss": 0.1515,
      "step": 19100
    },
    {
      "epoch": 12.639894667544437,
      "grad_norm": 0.6759684681892395,
      "learning_rate": 2.4721527320605665e-05,
      "loss": 0.1804,
      "step": 19200
    },
    {
      "epoch": 12.705727452271232,
      "grad_norm": 0.9995993971824646,
      "learning_rate": 2.4589861751152073e-05,
      "loss": 0.1577,
      "step": 19300
    },
    {
      "epoch": 12.771560236998026,
      "grad_norm": 1.1370880603790283,
      "learning_rate": 2.4458196181698486e-05,
      "loss": 0.1919,
      "step": 19400
    },
    {
      "epoch": 12.83739302172482,
      "grad_norm": 12.21922492980957,
      "learning_rate": 2.4326530612244898e-05,
      "loss": 0.1709,
      "step": 19500
    },
    {
      "epoch": 12.903225806451612,
      "grad_norm": 3.8138539791107178,
      "learning_rate": 2.4194865042791314e-05,
      "loss": 0.1661,
      "step": 19600
    },
    {
      "epoch": 12.969058591178406,
      "grad_norm": 2.9684534072875977,
      "learning_rate": 2.4063199473337723e-05,
      "loss": 0.1556,
      "step": 19700
    },
    {
      "epoch": 13.0348913759052,
      "grad_norm": 4.68226957321167,
      "learning_rate": 2.3931533903884135e-05,
      "loss": 0.1947,
      "step": 19800
    },
    {
      "epoch": 13.100724160631994,
      "grad_norm": 67.7851791381836,
      "learning_rate": 2.3799868334430547e-05,
      "loss": 0.1818,
      "step": 19900
    },
    {
      "epoch": 13.166556945358789,
      "grad_norm": 4.257424831390381,
      "learning_rate": 2.366820276497696e-05,
      "loss": 0.1558,
      "step": 20000
    },
    {
      "epoch": 13.166556945358789,
      "eval_f1_macro": 0.862106879578697,
      "eval_iou_Block": 0.7736293660750775,
      "eval_iou_unlabeled": 0.7404403996694592,
      "eval_loss": 0.6555938124656677,
      "eval_macro_precision": 0.8607669939797493,
      "eval_macro_recall": 0.8634509430627308,
      "eval_mean_accuracy": 0.8634509430627308,
      "eval_mean_iou": 0.7570348828722684,
      "eval_overall_accuracy": 0.8624524634501656,
      "eval_precision_Block": 0.891978326895935,
      "eval_precision_unlabeled": 0.8295556610635637,
      "eval_recall_Block": 0.8536027250077288,
      "eval_recall_unlabeled": 0.8732991611177328,
      "eval_runtime": 8.5212,
      "eval_samples_per_second": 46.237,
      "eval_steps_per_second": 11.618,
      "step": 20000
    },
    {
      "epoch": 13.232389730085583,
      "grad_norm": 2.8627383708953857,
      "learning_rate": 2.3536537195523372e-05,
      "loss": 0.1504,
      "step": 20100
    },
    {
      "epoch": 13.298222514812377,
      "grad_norm": 1.0577763319015503,
      "learning_rate": 2.3404871626069784e-05,
      "loss": 0.1589,
      "step": 20200
    },
    {
      "epoch": 13.36405529953917,
      "grad_norm": 1.0231046676635742,
      "learning_rate": 2.3273206056616196e-05,
      "loss": 0.1575,
      "step": 20300
    },
    {
      "epoch": 13.429888084265965,
      "grad_norm": 60.38513946533203,
      "learning_rate": 2.314154048716261e-05,
      "loss": 0.1694,
      "step": 20400
    },
    {
      "epoch": 13.495720868992759,
      "grad_norm": 0.8661919832229614,
      "learning_rate": 2.300987491770902e-05,
      "loss": 0.1629,
      "step": 20500
    },
    {
      "epoch": 13.561553653719553,
      "grad_norm": 2.73049259185791,
      "learning_rate": 2.2878209348255433e-05,
      "loss": 0.1764,
      "step": 20600
    },
    {
      "epoch": 13.627386438446345,
      "grad_norm": 22.357179641723633,
      "learning_rate": 2.2746543778801842e-05,
      "loss": 0.1661,
      "step": 20700
    },
    {
      "epoch": 13.69321922317314,
      "grad_norm": 2.125202178955078,
      "learning_rate": 2.2614878209348254e-05,
      "loss": 0.1605,
      "step": 20800
    },
    {
      "epoch": 13.759052007899934,
      "grad_norm": 1.1494500637054443,
      "learning_rate": 2.248321263989467e-05,
      "loss": 0.1641,
      "step": 20900
    },
    {
      "epoch": 13.824884792626728,
      "grad_norm": 1.83089017868042,
      "learning_rate": 2.2351547070441082e-05,
      "loss": 0.1587,
      "step": 21000
    },
    {
      "epoch": 13.890717577353522,
      "grad_norm": 1.0237276554107666,
      "learning_rate": 2.2219881500987495e-05,
      "loss": 0.1593,
      "step": 21100
    },
    {
      "epoch": 13.956550362080316,
      "grad_norm": 0.494797945022583,
      "learning_rate": 2.2088215931533904e-05,
      "loss": 0.1998,
      "step": 21200
    },
    {
      "epoch": 14.02238314680711,
      "grad_norm": 1.1923778057098389,
      "learning_rate": 2.1956550362080316e-05,
      "loss": 0.1609,
      "step": 21300
    },
    {
      "epoch": 14.088215931533904,
      "grad_norm": 1.5574195384979248,
      "learning_rate": 2.1824884792626728e-05,
      "loss": 0.1435,
      "step": 21400
    },
    {
      "epoch": 14.154048716260698,
      "grad_norm": 1.2672414779663086,
      "learning_rate": 2.169321922317314e-05,
      "loss": 0.1473,
      "step": 21500
    },
    {
      "epoch": 14.219881500987492,
      "grad_norm": 0.8490583300590515,
      "learning_rate": 2.1561553653719556e-05,
      "loss": 0.1968,
      "step": 21600
    },
    {
      "epoch": 14.285714285714286,
      "grad_norm": 1.3170373439788818,
      "learning_rate": 2.1429888084265965e-05,
      "loss": 0.1627,
      "step": 21700
    },
    {
      "epoch": 14.351547070441079,
      "grad_norm": 2.7611241340637207,
      "learning_rate": 2.1298222514812377e-05,
      "loss": 0.1527,
      "step": 21800
    },
    {
      "epoch": 14.417379855167873,
      "grad_norm": 9.262398719787598,
      "learning_rate": 2.116655694535879e-05,
      "loss": 0.1671,
      "step": 21900
    },
    {
      "epoch": 14.483212639894667,
      "grad_norm": 1.4511290788650513,
      "learning_rate": 2.1034891375905202e-05,
      "loss": 0.1681,
      "step": 22000
    },
    {
      "epoch": 14.483212639894667,
      "eval_f1_macro": 0.8660195463346769,
      "eval_iou_Block": 0.7780873688099312,
      "eval_iou_unlabeled": 0.7474265339884604,
      "eval_loss": 0.5847271084785461,
      "eval_macro_precision": 0.8645049148678463,
      "eval_macro_recall": 0.8675394944521294,
      "eval_mean_accuracy": 0.8675394944521294,
      "eval_mean_iou": 0.7627569513991959,
      "eval_overall_accuracy": 0.8660508944903533,
      "eval_precision_Block": 0.898736351699788,
      "eval_precision_unlabeled": 0.8302734780359045,
      "eval_recall_Block": 0.8528571145259388,
      "eval_recall_unlabeled": 0.88222187437832,
      "eval_runtime": 9.9523,
      "eval_samples_per_second": 39.589,
      "eval_steps_per_second": 9.947,
      "step": 22000
    },
    {
      "epoch": 14.549045424621461,
      "grad_norm": 5.216567039489746,
      "learning_rate": 2.0903225806451614e-05,
      "loss": 0.1906,
      "step": 22100
    },
    {
      "epoch": 14.614878209348255,
      "grad_norm": 3.510530710220337,
      "learning_rate": 2.0771560236998026e-05,
      "loss": 0.1508,
      "step": 22200
    },
    {
      "epoch": 14.68071099407505,
      "grad_norm": 1.0799007415771484,
      "learning_rate": 2.063989466754444e-05,
      "loss": 0.1648,
      "step": 22300
    },
    {
      "epoch": 14.746543778801843,
      "grad_norm": 2.7224748134613037,
      "learning_rate": 2.050822909809085e-05,
      "loss": 0.1413,
      "step": 22400
    },
    {
      "epoch": 14.812376563528638,
      "grad_norm": 0.620292603969574,
      "learning_rate": 2.0376563528637263e-05,
      "loss": 0.1659,
      "step": 22500
    },
    {
      "epoch": 14.878209348255432,
      "grad_norm": 5.734517574310303,
      "learning_rate": 2.0244897959183676e-05,
      "loss": 0.1513,
      "step": 22600
    },
    {
      "epoch": 14.944042132982226,
      "grad_norm": 4.068604946136475,
      "learning_rate": 2.0113232389730084e-05,
      "loss": 0.1473,
      "step": 22700
    },
    {
      "epoch": 15.00987491770902,
      "grad_norm": 36.622371673583984,
      "learning_rate": 1.9981566820276497e-05,
      "loss": 0.2211,
      "step": 22800
    },
    {
      "epoch": 15.075707702435814,
      "grad_norm": 3.4397616386413574,
      "learning_rate": 1.9849901250822912e-05,
      "loss": 0.1556,
      "step": 22900
    },
    {
      "epoch": 15.141540487162606,
      "grad_norm": 4.094072341918945,
      "learning_rate": 1.9718235681369325e-05,
      "loss": 0.1771,
      "step": 23000
    },
    {
      "epoch": 15.2073732718894,
      "grad_norm": 13.757534980773926,
      "learning_rate": 1.9586570111915737e-05,
      "loss": 0.1576,
      "step": 23100
    },
    {
      "epoch": 15.273206056616194,
      "grad_norm": 1.9407516717910767,
      "learning_rate": 1.9454904542462146e-05,
      "loss": 0.1659,
      "step": 23200
    },
    {
      "epoch": 15.339038841342989,
      "grad_norm": 2.567138910293579,
      "learning_rate": 1.9323238973008558e-05,
      "loss": 0.1459,
      "step": 23300
    },
    {
      "epoch": 15.404871626069783,
      "grad_norm": 1.867597222328186,
      "learning_rate": 1.919157340355497e-05,
      "loss": 0.1445,
      "step": 23400
    },
    {
      "epoch": 15.470704410796577,
      "grad_norm": 4.250420093536377,
      "learning_rate": 1.9059907834101383e-05,
      "loss": 0.1488,
      "step": 23500
    },
    {
      "epoch": 15.53653719552337,
      "grad_norm": 4.148475170135498,
      "learning_rate": 1.8928242264647795e-05,
      "loss": 0.1406,
      "step": 23600
    },
    {
      "epoch": 15.602369980250165,
      "grad_norm": 1.0826046466827393,
      "learning_rate": 1.8796576695194207e-05,
      "loss": 0.1318,
      "step": 23700
    },
    {
      "epoch": 15.668202764976959,
      "grad_norm": 2.307647943496704,
      "learning_rate": 1.866491112574062e-05,
      "loss": 0.1693,
      "step": 23800
    },
    {
      "epoch": 15.734035549703753,
      "grad_norm": 1.5942381620407104,
      "learning_rate": 1.8533245556287032e-05,
      "loss": 0.1695,
      "step": 23900
    },
    {
      "epoch": 15.799868334430546,
      "grad_norm": 1.4528700113296509,
      "learning_rate": 1.8401579986833444e-05,
      "loss": 0.1522,
      "step": 24000
    },
    {
      "epoch": 15.799868334430546,
      "eval_f1_macro": 0.8638913751589199,
      "eval_iou_Block": 0.7780519601689139,
      "eval_iou_unlabeled": 0.7423318308783928,
      "eval_loss": 0.6307429075241089,
      "eval_macro_precision": 0.862849293501733,
      "eval_macro_recall": 0.8649359769496062,
      "eval_mean_accuracy": 0.8649359769496062,
      "eval_mean_iou": 0.7601918955236533,
      "eval_overall_accuracy": 0.864618243299765,
      "eval_precision_Block": 0.8889663258511382,
      "eval_precision_unlabeled": 0.8367322611523278,
      "eval_recall_Block": 0.8618021019784303,
      "eval_recall_unlabeled": 0.8680698519207821,
      "eval_runtime": 8.439,
      "eval_samples_per_second": 46.688,
      "eval_steps_per_second": 11.731,
      "step": 24000
    },
    {
      "epoch": 15.86570111915734,
      "grad_norm": 1.1806436777114868,
      "learning_rate": 1.8269914417379856e-05,
      "loss": 0.146,
      "step": 24100
    },
    {
      "epoch": 15.931533903884134,
      "grad_norm": 1.7473986148834229,
      "learning_rate": 1.813824884792627e-05,
      "loss": 0.1409,
      "step": 24200
    },
    {
      "epoch": 15.997366688610928,
      "grad_norm": 26.55050277709961,
      "learning_rate": 1.800658327847268e-05,
      "loss": 0.1405,
      "step": 24300
    },
    {
      "epoch": 16.063199473337722,
      "grad_norm": 1.0776684284210205,
      "learning_rate": 1.7874917709019093e-05,
      "loss": 0.145,
      "step": 24400
    },
    {
      "epoch": 16.129032258064516,
      "grad_norm": 1.4554688930511475,
      "learning_rate": 1.7743252139565506e-05,
      "loss": 0.1521,
      "step": 24500
    },
    {
      "epoch": 16.19486504279131,
      "grad_norm": 0.9816213250160217,
      "learning_rate": 1.7611586570111915e-05,
      "loss": 0.145,
      "step": 24600
    },
    {
      "epoch": 16.260697827518104,
      "grad_norm": 1.4591704607009888,
      "learning_rate": 1.7479921000658327e-05,
      "loss": 0.1342,
      "step": 24700
    },
    {
      "epoch": 16.3265306122449,
      "grad_norm": 28.16242027282715,
      "learning_rate": 1.734825543120474e-05,
      "loss": 0.1779,
      "step": 24800
    },
    {
      "epoch": 16.392363396971692,
      "grad_norm": 1.5964174270629883,
      "learning_rate": 1.7216589861751155e-05,
      "loss": 0.1453,
      "step": 24900
    },
    {
      "epoch": 16.458196181698487,
      "grad_norm": 1.8991948366165161,
      "learning_rate": 1.7084924292297567e-05,
      "loss": 0.1465,
      "step": 25000
    },
    {
      "epoch": 16.52402896642528,
      "grad_norm": 2.699833393096924,
      "learning_rate": 1.6953258722843976e-05,
      "loss": 0.1447,
      "step": 25100
    },
    {
      "epoch": 16.589861751152075,
      "grad_norm": 1.6927480697631836,
      "learning_rate": 1.6821593153390388e-05,
      "loss": 0.1554,
      "step": 25200
    },
    {
      "epoch": 16.65569453587887,
      "grad_norm": 5.546261310577393,
      "learning_rate": 1.66899275839368e-05,
      "loss": 0.1538,
      "step": 25300
    },
    {
      "epoch": 16.721527320605663,
      "grad_norm": 1.4166339635849,
      "learning_rate": 1.6558262014483213e-05,
      "loss": 0.1473,
      "step": 25400
    },
    {
      "epoch": 16.787360105332457,
      "grad_norm": 2.391481637954712,
      "learning_rate": 1.6426596445029625e-05,
      "loss": 0.1575,
      "step": 25500
    },
    {
      "epoch": 16.85319289005925,
      "grad_norm": 2.7531516551971436,
      "learning_rate": 1.6294930875576037e-05,
      "loss": 0.1492,
      "step": 25600
    },
    {
      "epoch": 16.91902567478604,
      "grad_norm": 0.6849203109741211,
      "learning_rate": 1.616326530612245e-05,
      "loss": 0.1404,
      "step": 25700
    },
    {
      "epoch": 16.984858459512836,
      "grad_norm": 1.6381142139434814,
      "learning_rate": 1.6031599736668862e-05,
      "loss": 0.132,
      "step": 25800
    },
    {
      "epoch": 17.05069124423963,
      "grad_norm": 1.6918965578079224,
      "learning_rate": 1.5899934167215274e-05,
      "loss": 0.1422,
      "step": 25900
    },
    {
      "epoch": 17.116524028966424,
      "grad_norm": 8.044330596923828,
      "learning_rate": 1.5768268597761687e-05,
      "loss": 0.1444,
      "step": 26000
    },
    {
      "epoch": 17.116524028966424,
      "eval_f1_macro": 0.8637506183588706,
      "eval_iou_Block": 0.775145062462295,
      "eval_iou_unlabeled": 0.7435494528691236,
      "eval_loss": 0.6925837993621826,
      "eval_macro_precision": 0.8622894725029832,
      "eval_macro_recall": 0.8652167244317442,
      "eval_mean_accuracy": 0.8652167244317442,
      "eval_mean_iou": 0.7593472576657092,
      "eval_overall_accuracy": 0.8638844465846338,
      "eval_precision_Block": 0.8956744178181337,
      "eval_precision_unlabeled": 0.8289045271878326,
      "eval_recall_Block": 0.852076182969426,
      "eval_recall_unlabeled": 0.8783572658940625,
      "eval_runtime": 8.3429,
      "eval_samples_per_second": 47.226,
      "eval_steps_per_second": 11.866,
      "step": 26000
    },
    {
      "epoch": 17.182356813693218,
      "grad_norm": 1.2933942079544067,
      "learning_rate": 1.56366030283081e-05,
      "loss": 0.1451,
      "step": 26100
    },
    {
      "epoch": 17.248189598420012,
      "grad_norm": 0.7735565304756165,
      "learning_rate": 1.550493745885451e-05,
      "loss": 0.1423,
      "step": 26200
    },
    {
      "epoch": 17.314022383146806,
      "grad_norm": 3.211850643157959,
      "learning_rate": 1.5373271889400923e-05,
      "loss": 0.144,
      "step": 26300
    },
    {
      "epoch": 17.3798551678736,
      "grad_norm": 5.525993824005127,
      "learning_rate": 1.5241606319947336e-05,
      "loss": 0.1295,
      "step": 26400
    },
    {
      "epoch": 17.445687952600395,
      "grad_norm": 1.2795742750167847,
      "learning_rate": 1.5109940750493748e-05,
      "loss": 0.144,
      "step": 26500
    },
    {
      "epoch": 17.51152073732719,
      "grad_norm": 2.5219058990478516,
      "learning_rate": 1.4978275181040159e-05,
      "loss": 0.1548,
      "step": 26600
    },
    {
      "epoch": 17.577353522053983,
      "grad_norm": 0.7468212842941284,
      "learning_rate": 1.4846609611586571e-05,
      "loss": 0.1508,
      "step": 26700
    },
    {
      "epoch": 17.643186306780777,
      "grad_norm": 0.601524829864502,
      "learning_rate": 1.4714944042132983e-05,
      "loss": 0.128,
      "step": 26800
    },
    {
      "epoch": 17.70901909150757,
      "grad_norm": 5.397899150848389,
      "learning_rate": 1.4583278472679395e-05,
      "loss": 0.1438,
      "step": 26900
    },
    {
      "epoch": 17.774851876234365,
      "grad_norm": 6.670697212219238,
      "learning_rate": 1.4451612903225808e-05,
      "loss": 0.1433,
      "step": 27000
    },
    {
      "epoch": 17.84068466096116,
      "grad_norm": 1.5629452466964722,
      "learning_rate": 1.4319947333772218e-05,
      "loss": 0.1451,
      "step": 27100
    },
    {
      "epoch": 17.906517445687953,
      "grad_norm": 3.9582033157348633,
      "learning_rate": 1.418828176431863e-05,
      "loss": 0.1746,
      "step": 27200
    },
    {
      "epoch": 17.972350230414747,
      "grad_norm": 5.2170281410217285,
      "learning_rate": 1.4056616194865045e-05,
      "loss": 0.1418,
      "step": 27300
    },
    {
      "epoch": 18.03818301514154,
      "grad_norm": 64.26946258544922,
      "learning_rate": 1.3924950625411457e-05,
      "loss": 0.1295,
      "step": 27400
    },
    {
      "epoch": 18.104015799868336,
      "grad_norm": 2.900794267654419,
      "learning_rate": 1.3793285055957866e-05,
      "loss": 0.1304,
      "step": 27500
    },
    {
      "epoch": 18.16984858459513,
      "grad_norm": 0.4014522433280945,
      "learning_rate": 1.366161948650428e-05,
      "loss": 0.1463,
      "step": 27600
    },
    {
      "epoch": 18.235681369321924,
      "grad_norm": 1.8317524194717407,
      "learning_rate": 1.3529953917050692e-05,
      "loss": 0.1753,
      "step": 27700
    },
    {
      "epoch": 18.301514154048718,
      "grad_norm": 8.509689331054688,
      "learning_rate": 1.3398288347597104e-05,
      "loss": 0.1339,
      "step": 27800
    },
    {
      "epoch": 18.367346938775512,
      "grad_norm": 3.1235878467559814,
      "learning_rate": 1.3266622778143517e-05,
      "loss": 0.1498,
      "step": 27900
    },
    {
      "epoch": 18.433179723502302,
      "grad_norm": 32.358280181884766,
      "learning_rate": 1.3134957208689927e-05,
      "loss": 0.1456,
      "step": 28000
    },
    {
      "epoch": 18.433179723502302,
      "eval_f1_macro": 0.866075617974903,
      "eval_iou_Block": 0.7805366889213521,
      "eval_iou_unlabeled": 0.7463338505097191,
      "eval_loss": 0.632717490196228,
      "eval_macro_precision": 0.8649017979764273,
      "eval_macro_recall": 0.8672526284543103,
      "eval_mean_accuracy": 0.8672526284543103,
      "eval_mean_iou": 0.7634352697155355,
      "eval_overall_accuracy": 0.8666446124236595,
      "eval_precision_Block": 0.8927979092792627,
      "eval_precision_unlabeled": 0.8370056866735919,
      "eval_recall_Block": 0.8612556362519336,
      "eval_recall_unlabeled": 0.8732496206566871,
      "eval_runtime": 8.4299,
      "eval_samples_per_second": 46.739,
      "eval_steps_per_second": 11.744,
      "step": 28000
    },
    {
      "epoch": 18.499012508229097,
      "grad_norm": 1.0239760875701904,
      "learning_rate": 1.300329163923634e-05,
      "loss": 0.1289,
      "step": 28100
    },
    {
      "epoch": 18.56484529295589,
      "grad_norm": 1.4756873846054077,
      "learning_rate": 1.2871626069782752e-05,
      "loss": 0.1564,
      "step": 28200
    },
    {
      "epoch": 18.630678077682685,
      "grad_norm": 0.6529167294502258,
      "learning_rate": 1.2739960500329166e-05,
      "loss": 0.1267,
      "step": 28300
    },
    {
      "epoch": 18.69651086240948,
      "grad_norm": 6.502870559692383,
      "learning_rate": 1.2608294930875578e-05,
      "loss": 0.1941,
      "step": 28400
    },
    {
      "epoch": 18.762343647136273,
      "grad_norm": 3.65948748588562,
      "learning_rate": 1.2476629361421989e-05,
      "loss": 0.1342,
      "step": 28500
    },
    {
      "epoch": 18.828176431863067,
      "grad_norm": 1.3541624546051025,
      "learning_rate": 1.2344963791968401e-05,
      "loss": 0.1366,
      "step": 28600
    },
    {
      "epoch": 18.89400921658986,
      "grad_norm": 1.6223649978637695,
      "learning_rate": 1.2213298222514813e-05,
      "loss": 0.1361,
      "step": 28700
    },
    {
      "epoch": 18.959842001316655,
      "grad_norm": 3.444284439086914,
      "learning_rate": 1.2081632653061225e-05,
      "loss": 0.1289,
      "step": 28800
    },
    {
      "epoch": 19.02567478604345,
      "grad_norm": 1.043494701385498,
      "learning_rate": 1.1949967083607636e-05,
      "loss": 0.1338,
      "step": 28900
    },
    {
      "epoch": 19.091507570770244,
      "grad_norm": 1.106284260749817,
      "learning_rate": 1.181830151415405e-05,
      "loss": 0.1497,
      "step": 29000
    },
    {
      "epoch": 19.157340355497038,
      "grad_norm": 1.0545570850372314,
      "learning_rate": 1.168663594470046e-05,
      "loss": 0.129,
      "step": 29100
    },
    {
      "epoch": 19.22317314022383,
      "grad_norm": 1.8013097047805786,
      "learning_rate": 1.1554970375246873e-05,
      "loss": 0.1613,
      "step": 29200
    },
    {
      "epoch": 19.289005924950626,
      "grad_norm": 0.8048954606056213,
      "learning_rate": 1.1423304805793287e-05,
      "loss": 0.1242,
      "step": 29300
    },
    {
      "epoch": 19.35483870967742,
      "grad_norm": 0.8609532117843628,
      "learning_rate": 1.1291639236339698e-05,
      "loss": 0.1356,
      "step": 29400
    },
    {
      "epoch": 19.420671494404214,
      "grad_norm": 1.094378113746643,
      "learning_rate": 1.115997366688611e-05,
      "loss": 0.1286,
      "step": 29500
    },
    {
      "epoch": 19.486504279131008,
      "grad_norm": 2.9435532093048096,
      "learning_rate": 1.1028308097432522e-05,
      "loss": 0.1373,
      "step": 29600
    },
    {
      "epoch": 19.552337063857802,
      "grad_norm": 1.656419277191162,
      "learning_rate": 1.0896642527978934e-05,
      "loss": 0.1173,
      "step": 29700
    },
    {
      "epoch": 19.618169848584596,
      "grad_norm": 1.5447605848312378,
      "learning_rate": 1.0764976958525347e-05,
      "loss": 0.1274,
      "step": 29800
    },
    {
      "epoch": 19.68400263331139,
      "grad_norm": 1.5247318744659424,
      "learning_rate": 1.0633311389071757e-05,
      "loss": 0.137,
      "step": 29900
    },
    {
      "epoch": 19.749835418038185,
      "grad_norm": 0.642062783241272,
      "learning_rate": 1.0501645819618171e-05,
      "loss": 0.1537,
      "step": 30000
    },
    {
      "epoch": 19.749835418038185,
      "eval_f1_macro": 0.8670570412498253,
      "eval_iou_Block": 0.7805831289683228,
      "eval_iou_unlabeled": 0.7486774584058186,
      "eval_loss": 0.6691562533378601,
      "eval_macro_precision": 0.865662892346486,
      "eval_macro_recall": 0.8684556879476597,
      "eval_mean_accuracy": 0.8684556879476597,
      "eval_mean_iou": 0.7646302936870707,
      "eval_overall_accuracy": 0.8673121553992257,
      "eval_precision_Block": 0.8972850510264956,
      "eval_precision_unlabeled": 0.8340407336664764,
      "eval_recall_Block": 0.8571767817504288,
      "eval_recall_unlabeled": 0.8797345941448907,
      "eval_runtime": 8.35,
      "eval_samples_per_second": 47.185,
      "eval_steps_per_second": 11.856,
      "step": 30000
    },
    {
      "epoch": 19.81566820276498,
      "grad_norm": 1.6786842346191406,
      "learning_rate": 1.0369980250164582e-05,
      "loss": 0.1356,
      "step": 30100
    },
    {
      "epoch": 19.88150098749177,
      "grad_norm": 4.06010627746582,
      "learning_rate": 1.0238314680710994e-05,
      "loss": 0.1301,
      "step": 30200
    },
    {
      "epoch": 19.947333772218563,
      "grad_norm": 1.545228123664856,
      "learning_rate": 1.0106649111257406e-05,
      "loss": 0.1418,
      "step": 30300
    },
    {
      "epoch": 20.013166556945357,
      "grad_norm": 3.9002299308776855,
      "learning_rate": 9.974983541803819e-06,
      "loss": 0.1474,
      "step": 30400
    },
    {
      "epoch": 20.07899934167215,
      "grad_norm": 1.6774232387542725,
      "learning_rate": 9.843317972350231e-06,
      "loss": 0.121,
      "step": 30500
    },
    {
      "epoch": 20.144832126398946,
      "grad_norm": 2.438185691833496,
      "learning_rate": 9.711652402896643e-06,
      "loss": 0.1343,
      "step": 30600
    },
    {
      "epoch": 20.21066491112574,
      "grad_norm": 1.1280471086502075,
      "learning_rate": 9.579986833443056e-06,
      "loss": 0.1105,
      "step": 30700
    },
    {
      "epoch": 20.276497695852534,
      "grad_norm": 1.9233869314193726,
      "learning_rate": 9.448321263989466e-06,
      "loss": 0.1411,
      "step": 30800
    },
    {
      "epoch": 20.342330480579328,
      "grad_norm": 1.0672000646591187,
      "learning_rate": 9.31665569453588e-06,
      "loss": 0.1867,
      "step": 30900
    },
    {
      "epoch": 20.408163265306122,
      "grad_norm": 2.4837019443511963,
      "learning_rate": 9.184990125082292e-06,
      "loss": 0.1351,
      "step": 31000
    },
    {
      "epoch": 20.473996050032916,
      "grad_norm": 0.6904329061508179,
      "learning_rate": 9.053324555628703e-06,
      "loss": 0.1243,
      "step": 31100
    },
    {
      "epoch": 20.53982883475971,
      "grad_norm": 10.259819030761719,
      "learning_rate": 8.921658986175115e-06,
      "loss": 0.1199,
      "step": 31200
    },
    {
      "epoch": 20.605661619486504,
      "grad_norm": 2.0571770668029785,
      "learning_rate": 8.789993416721528e-06,
      "loss": 0.148,
      "step": 31300
    },
    {
      "epoch": 20.6714944042133,
      "grad_norm": 2.1030025482177734,
      "learning_rate": 8.65832784726794e-06,
      "loss": 0.126,
      "step": 31400
    },
    {
      "epoch": 20.737327188940093,
      "grad_norm": 1.9262175559997559,
      "learning_rate": 8.526662277814352e-06,
      "loss": 0.1195,
      "step": 31500
    },
    {
      "epoch": 20.803159973666887,
      "grad_norm": 8.323551177978516,
      "learning_rate": 8.394996708360764e-06,
      "loss": 0.1235,
      "step": 31600
    },
    {
      "epoch": 20.86899275839368,
      "grad_norm": 1.5806721448898315,
      "learning_rate": 8.263331138907177e-06,
      "loss": 0.1247,
      "step": 31700
    },
    {
      "epoch": 20.934825543120475,
      "grad_norm": 2.5607988834381104,
      "learning_rate": 8.131665569453587e-06,
      "loss": 0.1243,
      "step": 31800
    },
    {
      "epoch": 21.00065832784727,
      "grad_norm": 1.9843961000442505,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.1432,
      "step": 31900
    },
    {
      "epoch": 21.066491112574063,
      "grad_norm": 2.3295786380767822,
      "learning_rate": 7.868334430546412e-06,
      "loss": 0.1262,
      "step": 32000
    },
    {
      "epoch": 21.066491112574063,
      "eval_f1_macro": 0.8660956321950791,
      "eval_iou_Block": 0.7791345113216883,
      "eval_iou_unlabeled": 0.7471182835492588,
      "eval_loss": 0.7002121806144714,
      "eval_macro_precision": 0.8646991247616553,
      "eval_macro_recall": 0.8674966577045647,
      "eval_mean_accuracy": 0.8674966577045647,
      "eval_mean_iou": 0.7631263974354736,
      "eval_overall_accuracy": 0.866346978899186,
      "eval_precision_Block": 0.8964866881014543,
      "eval_precision_unlabeled": 0.8329115614218565,
      "eval_recall_Block": 0.856157129660026,
      "eval_recall_unlabeled": 0.8788361857491035,
      "eval_runtime": 8.493,
      "eval_samples_per_second": 46.391,
      "eval_steps_per_second": 11.657,
      "step": 32000
    },
    {
      "epoch": 21.132323897300857,
      "grad_norm": 1.1381741762161255,
      "learning_rate": 7.736668861092824e-06,
      "loss": 0.1164,
      "step": 32100
    },
    {
      "epoch": 21.19815668202765,
      "grad_norm": 0.9735715985298157,
      "learning_rate": 7.605003291639237e-06,
      "loss": 0.1435,
      "step": 32200
    },
    {
      "epoch": 21.263989466754445,
      "grad_norm": 2.491556167602539,
      "learning_rate": 7.473337722185649e-06,
      "loss": 0.13,
      "step": 32300
    },
    {
      "epoch": 21.32982225148124,
      "grad_norm": 1.4685380458831787,
      "learning_rate": 7.341672152732061e-06,
      "loss": 0.1394,
      "step": 32400
    },
    {
      "epoch": 21.39565503620803,
      "grad_norm": 1.8506852388381958,
      "learning_rate": 7.2100065832784725e-06,
      "loss": 0.1549,
      "step": 32500
    },
    {
      "epoch": 21.461487820934824,
      "grad_norm": 0.9151983857154846,
      "learning_rate": 7.078341013824885e-06,
      "loss": 0.113,
      "step": 32600
    },
    {
      "epoch": 21.527320605661618,
      "grad_norm": 2.0064542293548584,
      "learning_rate": 6.946675444371298e-06,
      "loss": 0.1239,
      "step": 32700
    },
    {
      "epoch": 21.593153390388412,
      "grad_norm": 2.3939566612243652,
      "learning_rate": 6.815009874917709e-06,
      "loss": 0.1175,
      "step": 32800
    },
    {
      "epoch": 21.658986175115206,
      "grad_norm": 1.42538583278656,
      "learning_rate": 6.683344305464122e-06,
      "loss": 0.114,
      "step": 32900
    },
    {
      "epoch": 21.724818959842,
      "grad_norm": 1.8097842931747437,
      "learning_rate": 6.551678736010533e-06,
      "loss": 0.1299,
      "step": 33000
    },
    {
      "epoch": 21.790651744568795,
      "grad_norm": 1.0934745073318481,
      "learning_rate": 6.420013166556945e-06,
      "loss": 0.1419,
      "step": 33100
    },
    {
      "epoch": 21.85648452929559,
      "grad_norm": 1.8669421672821045,
      "learning_rate": 6.2883475971033585e-06,
      "loss": 0.122,
      "step": 33200
    },
    {
      "epoch": 21.922317314022383,
      "grad_norm": 1.1054298877716064,
      "learning_rate": 6.15668202764977e-06,
      "loss": 0.1202,
      "step": 33300
    },
    {
      "epoch": 21.988150098749177,
      "grad_norm": 1.281319260597229,
      "learning_rate": 6.025016458196181e-06,
      "loss": 0.1356,
      "step": 33400
    },
    {
      "epoch": 22.05398288347597,
      "grad_norm": 1.1984935998916626,
      "learning_rate": 5.8933508887425945e-06,
      "loss": 0.1221,
      "step": 33500
    },
    {
      "epoch": 22.119815668202765,
      "grad_norm": 7.991922855377197,
      "learning_rate": 5.761685319289006e-06,
      "loss": 0.1586,
      "step": 33600
    },
    {
      "epoch": 22.18564845292956,
      "grad_norm": 22.8083553314209,
      "learning_rate": 5.630019749835418e-06,
      "loss": 0.1335,
      "step": 33700
    },
    {
      "epoch": 22.251481237656353,
      "grad_norm": 1.1337826251983643,
      "learning_rate": 5.4983541803818306e-06,
      "loss": 0.1199,
      "step": 33800
    },
    {
      "epoch": 22.317314022383147,
      "grad_norm": 1.4068431854248047,
      "learning_rate": 5.366688610928242e-06,
      "loss": 0.116,
      "step": 33900
    },
    {
      "epoch": 22.38314680710994,
      "grad_norm": 1.7330793142318726,
      "learning_rate": 5.235023041474655e-06,
      "loss": 0.1146,
      "step": 34000
    },
    {
      "epoch": 22.38314680710994,
      "eval_f1_macro": 0.8658089949039481,
      "eval_iou_Block": 0.7783084797678801,
      "eval_iou_unlabeled": 0.7468418826511375,
      "eval_loss": 0.7237179279327393,
      "eval_macro_precision": 0.864359631312611,
      "eval_macro_recall": 0.8672632272639891,
      "eval_mean_accuracy": 0.8672632272639891,
      "eval_mean_iou": 0.7625751812095087,
      "eval_overall_accuracy": 0.8659674262032291,
      "eval_precision_Block": 0.8972322960424094,
      "eval_precision_unlabeled": 0.8314869665828124,
      "eval_recall_Block": 0.8544824641500761,
      "eval_recall_unlabeled": 0.8800439903779022,
      "eval_runtime": 8.4221,
      "eval_samples_per_second": 46.782,
      "eval_steps_per_second": 11.755,
      "step": 34000
    },
    {
      "epoch": 22.448979591836736,
      "grad_norm": 260.6624755859375,
      "learning_rate": 5.103357472021067e-06,
      "loss": 0.1151,
      "step": 34100
    },
    {
      "epoch": 22.51481237656353,
      "grad_norm": 1.6015565395355225,
      "learning_rate": 4.971691902567479e-06,
      "loss": 0.1226,
      "step": 34200
    },
    {
      "epoch": 22.580645161290324,
      "grad_norm": 1.3781474828720093,
      "learning_rate": 4.840026333113891e-06,
      "loss": 0.129,
      "step": 34300
    },
    {
      "epoch": 22.646477946017118,
      "grad_norm": 2.360201358795166,
      "learning_rate": 4.708360763660303e-06,
      "loss": 0.1015,
      "step": 34400
    },
    {
      "epoch": 22.712310730743912,
      "grad_norm": 3.8958587646484375,
      "learning_rate": 4.576695194206715e-06,
      "loss": 0.1286,
      "step": 34500
    },
    {
      "epoch": 22.778143515470703,
      "grad_norm": 4.25031852722168,
      "learning_rate": 4.445029624753127e-06,
      "loss": 0.1276,
      "step": 34600
    },
    {
      "epoch": 22.843976300197497,
      "grad_norm": 1.627467393875122,
      "learning_rate": 4.3133640552995395e-06,
      "loss": 0.1457,
      "step": 34700
    },
    {
      "epoch": 22.90980908492429,
      "grad_norm": 1.4548380374908447,
      "learning_rate": 4.181698485845952e-06,
      "loss": 0.1294,
      "step": 34800
    },
    {
      "epoch": 22.975641869651085,
      "grad_norm": 1.8879320621490479,
      "learning_rate": 4.050032916392363e-06,
      "loss": 0.1267,
      "step": 34900
    },
    {
      "epoch": 23.04147465437788,
      "grad_norm": 1.2395133972167969,
      "learning_rate": 3.9183673469387755e-06,
      "loss": 0.1123,
      "step": 35000
    },
    {
      "epoch": 23.107307439104673,
      "grad_norm": 0.8494159579277039,
      "learning_rate": 3.7867017774851873e-06,
      "loss": 0.1436,
      "step": 35100
    },
    {
      "epoch": 23.173140223831467,
      "grad_norm": 6.950567245483398,
      "learning_rate": 3.6550362080316e-06,
      "loss": 0.1257,
      "step": 35200
    },
    {
      "epoch": 23.23897300855826,
      "grad_norm": 3.133898973464966,
      "learning_rate": 3.5233706385780123e-06,
      "loss": 0.1302,
      "step": 35300
    },
    {
      "epoch": 23.304805793285055,
      "grad_norm": 0.7396064400672913,
      "learning_rate": 3.391705069124424e-06,
      "loss": 0.1269,
      "step": 35400
    },
    {
      "epoch": 23.37063857801185,
      "grad_norm": 2.603379487991333,
      "learning_rate": 3.260039499670836e-06,
      "loss": 0.127,
      "step": 35500
    },
    {
      "epoch": 23.436471362738644,
      "grad_norm": 4.031406402587891,
      "learning_rate": 3.128373930217248e-06,
      "loss": 0.1068,
      "step": 35600
    },
    {
      "epoch": 23.502304147465438,
      "grad_norm": 0.8840509057044983,
      "learning_rate": 2.9967083607636602e-06,
      "loss": 0.1285,
      "step": 35700
    },
    {
      "epoch": 23.568136932192232,
      "grad_norm": 1.1477909088134766,
      "learning_rate": 2.8650427913100725e-06,
      "loss": 0.1171,
      "step": 35800
    },
    {
      "epoch": 23.633969716919026,
      "grad_norm": 4.8663458824157715,
      "learning_rate": 2.733377221856485e-06,
      "loss": 0.1108,
      "step": 35900
    },
    {
      "epoch": 23.69980250164582,
      "grad_norm": 2.285778760910034,
      "learning_rate": 2.6017116524028967e-06,
      "loss": 0.1301,
      "step": 36000
    },
    {
      "epoch": 23.69980250164582,
      "eval_f1_macro": 0.8654569987889253,
      "eval_iou_Block": 0.7765128600866679,
      "eval_iou_unlabeled": 0.7468252150535433,
      "eval_loss": 0.6756904125213623,
      "eval_macro_precision": 0.8638638525409963,
      "eval_macro_recall": 0.8670560320868994,
      "eval_mean_accuracy": 0.8670560320868994,
      "eval_mean_iou": 0.7616690375701056,
      "eval_overall_accuracy": 0.8653084517735515,
      "eval_precision_Block": 0.9000188043078194,
      "eval_precision_unlabeled": 0.8277089007741733,
      "eval_recall_Block": 0.8498192735413117,
      "eval_recall_unlabeled": 0.8842927906324871,
      "eval_runtime": 8.3634,
      "eval_samples_per_second": 47.11,
      "eval_steps_per_second": 11.837,
      "step": 36000
    },
    {
      "epoch": 23.765635286372614,
      "grad_norm": 8.556106567382812,
      "learning_rate": 2.470046082949309e-06,
      "loss": 0.1293,
      "step": 36100
    },
    {
      "epoch": 23.83146807109941,
      "grad_norm": 25.744571685791016,
      "learning_rate": 2.3383805134957212e-06,
      "loss": 0.154,
      "step": 36200
    },
    {
      "epoch": 23.897300855826202,
      "grad_norm": 2.6428534984588623,
      "learning_rate": 2.206714944042133e-06,
      "loss": 0.1442,
      "step": 36300
    },
    {
      "epoch": 23.963133640552996,
      "grad_norm": 1.3869425058364868,
      "learning_rate": 2.0750493745885454e-06,
      "loss": 0.122,
      "step": 36400
    },
    {
      "epoch": 24.02896642527979,
      "grad_norm": 3.844515800476074,
      "learning_rate": 1.9433838051349572e-06,
      "loss": 0.1211,
      "step": 36500
    },
    {
      "epoch": 24.094799210006585,
      "grad_norm": 1.729252576828003,
      "learning_rate": 1.8117182356813693e-06,
      "loss": 0.1149,
      "step": 36600
    },
    {
      "epoch": 24.16063199473338,
      "grad_norm": 7.563381671905518,
      "learning_rate": 1.6800526662277816e-06,
      "loss": 0.1228,
      "step": 36700
    },
    {
      "epoch": 24.226464779460173,
      "grad_norm": 22.361906051635742,
      "learning_rate": 1.5483870967741937e-06,
      "loss": 0.1129,
      "step": 36800
    },
    {
      "epoch": 24.292297564186963,
      "grad_norm": 3.042412042617798,
      "learning_rate": 1.4167215273206058e-06,
      "loss": 0.1085,
      "step": 36900
    },
    {
      "epoch": 24.358130348913758,
      "grad_norm": 0.8861579895019531,
      "learning_rate": 1.2850559578670178e-06,
      "loss": 0.1067,
      "step": 37000
    },
    {
      "epoch": 24.42396313364055,
      "grad_norm": 2.0340683460235596,
      "learning_rate": 1.15339038841343e-06,
      "loss": 0.1315,
      "step": 37100
    },
    {
      "epoch": 24.489795918367346,
      "grad_norm": 2.1406090259552,
      "learning_rate": 1.021724818959842e-06,
      "loss": 0.1075,
      "step": 37200
    },
    {
      "epoch": 24.55562870309414,
      "grad_norm": 0.564964771270752,
      "learning_rate": 8.900592495062543e-07,
      "loss": 0.123,
      "step": 37300
    },
    {
      "epoch": 24.621461487820934,
      "grad_norm": 0.8774010539054871,
      "learning_rate": 7.583936800526664e-07,
      "loss": 0.1377,
      "step": 37400
    },
    {
      "epoch": 24.687294272547728,
      "grad_norm": 3.0434515476226807,
      "learning_rate": 6.267281105990783e-07,
      "loss": 0.1174,
      "step": 37500
    },
    {
      "epoch": 24.753127057274522,
      "grad_norm": 0.9941107034683228,
      "learning_rate": 4.950625411454904e-07,
      "loss": 0.1313,
      "step": 37600
    },
    {
      "epoch": 24.818959842001316,
      "grad_norm": 2.778174877166748,
      "learning_rate": 3.633969716919026e-07,
      "loss": 0.1148,
      "step": 37700
    },
    {
      "epoch": 24.88479262672811,
      "grad_norm": 3.462442636489868,
      "learning_rate": 2.317314022383147e-07,
      "loss": 0.103,
      "step": 37800
    },
    {
      "epoch": 24.950625411454904,
      "grad_norm": 0.7345640659332275,
      "learning_rate": 1.000658327847268e-07,
      "loss": 0.1236,
      "step": 37900
    }
  ],
  "logging_steps": 100,
  "max_steps": 37975,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 25,
  "save_steps": 2000,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 30,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 3
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.6616200459452416e+18,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
