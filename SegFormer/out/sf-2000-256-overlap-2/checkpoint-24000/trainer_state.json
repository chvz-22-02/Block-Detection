{
  "best_global_step": 24000,
  "best_metric": 0.7833962394540589,
  "best_model_checkpoint": "out/sf-2000-256-overlap-2\\checkpoint-24000",
  "epoch": 21.798365122615802,
  "eval_steps": 2000,
  "global_step": 24000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.09082652134423251,
      "grad_norm": 8.526172637939453,
      "learning_rate": 4.982016348773842e-05,
      "loss": 0.5473,
      "step": 100
    },
    {
      "epoch": 0.18165304268846502,
      "grad_norm": 2.7600388526916504,
      "learning_rate": 4.963851044504996e-05,
      "loss": 0.4619,
      "step": 200
    },
    {
      "epoch": 0.2724795640326976,
      "grad_norm": 4.226351737976074,
      "learning_rate": 4.945685740236149e-05,
      "loss": 0.4459,
      "step": 300
    },
    {
      "epoch": 0.36330608537693004,
      "grad_norm": 1.4779093265533447,
      "learning_rate": 4.927520435967303e-05,
      "loss": 0.4241,
      "step": 400
    },
    {
      "epoch": 0.45413260672116257,
      "grad_norm": 11.566169738769531,
      "learning_rate": 4.909355131698456e-05,
      "loss": 0.4633,
      "step": 500
    },
    {
      "epoch": 0.5449591280653951,
      "grad_norm": 8.289678573608398,
      "learning_rate": 4.89118982742961e-05,
      "loss": 0.4201,
      "step": 600
    },
    {
      "epoch": 0.6357856494096276,
      "grad_norm": 1.561997413635254,
      "learning_rate": 4.873024523160763e-05,
      "loss": 0.4108,
      "step": 700
    },
    {
      "epoch": 0.7266121707538601,
      "grad_norm": 3.0128846168518066,
      "learning_rate": 4.854859218891917e-05,
      "loss": 0.4327,
      "step": 800
    },
    {
      "epoch": 0.8174386920980926,
      "grad_norm": 4.781454563140869,
      "learning_rate": 4.83669391462307e-05,
      "loss": 0.407,
      "step": 900
    },
    {
      "epoch": 0.9082652134423251,
      "grad_norm": 25.563251495361328,
      "learning_rate": 4.818528610354224e-05,
      "loss": 0.4144,
      "step": 1000
    },
    {
      "epoch": 0.9990917347865577,
      "grad_norm": 5.055729866027832,
      "learning_rate": 4.800363306085377e-05,
      "loss": 0.411,
      "step": 1100
    },
    {
      "epoch": 1.0899182561307903,
      "grad_norm": 3.1879260540008545,
      "learning_rate": 4.782198001816531e-05,
      "loss": 0.377,
      "step": 1200
    },
    {
      "epoch": 1.1807447774750228,
      "grad_norm": 3.1370701789855957,
      "learning_rate": 4.764032697547684e-05,
      "loss": 0.4247,
      "step": 1300
    },
    {
      "epoch": 1.2715712988192553,
      "grad_norm": 3.5804738998413086,
      "learning_rate": 4.745867393278838e-05,
      "loss": 0.4035,
      "step": 1400
    },
    {
      "epoch": 1.3623978201634879,
      "grad_norm": 0.7387668490409851,
      "learning_rate": 4.727702089009991e-05,
      "loss": 0.3652,
      "step": 1500
    },
    {
      "epoch": 1.4532243415077202,
      "grad_norm": 4.596427917480469,
      "learning_rate": 4.709536784741145e-05,
      "loss": 0.3874,
      "step": 1600
    },
    {
      "epoch": 1.544050862851953,
      "grad_norm": 1.4554258584976196,
      "learning_rate": 4.6913714804722983e-05,
      "loss": 0.3912,
      "step": 1700
    },
    {
      "epoch": 1.6348773841961854,
      "grad_norm": 5.531268119812012,
      "learning_rate": 4.673206176203452e-05,
      "loss": 0.3994,
      "step": 1800
    },
    {
      "epoch": 1.7257039055404177,
      "grad_norm": 4.0310187339782715,
      "learning_rate": 4.6550408719346053e-05,
      "loss": 0.3678,
      "step": 1900
    },
    {
      "epoch": 1.8165304268846503,
      "grad_norm": 2.3541340827941895,
      "learning_rate": 4.636875567665759e-05,
      "loss": 0.3366,
      "step": 2000
    },
    {
      "epoch": 1.8165304268846503,
      "eval_f1_macro": 0.8540803270486875,
      "eval_iou_Block": 0.729147594602664,
      "eval_iou_unlabeled": 0.7615344154133674,
      "eval_loss": 0.32755082845687866,
      "eval_macro_precision": 0.8535604999954701,
      "eval_macro_recall": 0.8546007876487005,
      "eval_mean_accuracy": 0.8546007876487005,
      "eval_mean_iou": 0.7453410050080157,
      "eval_overall_accuracy": 0.8547677904259857,
      "eval_precision_Block": 0.8343337531020597,
      "eval_precision_unlabeled": 0.8727872468888805,
      "eval_recall_Block": 0.8525851896887054,
      "eval_recall_unlabeled": 0.8566163856086956,
      "eval_runtime": 992.3441,
      "eval_samples_per_second": 1.396,
      "eval_steps_per_second": 0.35,
      "step": 2000
    },
    {
      "epoch": 1.9073569482288828,
      "grad_norm": 1.4205000400543213,
      "learning_rate": 4.6187102633969123e-05,
      "loss": 0.3706,
      "step": 2100
    },
    {
      "epoch": 1.9981834695731153,
      "grad_norm": 0.8839593529701233,
      "learning_rate": 4.600544959128066e-05,
      "loss": 0.4067,
      "step": 2200
    },
    {
      "epoch": 2.089009990917348,
      "grad_norm": 2.0553138256073,
      "learning_rate": 4.5823796548592193e-05,
      "loss": 0.3174,
      "step": 2300
    },
    {
      "epoch": 2.1798365122615806,
      "grad_norm": 2.259276866912842,
      "learning_rate": 4.564214350590373e-05,
      "loss": 0.3641,
      "step": 2400
    },
    {
      "epoch": 2.270663033605813,
      "grad_norm": 8.245923042297363,
      "learning_rate": 4.5460490463215263e-05,
      "loss": 0.3434,
      "step": 2500
    },
    {
      "epoch": 2.3614895549500456,
      "grad_norm": 4.470372676849365,
      "learning_rate": 4.52788374205268e-05,
      "loss": 0.3843,
      "step": 2600
    },
    {
      "epoch": 2.452316076294278,
      "grad_norm": 4.1141438484191895,
      "learning_rate": 4.5097184377838333e-05,
      "loss": 0.352,
      "step": 2700
    },
    {
      "epoch": 2.5431425976385107,
      "grad_norm": 7.569090843200684,
      "learning_rate": 4.491553133514987e-05,
      "loss": 0.366,
      "step": 2800
    },
    {
      "epoch": 2.633969118982743,
      "grad_norm": 37.529605865478516,
      "learning_rate": 4.4733878292461403e-05,
      "loss": 0.3403,
      "step": 2900
    },
    {
      "epoch": 2.7247956403269757,
      "grad_norm": 4.323421955108643,
      "learning_rate": 4.455222524977293e-05,
      "loss": 0.3743,
      "step": 3000
    },
    {
      "epoch": 2.8156221616712083,
      "grad_norm": 14.64501667022705,
      "learning_rate": 4.4370572207084473e-05,
      "loss": 0.3645,
      "step": 3100
    },
    {
      "epoch": 2.9064486830154403,
      "grad_norm": 4.40239143371582,
      "learning_rate": 4.4188919164396e-05,
      "loss": 0.3375,
      "step": 3200
    },
    {
      "epoch": 2.997275204359673,
      "grad_norm": 4.692040920257568,
      "learning_rate": 4.4007266121707543e-05,
      "loss": 0.361,
      "step": 3300
    },
    {
      "epoch": 3.0881017257039054,
      "grad_norm": 3.105687379837036,
      "learning_rate": 4.382561307901907e-05,
      "loss": 0.3494,
      "step": 3400
    },
    {
      "epoch": 3.178928247048138,
      "grad_norm": 2.4704678058624268,
      "learning_rate": 4.3643960036330613e-05,
      "loss": 0.3292,
      "step": 3500
    },
    {
      "epoch": 3.2697547683923704,
      "grad_norm": 12.026129722595215,
      "learning_rate": 4.346230699364214e-05,
      "loss": 0.3392,
      "step": 3600
    },
    {
      "epoch": 3.360581289736603,
      "grad_norm": 5.920993804931641,
      "learning_rate": 4.3280653950953683e-05,
      "loss": 0.2991,
      "step": 3700
    },
    {
      "epoch": 3.4514078110808355,
      "grad_norm": 1.3242955207824707,
      "learning_rate": 4.309900090826521e-05,
      "loss": 0.3098,
      "step": 3800
    },
    {
      "epoch": 3.542234332425068,
      "grad_norm": 5.141322135925293,
      "learning_rate": 4.2917347865576753e-05,
      "loss": 0.3145,
      "step": 3900
    },
    {
      "epoch": 3.6330608537693005,
      "grad_norm": 19.69380760192871,
      "learning_rate": 4.273569482288828e-05,
      "loss": 0.3153,
      "step": 4000
    },
    {
      "epoch": 3.6330608537693005,
      "eval_f1_macro": 0.8528807754679291,
      "eval_iou_Block": 0.7322198412914956,
      "eval_iou_unlabeled": 0.7499404360480578,
      "eval_loss": 0.37353283166885376,
      "eval_macro_precision": 0.8516702477772456,
      "eval_macro_recall": 0.8540947492423757,
      "eval_mean_accuracy": 0.8540947492423757,
      "eval_mean_iou": 0.7410801386697767,
      "eval_overall_accuracy": 0.8514878062995332,
      "eval_precision_Block": 0.8087478727357211,
      "eval_precision_unlabeled": 0.8945926228187702,
      "eval_recall_Block": 0.8855585905199589,
      "eval_recall_unlabeled": 0.8226309079647925,
      "eval_runtime": 43.4567,
      "eval_samples_per_second": 31.871,
      "eval_steps_per_second": 7.985,
      "step": 4000
    },
    {
      "epoch": 3.723887375113533,
      "grad_norm": 1.5550295114517212,
      "learning_rate": 4.2554041780199823e-05,
      "loss": 0.3201,
      "step": 4100
    },
    {
      "epoch": 3.8147138964577656,
      "grad_norm": 4.980742454528809,
      "learning_rate": 4.237238873751135e-05,
      "loss": 0.3088,
      "step": 4200
    },
    {
      "epoch": 3.905540417801998,
      "grad_norm": 7.849128723144531,
      "learning_rate": 4.219073569482289e-05,
      "loss": 0.3353,
      "step": 4300
    },
    {
      "epoch": 3.9963669391462306,
      "grad_norm": 20.990663528442383,
      "learning_rate": 4.200908265213442e-05,
      "loss": 0.3198,
      "step": 4400
    },
    {
      "epoch": 4.087193460490464,
      "grad_norm": 9.94265079498291,
      "learning_rate": 4.182742960944596e-05,
      "loss": 0.2931,
      "step": 4500
    },
    {
      "epoch": 4.178019981834696,
      "grad_norm": 0.5067456960678101,
      "learning_rate": 4.164577656675749e-05,
      "loss": 0.2804,
      "step": 4600
    },
    {
      "epoch": 4.268846503178928,
      "grad_norm": 21.21889877319336,
      "learning_rate": 4.146412352406903e-05,
      "loss": 0.3032,
      "step": 4700
    },
    {
      "epoch": 4.359673024523161,
      "grad_norm": 1.1444532871246338,
      "learning_rate": 4.128247048138056e-05,
      "loss": 0.3209,
      "step": 4800
    },
    {
      "epoch": 4.450499545867393,
      "grad_norm": 17.74746322631836,
      "learning_rate": 4.11008174386921e-05,
      "loss": 0.287,
      "step": 4900
    },
    {
      "epoch": 4.541326067211626,
      "grad_norm": 20.29314613342285,
      "learning_rate": 4.091916439600363e-05,
      "loss": 0.2699,
      "step": 5000
    },
    {
      "epoch": 4.632152588555858,
      "grad_norm": 0.6932498216629028,
      "learning_rate": 4.073751135331517e-05,
      "loss": 0.2988,
      "step": 5100
    },
    {
      "epoch": 4.722979109900091,
      "grad_norm": 10.10067081451416,
      "learning_rate": 4.05558583106267e-05,
      "loss": 0.3181,
      "step": 5200
    },
    {
      "epoch": 4.813805631244323,
      "grad_norm": 16.13100242614746,
      "learning_rate": 4.037420526793824e-05,
      "loss": 0.2745,
      "step": 5300
    },
    {
      "epoch": 4.904632152588556,
      "grad_norm": 3.106036424636841,
      "learning_rate": 4.019255222524977e-05,
      "loss": 0.3165,
      "step": 5400
    },
    {
      "epoch": 4.995458673932788,
      "grad_norm": 2.7179768085479736,
      "learning_rate": 4.001089918256131e-05,
      "loss": 0.3335,
      "step": 5500
    },
    {
      "epoch": 5.0862851952770205,
      "grad_norm": 1.4295713901519775,
      "learning_rate": 3.982924613987284e-05,
      "loss": 0.2603,
      "step": 5600
    },
    {
      "epoch": 5.177111716621253,
      "grad_norm": 13.049595832824707,
      "learning_rate": 3.964759309718438e-05,
      "loss": 0.2823,
      "step": 5700
    },
    {
      "epoch": 5.2679382379654855,
      "grad_norm": 11.115368843078613,
      "learning_rate": 3.946594005449591e-05,
      "loss": 0.2886,
      "step": 5800
    },
    {
      "epoch": 5.358764759309718,
      "grad_norm": 6.314699172973633,
      "learning_rate": 3.928428701180745e-05,
      "loss": 0.2821,
      "step": 5900
    },
    {
      "epoch": 5.449591280653951,
      "grad_norm": 0.9361520409584045,
      "learning_rate": 3.910263396911898e-05,
      "loss": 0.2607,
      "step": 6000
    },
    {
      "epoch": 5.449591280653951,
      "eval_f1_macro": 0.8712354430248688,
      "eval_iou_Block": 0.7476084183101744,
      "eval_iou_unlabeled": 0.7939647573794419,
      "eval_loss": 0.3620382845401764,
      "eval_macro_precision": 0.8739236972388553,
      "eval_macro_recall": 0.868563676633442,
      "eval_mean_accuracy": 0.868563676633442,
      "eval_mean_iou": 0.7707865878448081,
      "eval_overall_accuracy": 0.8720513574483162,
      "eval_precision_Block": 0.8868130773087617,
      "eval_precision_unlabeled": 0.8610343171689488,
      "eval_recall_Block": 0.8264699914274195,
      "eval_recall_unlabeled": 0.9106573618394646,
      "eval_runtime": 45.3229,
      "eval_samples_per_second": 30.559,
      "eval_steps_per_second": 7.656,
      "step": 6000
    },
    {
      "epoch": 5.540417801998183,
      "grad_norm": 2.6930060386657715,
      "learning_rate": 3.8920980926430517e-05,
      "loss": 0.2706,
      "step": 6100
    },
    {
      "epoch": 5.631244323342416,
      "grad_norm": 11.43631649017334,
      "learning_rate": 3.873932788374205e-05,
      "loss": 0.2732,
      "step": 6200
    },
    {
      "epoch": 5.722070844686648,
      "grad_norm": 23.561845779418945,
      "learning_rate": 3.8557674841053587e-05,
      "loss": 0.3072,
      "step": 6300
    },
    {
      "epoch": 5.812897366030881,
      "grad_norm": 4.17338752746582,
      "learning_rate": 3.837602179836512e-05,
      "loss": 0.2637,
      "step": 6400
    },
    {
      "epoch": 5.903723887375113,
      "grad_norm": 53.47994613647461,
      "learning_rate": 3.8194368755676657e-05,
      "loss": 0.2868,
      "step": 6500
    },
    {
      "epoch": 5.994550408719346,
      "grad_norm": 3.3449058532714844,
      "learning_rate": 3.80127157129882e-05,
      "loss": 0.2816,
      "step": 6600
    },
    {
      "epoch": 6.085376930063578,
      "grad_norm": 1.8416225910186768,
      "learning_rate": 3.7831062670299727e-05,
      "loss": 0.2827,
      "step": 6700
    },
    {
      "epoch": 6.176203451407811,
      "grad_norm": 2.8344764709472656,
      "learning_rate": 3.764940962761127e-05,
      "loss": 0.2856,
      "step": 6800
    },
    {
      "epoch": 6.267029972752043,
      "grad_norm": 2.7433202266693115,
      "learning_rate": 3.7467756584922797e-05,
      "loss": 0.2506,
      "step": 6900
    },
    {
      "epoch": 6.357856494096276,
      "grad_norm": 3.0606396198272705,
      "learning_rate": 3.728610354223434e-05,
      "loss": 0.2713,
      "step": 7000
    },
    {
      "epoch": 6.448683015440508,
      "grad_norm": 12.291847229003906,
      "learning_rate": 3.7104450499545867e-05,
      "loss": 0.26,
      "step": 7100
    },
    {
      "epoch": 6.539509536784741,
      "grad_norm": 2.918443202972412,
      "learning_rate": 3.692279745685741e-05,
      "loss": 0.239,
      "step": 7200
    },
    {
      "epoch": 6.630336058128973,
      "grad_norm": 5.0197434425354,
      "learning_rate": 3.6741144414168937e-05,
      "loss": 0.2604,
      "step": 7300
    },
    {
      "epoch": 6.721162579473206,
      "grad_norm": 3.187291383743286,
      "learning_rate": 3.655949137148048e-05,
      "loss": 0.2706,
      "step": 7400
    },
    {
      "epoch": 6.8119891008174385,
      "grad_norm": 1.7081246376037598,
      "learning_rate": 3.6377838328792006e-05,
      "loss": 0.2252,
      "step": 7500
    },
    {
      "epoch": 6.902815622161671,
      "grad_norm": 14.995336532592773,
      "learning_rate": 3.619618528610355e-05,
      "loss": 0.2416,
      "step": 7600
    },
    {
      "epoch": 6.9936421435059035,
      "grad_norm": 5.577857494354248,
      "learning_rate": 3.6014532243415076e-05,
      "loss": 0.2533,
      "step": 7700
    },
    {
      "epoch": 7.084468664850136,
      "grad_norm": 2.5856246948242188,
      "learning_rate": 3.583287920072662e-05,
      "loss": 0.2211,
      "step": 7800
    },
    {
      "epoch": 7.175295186194369,
      "grad_norm": 2.624540090560913,
      "learning_rate": 3.5651226158038146e-05,
      "loss": 0.1981,
      "step": 7900
    },
    {
      "epoch": 7.266121707538601,
      "grad_norm": 9.565502166748047,
      "learning_rate": 3.546957311534969e-05,
      "loss": 0.2576,
      "step": 8000
    },
    {
      "epoch": 7.266121707538601,
      "eval_f1_macro": 0.8684857545466356,
      "eval_iou_Block": 0.7543236589898387,
      "eval_iou_unlabeled": 0.7797165920779554,
      "eval_loss": 0.362540066242218,
      "eval_macro_precision": 0.8675194846692016,
      "eval_macro_recall": 0.8694541793474936,
      "eval_mean_accuracy": 0.8694541793474936,
      "eval_mean_iou": 0.7670201255338971,
      "eval_overall_accuracy": 0.8685939995390414,
      "eval_precision_Block": 0.8409613375370568,
      "eval_precision_unlabeled": 0.8940776318013463,
      "eval_recall_Block": 0.8798359029052067,
      "eval_recall_unlabeled": 0.8590724557897804,
      "eval_runtime": 44.4007,
      "eval_samples_per_second": 31.193,
      "eval_steps_per_second": 7.815,
      "step": 8000
    },
    {
      "epoch": 7.356948228882834,
      "grad_norm": 4.1709113121032715,
      "learning_rate": 3.5287920072661216e-05,
      "loss": 0.2219,
      "step": 8100
    },
    {
      "epoch": 7.447774750227066,
      "grad_norm": 0.8522440195083618,
      "learning_rate": 3.510626702997276e-05,
      "loss": 0.2181,
      "step": 8200
    },
    {
      "epoch": 7.538601271571299,
      "grad_norm": 2.15694260597229,
      "learning_rate": 3.4924613987284286e-05,
      "loss": 0.2543,
      "step": 8300
    },
    {
      "epoch": 7.629427792915531,
      "grad_norm": 1.0811139345169067,
      "learning_rate": 3.474296094459583e-05,
      "loss": 0.2195,
      "step": 8400
    },
    {
      "epoch": 7.720254314259764,
      "grad_norm": 5.249212265014648,
      "learning_rate": 3.4561307901907356e-05,
      "loss": 0.2422,
      "step": 8500
    },
    {
      "epoch": 7.811080835603996,
      "grad_norm": 1.389992117881775,
      "learning_rate": 3.43796548592189e-05,
      "loss": 0.2383,
      "step": 8600
    },
    {
      "epoch": 7.901907356948229,
      "grad_norm": 1.6892869472503662,
      "learning_rate": 3.4198001816530426e-05,
      "loss": 0.2281,
      "step": 8700
    },
    {
      "epoch": 7.992733878292461,
      "grad_norm": 49.28996658325195,
      "learning_rate": 3.401634877384197e-05,
      "loss": 0.2113,
      "step": 8800
    },
    {
      "epoch": 8.083560399636694,
      "grad_norm": 5.133399963378906,
      "learning_rate": 3.3834695731153496e-05,
      "loss": 0.2141,
      "step": 8900
    },
    {
      "epoch": 8.174386920980927,
      "grad_norm": 2.4291398525238037,
      "learning_rate": 3.365304268846503e-05,
      "loss": 0.2314,
      "step": 9000
    },
    {
      "epoch": 8.265213442325159,
      "grad_norm": 2.962045192718506,
      "learning_rate": 3.3471389645776566e-05,
      "loss": 0.2148,
      "step": 9100
    },
    {
      "epoch": 8.356039963669392,
      "grad_norm": 63.47797775268555,
      "learning_rate": 3.32897366030881e-05,
      "loss": 0.2086,
      "step": 9200
    },
    {
      "epoch": 8.446866485013624,
      "grad_norm": 2.610826253890991,
      "learning_rate": 3.3108083560399636e-05,
      "loss": 0.2102,
      "step": 9300
    },
    {
      "epoch": 8.537693006357856,
      "grad_norm": 12.843141555786133,
      "learning_rate": 3.292643051771117e-05,
      "loss": 0.2092,
      "step": 9400
    },
    {
      "epoch": 8.628519527702089,
      "grad_norm": 3.4804129600524902,
      "learning_rate": 3.2744777475022706e-05,
      "loss": 0.1951,
      "step": 9500
    },
    {
      "epoch": 8.719346049046322,
      "grad_norm": 3.4914016723632812,
      "learning_rate": 3.256312443233424e-05,
      "loss": 0.2291,
      "step": 9600
    },
    {
      "epoch": 8.810172570390554,
      "grad_norm": 17.894670486450195,
      "learning_rate": 3.2381471389645776e-05,
      "loss": 0.2192,
      "step": 9700
    },
    {
      "epoch": 8.900999091734786,
      "grad_norm": 0.8733909130096436,
      "learning_rate": 3.219981834695731e-05,
      "loss": 0.2381,
      "step": 9800
    },
    {
      "epoch": 8.991825613079019,
      "grad_norm": 9.95828914642334,
      "learning_rate": 3.2018165304268846e-05,
      "loss": 0.2109,
      "step": 9900
    },
    {
      "epoch": 9.082652134423252,
      "grad_norm": 4.145860195159912,
      "learning_rate": 3.183651226158038e-05,
      "loss": 0.2136,
      "step": 10000
    },
    {
      "epoch": 9.082652134423252,
      "eval_f1_macro": 0.8702085351063221,
      "eval_iou_Block": 0.7471728687745698,
      "eval_iou_unlabeled": 0.7918861114293235,
      "eval_loss": 0.4297340512275696,
      "eval_macro_precision": 0.8724025435995826,
      "eval_macro_recall": 0.8680255343713066,
      "eval_mean_accuracy": 0.8680255343713066,
      "eval_mean_iou": 0.7695294901019467,
      "eval_overall_accuracy": 0.871139551155834,
      "eval_precision_Block": 0.8816787935677934,
      "eval_precision_unlabeled": 0.8631262936313718,
      "eval_recall_Block": 0.8304416930704805,
      "eval_recall_unlabeled": 0.9056093756721325,
      "eval_runtime": 43.266,
      "eval_samples_per_second": 32.011,
      "eval_steps_per_second": 8.02,
      "step": 10000
    },
    {
      "epoch": 9.173478655767484,
      "grad_norm": 7.057398319244385,
      "learning_rate": 3.1654859218891916e-05,
      "loss": 0.2055,
      "step": 10100
    },
    {
      "epoch": 9.264305177111716,
      "grad_norm": 9.001239776611328,
      "learning_rate": 3.147320617620345e-05,
      "loss": 0.2228,
      "step": 10200
    },
    {
      "epoch": 9.35513169845595,
      "grad_norm": 1.2431519031524658,
      "learning_rate": 3.1291553133514986e-05,
      "loss": 0.211,
      "step": 10300
    },
    {
      "epoch": 9.44595821980018,
      "grad_norm": 0.8346874713897705,
      "learning_rate": 3.110990009082652e-05,
      "loss": 0.2017,
      "step": 10400
    },
    {
      "epoch": 9.536784741144414,
      "grad_norm": 2.1647400856018066,
      "learning_rate": 3.0928247048138056e-05,
      "loss": 0.2221,
      "step": 10500
    },
    {
      "epoch": 9.627611262488646,
      "grad_norm": 4.712480068206787,
      "learning_rate": 3.074659400544959e-05,
      "loss": 0.2263,
      "step": 10600
    },
    {
      "epoch": 9.71843778383288,
      "grad_norm": 0.8934444785118103,
      "learning_rate": 3.0564940962761126e-05,
      "loss": 0.1968,
      "step": 10700
    },
    {
      "epoch": 9.809264305177111,
      "grad_norm": 14.83648681640625,
      "learning_rate": 3.038328792007266e-05,
      "loss": 0.1884,
      "step": 10800
    },
    {
      "epoch": 9.900090826521344,
      "grad_norm": 3.571709632873535,
      "learning_rate": 3.02016348773842e-05,
      "loss": 0.1871,
      "step": 10900
    },
    {
      "epoch": 9.990917347865576,
      "grad_norm": 2.4877097606658936,
      "learning_rate": 3.001998183469573e-05,
      "loss": 0.2005,
      "step": 11000
    },
    {
      "epoch": 10.08174386920981,
      "grad_norm": 1.5256454944610596,
      "learning_rate": 2.983832879200727e-05,
      "loss": 0.2135,
      "step": 11100
    },
    {
      "epoch": 10.172570390554041,
      "grad_norm": 11.718792915344238,
      "learning_rate": 2.96566757493188e-05,
      "loss": 0.1725,
      "step": 11200
    },
    {
      "epoch": 10.263396911898274,
      "grad_norm": 5.157980918884277,
      "learning_rate": 2.947502270663034e-05,
      "loss": 0.2044,
      "step": 11300
    },
    {
      "epoch": 10.354223433242506,
      "grad_norm": 0.7364321947097778,
      "learning_rate": 2.929336966394187e-05,
      "loss": 0.2132,
      "step": 11400
    },
    {
      "epoch": 10.44504995458674,
      "grad_norm": 1.9263489246368408,
      "learning_rate": 2.911171662125341e-05,
      "loss": 0.2021,
      "step": 11500
    },
    {
      "epoch": 10.535876475930971,
      "grad_norm": 0.9510646462440491,
      "learning_rate": 2.893006357856494e-05,
      "loss": 0.1854,
      "step": 11600
    },
    {
      "epoch": 10.626702997275205,
      "grad_norm": 1.114639401435852,
      "learning_rate": 2.874841053587648e-05,
      "loss": 0.2353,
      "step": 11700
    },
    {
      "epoch": 10.717529518619436,
      "grad_norm": 3.1212363243103027,
      "learning_rate": 2.856675749318801e-05,
      "loss": 0.1938,
      "step": 11800
    },
    {
      "epoch": 10.80835603996367,
      "grad_norm": 9.928292274475098,
      "learning_rate": 2.8385104450499543e-05,
      "loss": 0.189,
      "step": 11900
    },
    {
      "epoch": 10.899182561307901,
      "grad_norm": 1.0408395528793335,
      "learning_rate": 2.820345140781108e-05,
      "loss": 0.1936,
      "step": 12000
    },
    {
      "epoch": 10.899182561307901,
      "eval_f1_macro": 0.8740904490224095,
      "eval_iou_Block": 0.7537206129826671,
      "eval_iou_unlabeled": 0.7974714543065394,
      "eval_loss": 0.44600024819374084,
      "eval_macro_precision": 0.8763248760481797,
      "eval_macro_recall": 0.8718673875687827,
      "eval_mean_accuracy": 0.8718673875687827,
      "eval_mean_iou": 0.7755960336446033,
      "eval_overall_accuracy": 0.8749688158827138,
      "eval_precision_Block": 0.8862603936805626,
      "eval_precision_unlabeled": 0.8663893584157966,
      "eval_recall_Block": 0.8344354796433526,
      "eval_recall_unlabeled": 0.9092992954942127,
      "eval_runtime": 44.1859,
      "eval_samples_per_second": 31.345,
      "eval_steps_per_second": 7.853,
      "step": 12000
    },
    {
      "epoch": 10.990009082652135,
      "grad_norm": 1.6395378112792969,
      "learning_rate": 2.8021798365122613e-05,
      "loss": 0.1895,
      "step": 12100
    },
    {
      "epoch": 11.080835603996366,
      "grad_norm": 1.6217583417892456,
      "learning_rate": 2.784014532243415e-05,
      "loss": 0.188,
      "step": 12200
    },
    {
      "epoch": 11.1716621253406,
      "grad_norm": 3.9637062549591064,
      "learning_rate": 2.7658492279745686e-05,
      "loss": 0.2066,
      "step": 12300
    },
    {
      "epoch": 11.262488646684831,
      "grad_norm": 14.49028491973877,
      "learning_rate": 2.747683923705722e-05,
      "loss": 0.1808,
      "step": 12400
    },
    {
      "epoch": 11.353315168029065,
      "grad_norm": 2.0423202514648438,
      "learning_rate": 2.7295186194368756e-05,
      "loss": 0.1848,
      "step": 12500
    },
    {
      "epoch": 11.444141689373296,
      "grad_norm": 2.8291196823120117,
      "learning_rate": 2.711353315168029e-05,
      "loss": 0.1804,
      "step": 12600
    },
    {
      "epoch": 11.53496821071753,
      "grad_norm": 1.40559983253479,
      "learning_rate": 2.6931880108991826e-05,
      "loss": 0.1722,
      "step": 12700
    },
    {
      "epoch": 11.625794732061761,
      "grad_norm": 2.1339757442474365,
      "learning_rate": 2.675022706630336e-05,
      "loss": 0.1873,
      "step": 12800
    },
    {
      "epoch": 11.716621253405995,
      "grad_norm": 2.324460744857788,
      "learning_rate": 2.6568574023614896e-05,
      "loss": 0.1871,
      "step": 12900
    },
    {
      "epoch": 11.807447774750226,
      "grad_norm": 0.9744783043861389,
      "learning_rate": 2.638692098092643e-05,
      "loss": 0.1765,
      "step": 13000
    },
    {
      "epoch": 11.89827429609446,
      "grad_norm": 38.716758728027344,
      "learning_rate": 2.6205267938237966e-05,
      "loss": 0.1858,
      "step": 13100
    },
    {
      "epoch": 11.989100817438691,
      "grad_norm": 1.2019544839859009,
      "learning_rate": 2.60236148955495e-05,
      "loss": 0.2009,
      "step": 13200
    },
    {
      "epoch": 12.079927338782925,
      "grad_norm": 4.0810017585754395,
      "learning_rate": 2.5841961852861036e-05,
      "loss": 0.1753,
      "step": 13300
    },
    {
      "epoch": 12.170753860127157,
      "grad_norm": 8.332850456237793,
      "learning_rate": 2.5660308810172575e-05,
      "loss": 0.1769,
      "step": 13400
    },
    {
      "epoch": 12.26158038147139,
      "grad_norm": 4.988341331481934,
      "learning_rate": 2.5478655767484106e-05,
      "loss": 0.1701,
      "step": 13500
    },
    {
      "epoch": 12.352406902815622,
      "grad_norm": 2.1503074169158936,
      "learning_rate": 2.5297002724795645e-05,
      "loss": 0.1912,
      "step": 13600
    },
    {
      "epoch": 12.443233424159855,
      "grad_norm": 15.437950134277344,
      "learning_rate": 2.5115349682107176e-05,
      "loss": 0.1838,
      "step": 13700
    },
    {
      "epoch": 12.534059945504087,
      "grad_norm": 1.0233641862869263,
      "learning_rate": 2.493369663941871e-05,
      "loss": 0.166,
      "step": 13800
    },
    {
      "epoch": 12.62488646684832,
      "grad_norm": 1.0718793869018555,
      "learning_rate": 2.4752043596730246e-05,
      "loss": 0.1819,
      "step": 13900
    },
    {
      "epoch": 12.715712988192552,
      "grad_norm": 2.5441906452178955,
      "learning_rate": 2.457039055404178e-05,
      "loss": 0.1645,
      "step": 14000
    },
    {
      "epoch": 12.715712988192552,
      "eval_f1_macro": 0.87349601904946,
      "eval_iou_Block": 0.7526497996409457,
      "eval_iou_unlabeled": 0.7966457380589006,
      "eval_loss": 0.46254128217697144,
      "eval_macro_precision": 0.8757486453086176,
      "eval_macro_recall": 0.8712549516015812,
      "eval_mean_accuracy": 0.8712549516015812,
      "eval_mean_iou": 0.7746477688499231,
      "eval_overall_accuracy": 0.8743778187445355,
      "eval_precision_Block": 0.8857618321761068,
      "eval_precision_unlabeled": 0.8657354584411285,
      "eval_recall_Block": 0.8335642931287267,
      "eval_recall_unlabeled": 0.9089456100744356,
      "eval_runtime": 44.1635,
      "eval_samples_per_second": 31.361,
      "eval_steps_per_second": 7.857,
      "step": 14000
    },
    {
      "epoch": 12.806539509536785,
      "grad_norm": 2.5625662803649902,
      "learning_rate": 2.4388737511353316e-05,
      "loss": 0.1764,
      "step": 14100
    },
    {
      "epoch": 12.897366030881017,
      "grad_norm": 10.673996925354004,
      "learning_rate": 2.420708446866485e-05,
      "loss": 0.219,
      "step": 14200
    },
    {
      "epoch": 12.98819255222525,
      "grad_norm": 1.7086154222488403,
      "learning_rate": 2.4025431425976386e-05,
      "loss": 0.198,
      "step": 14300
    },
    {
      "epoch": 13.079019073569482,
      "grad_norm": 6.369633197784424,
      "learning_rate": 2.384377838328792e-05,
      "loss": 0.1654,
      "step": 14400
    },
    {
      "epoch": 13.169845594913715,
      "grad_norm": 2.3330013751983643,
      "learning_rate": 2.3662125340599456e-05,
      "loss": 0.1601,
      "step": 14500
    },
    {
      "epoch": 13.260672116257947,
      "grad_norm": 3.642915964126587,
      "learning_rate": 2.348047229791099e-05,
      "loss": 0.2215,
      "step": 14600
    },
    {
      "epoch": 13.35149863760218,
      "grad_norm": 1.656193733215332,
      "learning_rate": 2.3298819255222526e-05,
      "loss": 0.1595,
      "step": 14700
    },
    {
      "epoch": 13.442325158946412,
      "grad_norm": 1.3210631608963013,
      "learning_rate": 2.311716621253406e-05,
      "loss": 0.1742,
      "step": 14800
    },
    {
      "epoch": 13.533151680290645,
      "grad_norm": 2.2377169132232666,
      "learning_rate": 2.2935513169845596e-05,
      "loss": 0.1698,
      "step": 14900
    },
    {
      "epoch": 13.623978201634877,
      "grad_norm": 1.254146933555603,
      "learning_rate": 2.275386012715713e-05,
      "loss": 0.1648,
      "step": 15000
    },
    {
      "epoch": 13.71480472297911,
      "grad_norm": 9.828634262084961,
      "learning_rate": 2.2572207084468666e-05,
      "loss": 0.174,
      "step": 15100
    },
    {
      "epoch": 13.805631244323342,
      "grad_norm": 1.1215722560882568,
      "learning_rate": 2.23905540417802e-05,
      "loss": 0.1689,
      "step": 15200
    },
    {
      "epoch": 13.896457765667575,
      "grad_norm": 7.1416144371032715,
      "learning_rate": 2.2208900999091736e-05,
      "loss": 0.1822,
      "step": 15300
    },
    {
      "epoch": 13.987284287011807,
      "grad_norm": 2.4007163047790527,
      "learning_rate": 2.202724795640327e-05,
      "loss": 0.148,
      "step": 15400
    },
    {
      "epoch": 14.07811080835604,
      "grad_norm": 1.3483860492706299,
      "learning_rate": 2.1845594913714806e-05,
      "loss": 0.1571,
      "step": 15500
    },
    {
      "epoch": 14.168937329700272,
      "grad_norm": 2.8706858158111572,
      "learning_rate": 2.166394187102634e-05,
      "loss": 0.1496,
      "step": 15600
    },
    {
      "epoch": 14.259763851044506,
      "grad_norm": 0.3327498435974121,
      "learning_rate": 2.1482288828337876e-05,
      "loss": 0.1502,
      "step": 15700
    },
    {
      "epoch": 14.350590372388737,
      "grad_norm": 1.7701436281204224,
      "learning_rate": 2.130063578564941e-05,
      "loss": 0.1754,
      "step": 15800
    },
    {
      "epoch": 14.44141689373297,
      "grad_norm": 1.0487480163574219,
      "learning_rate": 2.1118982742960946e-05,
      "loss": 0.1649,
      "step": 15900
    },
    {
      "epoch": 14.532243415077202,
      "grad_norm": 9.758103370666504,
      "learning_rate": 2.093732970027248e-05,
      "loss": 0.1677,
      "step": 16000
    },
    {
      "epoch": 14.532243415077202,
      "eval_f1_macro": 0.8774169395837327,
      "eval_iou_Block": 0.7629909582527634,
      "eval_iou_unlabeled": 0.8001591740709254,
      "eval_loss": 0.46831169724464417,
      "eval_macro_precision": 0.8783320882471403,
      "eval_macro_recall": 0.8765036959533572,
      "eval_mean_accuracy": 0.8765036959533572,
      "eval_mean_iou": 0.7815750661618444,
      "eval_overall_accuracy": 0.8783932957838588,
      "eval_precision_Block": 0.8777653658512606,
      "eval_precision_unlabeled": 0.8788988106430199,
      "eval_recall_Block": 0.8536976467038762,
      "eval_recall_unlabeled": 0.8993097452028381,
      "eval_runtime": 43.8028,
      "eval_samples_per_second": 31.619,
      "eval_steps_per_second": 7.922,
      "step": 16000
    },
    {
      "epoch": 14.623069936421436,
      "grad_norm": 1.8389567136764526,
      "learning_rate": 2.0755676657584016e-05,
      "loss": 0.1581,
      "step": 16100
    },
    {
      "epoch": 14.713896457765667,
      "grad_norm": 3.3401527404785156,
      "learning_rate": 2.057402361489555e-05,
      "loss": 0.1551,
      "step": 16200
    },
    {
      "epoch": 14.8047229791099,
      "grad_norm": 11.926287651062012,
      "learning_rate": 2.0392370572207086e-05,
      "loss": 0.1824,
      "step": 16300
    },
    {
      "epoch": 14.895549500454132,
      "grad_norm": 1.032028079032898,
      "learning_rate": 2.0210717529518618e-05,
      "loss": 0.174,
      "step": 16400
    },
    {
      "epoch": 14.986376021798366,
      "grad_norm": 1.0305557250976562,
      "learning_rate": 2.0029064486830153e-05,
      "loss": 0.1617,
      "step": 16500
    },
    {
      "epoch": 15.077202543142597,
      "grad_norm": 2.6198549270629883,
      "learning_rate": 1.9847411444141688e-05,
      "loss": 0.1781,
      "step": 16600
    },
    {
      "epoch": 15.16802906448683,
      "grad_norm": 0.7670189142227173,
      "learning_rate": 1.9665758401453223e-05,
      "loss": 0.1412,
      "step": 16700
    },
    {
      "epoch": 15.258855585831062,
      "grad_norm": 1.423601508140564,
      "learning_rate": 1.9484105358764758e-05,
      "loss": 0.15,
      "step": 16800
    },
    {
      "epoch": 15.349682107175296,
      "grad_norm": 2.2957592010498047,
      "learning_rate": 1.9302452316076293e-05,
      "loss": 0.1693,
      "step": 16900
    },
    {
      "epoch": 15.440508628519527,
      "grad_norm": 8.118236541748047,
      "learning_rate": 1.9120799273387828e-05,
      "loss": 0.1518,
      "step": 17000
    },
    {
      "epoch": 15.53133514986376,
      "grad_norm": 0.9164192080497742,
      "learning_rate": 1.8939146230699363e-05,
      "loss": 0.1432,
      "step": 17100
    },
    {
      "epoch": 15.622161671207992,
      "grad_norm": 3.4596455097198486,
      "learning_rate": 1.87574931880109e-05,
      "loss": 0.1434,
      "step": 17200
    },
    {
      "epoch": 15.712988192552226,
      "grad_norm": 0.8612134456634521,
      "learning_rate": 1.8575840145322436e-05,
      "loss": 0.1586,
      "step": 17300
    },
    {
      "epoch": 15.803814713896458,
      "grad_norm": 2.9915175437927246,
      "learning_rate": 1.839418710263397e-05,
      "loss": 0.1576,
      "step": 17400
    },
    {
      "epoch": 15.894641235240691,
      "grad_norm": 1.1698668003082275,
      "learning_rate": 1.8212534059945506e-05,
      "loss": 0.1673,
      "step": 17500
    },
    {
      "epoch": 15.985467756584923,
      "grad_norm": 2.2319440841674805,
      "learning_rate": 1.803088101725704e-05,
      "loss": 0.1959,
      "step": 17600
    },
    {
      "epoch": 16.076294277929154,
      "grad_norm": 0.80549156665802,
      "learning_rate": 1.7849227974568576e-05,
      "loss": 0.1542,
      "step": 17700
    },
    {
      "epoch": 16.167120799273388,
      "grad_norm": 3.4903182983398438,
      "learning_rate": 1.766757493188011e-05,
      "loss": 0.155,
      "step": 17800
    },
    {
      "epoch": 16.25794732061762,
      "grad_norm": 4.9545578956604,
      "learning_rate": 1.7485921889191646e-05,
      "loss": 0.1345,
      "step": 17900
    },
    {
      "epoch": 16.348773841961854,
      "grad_norm": 1.410488247871399,
      "learning_rate": 1.730426884650318e-05,
      "loss": 0.1643,
      "step": 18000
    },
    {
      "epoch": 16.348773841961854,
      "eval_f1_macro": 0.8758975202887737,
      "eval_iou_Block": 0.7560419836214627,
      "eval_iou_unlabeled": 0.8004250106674377,
      "eval_loss": 0.4859940707683563,
      "eval_macro_precision": 0.8784363284304955,
      "eval_macro_recall": 0.8733733449033031,
      "eval_mean_accuracy": 0.8733733449033031,
      "eval_mean_iou": 0.7782334971444502,
      "eval_overall_accuracy": 0.8766910869722332,
      "eval_precision_Block": 0.8907304708731962,
      "eval_precision_unlabeled": 0.8661421859877948,
      "eval_recall_Block": 0.8333306925915673,
      "eval_recall_unlabeled": 0.9134159972150389,
      "eval_runtime": 42.9552,
      "eval_samples_per_second": 32.243,
      "eval_steps_per_second": 8.078,
      "step": 18000
    },
    {
      "epoch": 16.439600363306084,
      "grad_norm": 1.6521159410476685,
      "learning_rate": 1.7122615803814716e-05,
      "loss": 0.1584,
      "step": 18100
    },
    {
      "epoch": 16.530426884650318,
      "grad_norm": 5.348428726196289,
      "learning_rate": 1.694096276112625e-05,
      "loss": 0.1481,
      "step": 18200
    },
    {
      "epoch": 16.62125340599455,
      "grad_norm": 20.013532638549805,
      "learning_rate": 1.6759309718437786e-05,
      "loss": 0.161,
      "step": 18300
    },
    {
      "epoch": 16.712079927338785,
      "grad_norm": 10.94658374786377,
      "learning_rate": 1.657765667574932e-05,
      "loss": 0.145,
      "step": 18400
    },
    {
      "epoch": 16.802906448683014,
      "grad_norm": 2.9617397785186768,
      "learning_rate": 1.6396003633060856e-05,
      "loss": 0.1673,
      "step": 18500
    },
    {
      "epoch": 16.893732970027248,
      "grad_norm": 35.36513900756836,
      "learning_rate": 1.621435059037239e-05,
      "loss": 0.1541,
      "step": 18600
    },
    {
      "epoch": 16.98455949137148,
      "grad_norm": 6.7698469161987305,
      "learning_rate": 1.6032697547683926e-05,
      "loss": 0.1416,
      "step": 18700
    },
    {
      "epoch": 17.075386012715715,
      "grad_norm": 2.296678304672241,
      "learning_rate": 1.585104450499546e-05,
      "loss": 0.1473,
      "step": 18800
    },
    {
      "epoch": 17.166212534059945,
      "grad_norm": 2.4332501888275146,
      "learning_rate": 1.5669391462306996e-05,
      "loss": 0.1676,
      "step": 18900
    },
    {
      "epoch": 17.257039055404178,
      "grad_norm": 12.171119689941406,
      "learning_rate": 1.548773841961853e-05,
      "loss": 0.158,
      "step": 19000
    },
    {
      "epoch": 17.34786557674841,
      "grad_norm": 2.4787676334381104,
      "learning_rate": 1.5306085376930066e-05,
      "loss": 0.1294,
      "step": 19100
    },
    {
      "epoch": 17.438692098092645,
      "grad_norm": 130.53578186035156,
      "learning_rate": 1.5124432334241601e-05,
      "loss": 0.1657,
      "step": 19200
    },
    {
      "epoch": 17.529518619436875,
      "grad_norm": 28.08417320251465,
      "learning_rate": 1.4942779291553136e-05,
      "loss": 0.1503,
      "step": 19300
    },
    {
      "epoch": 17.620345140781108,
      "grad_norm": 0.6500487923622131,
      "learning_rate": 1.4761126248864668e-05,
      "loss": 0.1484,
      "step": 19400
    },
    {
      "epoch": 17.71117166212534,
      "grad_norm": 15.548930168151855,
      "learning_rate": 1.4579473206176203e-05,
      "loss": 0.1458,
      "step": 19500
    },
    {
      "epoch": 17.80199818346957,
      "grad_norm": 2.4381263256073,
      "learning_rate": 1.4397820163487738e-05,
      "loss": 0.1438,
      "step": 19600
    },
    {
      "epoch": 17.892824704813805,
      "grad_norm": 0.9639010429382324,
      "learning_rate": 1.4216167120799273e-05,
      "loss": 0.1284,
      "step": 19700
    },
    {
      "epoch": 17.983651226158038,
      "grad_norm": 0.8757891058921814,
      "learning_rate": 1.4034514078110808e-05,
      "loss": 0.1588,
      "step": 19800
    },
    {
      "epoch": 18.07447774750227,
      "grad_norm": 1.241710901260376,
      "learning_rate": 1.3852861035422343e-05,
      "loss": 0.1781,
      "step": 19900
    },
    {
      "epoch": 18.165304268846505,
      "grad_norm": 5.4194254875183105,
      "learning_rate": 1.3671207992733878e-05,
      "loss": 0.1402,
      "step": 20000
    },
    {
      "epoch": 18.165304268846505,
      "eval_f1_macro": 0.8767730143928912,
      "eval_iou_Block": 0.7585779568509086,
      "eval_iou_unlabeled": 0.8012038256147443,
      "eval_loss": 0.4930644631385803,
      "eval_macro_precision": 0.8789196449044056,
      "eval_macro_recall": 0.8746368439866379,
      "eval_mean_accuracy": 0.8746368439866379,
      "eval_mean_iou": 0.7798908912328264,
      "eval_overall_accuracy": 0.8776369501107006,
      "eval_precision_Block": 0.8884564606652897,
      "eval_precision_unlabeled": 0.8693828291435214,
      "eval_recall_Block": 0.838427818713346,
      "eval_recall_unlabeled": 0.9108458692599297,
      "eval_runtime": 42.846,
      "eval_samples_per_second": 32.325,
      "eval_steps_per_second": 8.099,
      "step": 20000
    },
    {
      "epoch": 18.256130790190735,
      "grad_norm": 5.209394454956055,
      "learning_rate": 1.3489554950045413e-05,
      "loss": 0.1521,
      "step": 20100
    },
    {
      "epoch": 18.34695731153497,
      "grad_norm": 3.7524290084838867,
      "learning_rate": 1.3307901907356948e-05,
      "loss": 0.1243,
      "step": 20200
    },
    {
      "epoch": 18.4377838328792,
      "grad_norm": 1.659158706665039,
      "learning_rate": 1.3126248864668483e-05,
      "loss": 0.1514,
      "step": 20300
    },
    {
      "epoch": 18.52861035422343,
      "grad_norm": 1.4679794311523438,
      "learning_rate": 1.2944595821980018e-05,
      "loss": 0.1433,
      "step": 20400
    },
    {
      "epoch": 18.619436875567665,
      "grad_norm": 180.7765350341797,
      "learning_rate": 1.2762942779291553e-05,
      "loss": 0.1612,
      "step": 20500
    },
    {
      "epoch": 18.7102633969119,
      "grad_norm": 1.6548292636871338,
      "learning_rate": 1.258128973660309e-05,
      "loss": 0.1458,
      "step": 20600
    },
    {
      "epoch": 18.80108991825613,
      "grad_norm": 2.999763011932373,
      "learning_rate": 1.2399636693914624e-05,
      "loss": 0.1267,
      "step": 20700
    },
    {
      "epoch": 18.89191643960036,
      "grad_norm": 19.77419662475586,
      "learning_rate": 1.221798365122616e-05,
      "loss": 0.1359,
      "step": 20800
    },
    {
      "epoch": 18.982742960944595,
      "grad_norm": 31.55171775817871,
      "learning_rate": 1.2036330608537694e-05,
      "loss": 0.1361,
      "step": 20900
    },
    {
      "epoch": 19.07356948228883,
      "grad_norm": 48.90026092529297,
      "learning_rate": 1.185467756584923e-05,
      "loss": 0.1141,
      "step": 21000
    },
    {
      "epoch": 19.164396003633062,
      "grad_norm": 1.1110255718231201,
      "learning_rate": 1.1673024523160764e-05,
      "loss": 0.1509,
      "step": 21100
    },
    {
      "epoch": 19.25522252497729,
      "grad_norm": 2.0509088039398193,
      "learning_rate": 1.14913714804723e-05,
      "loss": 0.1408,
      "step": 21200
    },
    {
      "epoch": 19.346049046321525,
      "grad_norm": 17.601442337036133,
      "learning_rate": 1.1309718437783834e-05,
      "loss": 0.1331,
      "step": 21300
    },
    {
      "epoch": 19.43687556766576,
      "grad_norm": 3.456925630569458,
      "learning_rate": 1.112806539509537e-05,
      "loss": 0.15,
      "step": 21400
    },
    {
      "epoch": 19.527702089009992,
      "grad_norm": 9.538345336914062,
      "learning_rate": 1.0946412352406904e-05,
      "loss": 0.1357,
      "step": 21500
    },
    {
      "epoch": 19.618528610354222,
      "grad_norm": 4.321194171905518,
      "learning_rate": 1.0764759309718438e-05,
      "loss": 0.1481,
      "step": 21600
    },
    {
      "epoch": 19.709355131698455,
      "grad_norm": 57.750667572021484,
      "learning_rate": 1.0583106267029973e-05,
      "loss": 0.1486,
      "step": 21700
    },
    {
      "epoch": 19.80018165304269,
      "grad_norm": 0.13045905530452728,
      "learning_rate": 1.0401453224341508e-05,
      "loss": 0.1394,
      "step": 21800
    },
    {
      "epoch": 19.891008174386922,
      "grad_norm": 1.7305898666381836,
      "learning_rate": 1.0219800181653043e-05,
      "loss": 0.1423,
      "step": 21900
    },
    {
      "epoch": 19.981834695731152,
      "grad_norm": 1.1593793630599976,
      "learning_rate": 1.0038147138964578e-05,
      "loss": 0.1276,
      "step": 22000
    },
    {
      "epoch": 19.981834695731152,
      "eval_f1_macro": 0.8771510411414245,
      "eval_iou_Block": 0.7642633563509276,
      "eval_iou_unlabeled": 0.7983694293744323,
      "eval_loss": 0.5170130729675293,
      "eval_macro_precision": 0.8774592696334635,
      "eval_macro_recall": 0.8768430291195604,
      "eval_mean_accuracy": 0.8768430291195604,
      "eval_mean_iou": 0.78131639286268,
      "eval_overall_accuracy": 0.8780723819663808,
      "eval_precision_Block": 0.870803797614513,
      "eval_precision_unlabeled": 0.8841147416524141,
      "eval_recall_Block": 0.8620056645532564,
      "eval_recall_unlabeled": 0.8916803936858642,
      "eval_runtime": 42.8674,
      "eval_samples_per_second": 32.309,
      "eval_steps_per_second": 8.095,
      "step": 22000
    },
    {
      "epoch": 20.072661217075385,
      "grad_norm": 1.62459135055542,
      "learning_rate": 9.856494096276113e-06,
      "loss": 0.123,
      "step": 22100
    },
    {
      "epoch": 20.16348773841962,
      "grad_norm": 1.3926169872283936,
      "learning_rate": 9.674841053587648e-06,
      "loss": 0.1252,
      "step": 22200
    },
    {
      "epoch": 20.254314259763852,
      "grad_norm": 2.50858211517334,
      "learning_rate": 9.493188010899183e-06,
      "loss": 0.1496,
      "step": 22300
    },
    {
      "epoch": 20.345140781108082,
      "grad_norm": 1.6280009746551514,
      "learning_rate": 9.311534968210718e-06,
      "loss": 0.1127,
      "step": 22400
    },
    {
      "epoch": 20.435967302452315,
      "grad_norm": 3.2285232543945312,
      "learning_rate": 9.129881925522253e-06,
      "loss": 0.1204,
      "step": 22500
    },
    {
      "epoch": 20.52679382379655,
      "grad_norm": 3.9251720905303955,
      "learning_rate": 8.948228882833788e-06,
      "loss": 0.1411,
      "step": 22600
    },
    {
      "epoch": 20.617620345140782,
      "grad_norm": 2.2337470054626465,
      "learning_rate": 8.766575840145323e-06,
      "loss": 0.1287,
      "step": 22700
    },
    {
      "epoch": 20.708446866485012,
      "grad_norm": 1.530200719833374,
      "learning_rate": 8.584922797456858e-06,
      "loss": 0.1217,
      "step": 22800
    },
    {
      "epoch": 20.799273387829246,
      "grad_norm": 6.245142936706543,
      "learning_rate": 8.403269754768393e-06,
      "loss": 0.1346,
      "step": 22900
    },
    {
      "epoch": 20.89009990917348,
      "grad_norm": 1.607385277748108,
      "learning_rate": 8.221616712079928e-06,
      "loss": 0.1231,
      "step": 23000
    },
    {
      "epoch": 20.980926430517712,
      "grad_norm": 4.490318775177002,
      "learning_rate": 8.039963669391463e-06,
      "loss": 0.1283,
      "step": 23100
    },
    {
      "epoch": 21.071752951861942,
      "grad_norm": 0.5546224117279053,
      "learning_rate": 7.858310626702998e-06,
      "loss": 0.132,
      "step": 23200
    },
    {
      "epoch": 21.162579473206176,
      "grad_norm": 1.2080819606781006,
      "learning_rate": 7.676657584014533e-06,
      "loss": 0.1159,
      "step": 23300
    },
    {
      "epoch": 21.25340599455041,
      "grad_norm": 0.5358849763870239,
      "learning_rate": 7.4950045413260675e-06,
      "loss": 0.147,
      "step": 23400
    },
    {
      "epoch": 21.344232515894642,
      "grad_norm": 1.8238036632537842,
      "learning_rate": 7.3133514986376025e-06,
      "loss": 0.1308,
      "step": 23500
    },
    {
      "epoch": 21.435059037238872,
      "grad_norm": 0.6798994541168213,
      "learning_rate": 7.1316984559491375e-06,
      "loss": 0.122,
      "step": 23600
    },
    {
      "epoch": 21.525885558583106,
      "grad_norm": 7.207299709320068,
      "learning_rate": 6.9500454132606725e-06,
      "loss": 0.1278,
      "step": 23700
    },
    {
      "epoch": 21.61671207992734,
      "grad_norm": 1.9404411315917969,
      "learning_rate": 6.7683923705722075e-06,
      "loss": 0.137,
      "step": 23800
    },
    {
      "epoch": 21.707538601271573,
      "grad_norm": 1.1378363370895386,
      "learning_rate": 6.5867393278837425e-06,
      "loss": 0.1232,
      "step": 23900
    },
    {
      "epoch": 21.798365122615802,
      "grad_norm": 1.0123172998428345,
      "learning_rate": 6.4050862851952775e-06,
      "loss": 0.1231,
      "step": 24000
    },
    {
      "epoch": 21.798365122615802,
      "eval_f1_macro": 0.8785881585736978,
      "eval_iou_Block": 0.7647407869126888,
      "eval_iou_unlabeled": 0.802051691995429,
      "eval_loss": 0.5062797665596008,
      "eval_macro_precision": 0.8795959333313749,
      "eval_macro_recall": 0.8775826904390618,
      "eval_mean_accuracy": 0.8775826904390618,
      "eval_mean_iou": 0.7833962394540589,
      "eval_overall_accuracy": 0.8795536908862392,
      "eval_precision_Block": 0.8799794452533634,
      "eval_precision_unlabeled": 0.8792124214093864,
      "eval_recall_Block": 0.8537941969477462,
      "eval_recall_unlabeled": 0.9013711839303773,
      "eval_runtime": 43.4194,
      "eval_samples_per_second": 31.898,
      "eval_steps_per_second": 7.992,
      "step": 24000
    }
  ],
  "logging_steps": 100,
  "max_steps": 27525,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 25,
  "save_steps": 2000,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 30,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.682683730067456e+18,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
