{
  "best_global_step": 8000,
  "best_metric": 0.7850507026267192,
  "best_model_checkpoint": "out/sf-2000-512-overlap\\checkpoint-8000",
  "epoch": 17.467248908296945,
  "eval_steps": 2000,
  "global_step": 8000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.2183406113537118,
      "grad_norm": 2.7828519344329834,
      "learning_rate": 4.956768558951965e-05,
      "loss": 0.4933,
      "step": 100
    },
    {
      "epoch": 0.4366812227074236,
      "grad_norm": 3.4486310482025146,
      "learning_rate": 4.913100436681223e-05,
      "loss": 0.4057,
      "step": 200
    },
    {
      "epoch": 0.6550218340611353,
      "grad_norm": 6.625727653503418,
      "learning_rate": 4.86943231441048e-05,
      "loss": 0.3818,
      "step": 300
    },
    {
      "epoch": 0.8733624454148472,
      "grad_norm": 2.2950923442840576,
      "learning_rate": 4.825764192139739e-05,
      "loss": 0.3876,
      "step": 400
    },
    {
      "epoch": 1.091703056768559,
      "grad_norm": 1.2045402526855469,
      "learning_rate": 4.782096069868996e-05,
      "loss": 0.3813,
      "step": 500
    },
    {
      "epoch": 1.3100436681222707,
      "grad_norm": 1.7482826709747314,
      "learning_rate": 4.738427947598254e-05,
      "loss": 0.3278,
      "step": 600
    },
    {
      "epoch": 1.5283842794759825,
      "grad_norm": 3.120490789413452,
      "learning_rate": 4.694759825327511e-05,
      "loss": 0.3298,
      "step": 700
    },
    {
      "epoch": 1.7467248908296944,
      "grad_norm": 2.5082309246063232,
      "learning_rate": 4.6510917030567686e-05,
      "loss": 0.3732,
      "step": 800
    },
    {
      "epoch": 1.965065502183406,
      "grad_norm": 0.858852207660675,
      "learning_rate": 4.6074235807860265e-05,
      "loss": 0.3529,
      "step": 900
    },
    {
      "epoch": 2.183406113537118,
      "grad_norm": 1.5141398906707764,
      "learning_rate": 4.563755458515284e-05,
      "loss": 0.3179,
      "step": 1000
    },
    {
      "epoch": 2.4017467248908297,
      "grad_norm": 2.0911083221435547,
      "learning_rate": 4.5200873362445414e-05,
      "loss": 0.2966,
      "step": 1100
    },
    {
      "epoch": 2.6200873362445414,
      "grad_norm": 4.417447566986084,
      "learning_rate": 4.476419213973799e-05,
      "loss": 0.3449,
      "step": 1200
    },
    {
      "epoch": 2.8384279475982535,
      "grad_norm": 4.162992477416992,
      "learning_rate": 4.432751091703057e-05,
      "loss": 0.3028,
      "step": 1300
    },
    {
      "epoch": 3.056768558951965,
      "grad_norm": 3.1116526126861572,
      "learning_rate": 4.389082969432315e-05,
      "loss": 0.2897,
      "step": 1400
    },
    {
      "epoch": 3.2751091703056767,
      "grad_norm": 1.0786134004592896,
      "learning_rate": 4.345414847161573e-05,
      "loss": 0.3103,
      "step": 1500
    },
    {
      "epoch": 3.493449781659389,
      "grad_norm": 4.364190101623535,
      "learning_rate": 4.30174672489083e-05,
      "loss": 0.291,
      "step": 1600
    },
    {
      "epoch": 3.7117903930131004,
      "grad_norm": 9.39981746673584,
      "learning_rate": 4.2580786026200876e-05,
      "loss": 0.2809,
      "step": 1700
    },
    {
      "epoch": 3.930131004366812,
      "grad_norm": 2.309199571609497,
      "learning_rate": 4.214410480349345e-05,
      "loss": 0.2689,
      "step": 1800
    },
    {
      "epoch": 4.148471615720524,
      "grad_norm": 2.980938196182251,
      "learning_rate": 4.1707423580786026e-05,
      "loss": 0.2616,
      "step": 1900
    },
    {
      "epoch": 4.366812227074236,
      "grad_norm": 5.1285014152526855,
      "learning_rate": 4.1270742358078604e-05,
      "loss": 0.2638,
      "step": 2000
    },
    {
      "epoch": 4.366812227074236,
      "eval_f1_macro": 0.8644860404625657,
      "eval_iou_Block": 0.7556934266664557,
      "eval_iou_unlabeled": 0.760452149693264,
      "eval_loss": 0.39479726552963257,
      "eval_macro_precision": 0.8648889418616337,
      "eval_macro_recall": 0.8640835142663172,
      "eval_mean_accuracy": 0.8640835142663172,
      "eval_mean_iou": 0.7580727881798599,
      "eval_overall_accuracy": 0.8624058159030213,
      "eval_precision_Block": 0.9059737355590443,
      "eval_precision_unlabeled": 0.8238041481642231,
      "eval_recall_Block": 0.8200060582102661,
      "eval_recall_unlabeled": 0.9081609703223684,
      "eval_runtime": 3.0336,
      "eval_samples_per_second": 32.305,
      "eval_steps_per_second": 8.241,
      "step": 2000
    },
    {
      "epoch": 4.585152838427947,
      "grad_norm": 4.02169942855835,
      "learning_rate": 4.083406113537118e-05,
      "loss": 0.2727,
      "step": 2100
    },
    {
      "epoch": 4.8034934497816595,
      "grad_norm": 6.682254791259766,
      "learning_rate": 4.039737991266376e-05,
      "loss": 0.2647,
      "step": 2200
    },
    {
      "epoch": 5.021834061135372,
      "grad_norm": 4.38791036605835,
      "learning_rate": 3.996069868995633e-05,
      "loss": 0.2606,
      "step": 2300
    },
    {
      "epoch": 5.240174672489083,
      "grad_norm": 3.0197527408599854,
      "learning_rate": 3.952401746724891e-05,
      "loss": 0.245,
      "step": 2400
    },
    {
      "epoch": 5.458515283842795,
      "grad_norm": 2.648550510406494,
      "learning_rate": 3.908733624454149e-05,
      "loss": 0.2665,
      "step": 2500
    },
    {
      "epoch": 5.676855895196507,
      "grad_norm": 2.3830418586730957,
      "learning_rate": 3.8650655021834066e-05,
      "loss": 0.2358,
      "step": 2600
    },
    {
      "epoch": 5.895196506550218,
      "grad_norm": 3.882944345474243,
      "learning_rate": 3.821397379912664e-05,
      "loss": 0.2515,
      "step": 2700
    },
    {
      "epoch": 6.11353711790393,
      "grad_norm": 1.586392879486084,
      "learning_rate": 3.7777292576419215e-05,
      "loss": 0.2462,
      "step": 2800
    },
    {
      "epoch": 6.331877729257642,
      "grad_norm": 2.1936194896698,
      "learning_rate": 3.7340611353711794e-05,
      "loss": 0.2133,
      "step": 2900
    },
    {
      "epoch": 6.550218340611353,
      "grad_norm": 9.00805950164795,
      "learning_rate": 3.6903930131004365e-05,
      "loss": 0.2392,
      "step": 3000
    },
    {
      "epoch": 6.7685589519650655,
      "grad_norm": 6.562851905822754,
      "learning_rate": 3.646724890829695e-05,
      "loss": 0.2499,
      "step": 3100
    },
    {
      "epoch": 6.986899563318778,
      "grad_norm": 1.836311936378479,
      "learning_rate": 3.603056768558952e-05,
      "loss": 0.2178,
      "step": 3200
    },
    {
      "epoch": 7.205240174672489,
      "grad_norm": 1.634484887123108,
      "learning_rate": 3.55938864628821e-05,
      "loss": 0.2038,
      "step": 3300
    },
    {
      "epoch": 7.423580786026201,
      "grad_norm": 1.4176255464553833,
      "learning_rate": 3.515720524017467e-05,
      "loss": 0.2002,
      "step": 3400
    },
    {
      "epoch": 7.641921397379913,
      "grad_norm": 15.457743644714355,
      "learning_rate": 3.472052401746725e-05,
      "loss": 0.2101,
      "step": 3500
    },
    {
      "epoch": 7.860262008733624,
      "grad_norm": 0.9797011613845825,
      "learning_rate": 3.428384279475983e-05,
      "loss": 0.2085,
      "step": 3600
    },
    {
      "epoch": 8.078602620087336,
      "grad_norm": 7.1302080154418945,
      "learning_rate": 3.3847161572052405e-05,
      "loss": 0.214,
      "step": 3700
    },
    {
      "epoch": 8.296943231441048,
      "grad_norm": 3.4887049198150635,
      "learning_rate": 3.341048034934498e-05,
      "loss": 0.2084,
      "step": 3800
    },
    {
      "epoch": 8.51528384279476,
      "grad_norm": 1.9249945878982544,
      "learning_rate": 3.2973799126637555e-05,
      "loss": 0.1963,
      "step": 3900
    },
    {
      "epoch": 8.733624454148472,
      "grad_norm": 2.4285268783569336,
      "learning_rate": 3.253711790393013e-05,
      "loss": 0.2131,
      "step": 4000
    },
    {
      "epoch": 8.733624454148472,
      "eval_f1_macro": 0.8760581282709186,
      "eval_iou_Block": 0.7833663061208586,
      "eval_iou_unlabeled": 0.7748183330254232,
      "eval_loss": 0.3761305510997772,
      "eval_macro_precision": 0.8757911584190172,
      "eval_macro_recall": 0.8763252609357743,
      "eval_mean_accuracy": 0.8763252609357743,
      "eval_mean_iou": 0.779092319573141,
      "eval_overall_accuracy": 0.8758834916718152,
      "eval_precision_Block": 0.892780011379133,
      "eval_precision_unlabeled": 0.8588023054589016,
      "eval_recall_Block": 0.8647188448212464,
      "eval_recall_unlabeled": 0.8879316770503024,
      "eval_runtime": 2.466,
      "eval_samples_per_second": 39.741,
      "eval_steps_per_second": 10.138,
      "step": 4000
    },
    {
      "epoch": 8.951965065502183,
      "grad_norm": 10.06704330444336,
      "learning_rate": 3.2100436681222704e-05,
      "loss": 0.2121,
      "step": 4100
    },
    {
      "epoch": 9.170305676855895,
      "grad_norm": 0.9693633317947388,
      "learning_rate": 3.166375545851529e-05,
      "loss": 0.1859,
      "step": 4200
    },
    {
      "epoch": 9.388646288209607,
      "grad_norm": 3.9031503200531006,
      "learning_rate": 3.122707423580786e-05,
      "loss": 0.1939,
      "step": 4300
    },
    {
      "epoch": 9.606986899563319,
      "grad_norm": 1.5856047868728638,
      "learning_rate": 3.079039301310044e-05,
      "loss": 0.1923,
      "step": 4400
    },
    {
      "epoch": 9.825327510917031,
      "grad_norm": 0.795579195022583,
      "learning_rate": 3.0353711790393013e-05,
      "loss": 0.1955,
      "step": 4500
    },
    {
      "epoch": 10.043668122270743,
      "grad_norm": 10.050332069396973,
      "learning_rate": 2.9917030567685588e-05,
      "loss": 0.1747,
      "step": 4600
    },
    {
      "epoch": 10.262008733624453,
      "grad_norm": 2.639340877532959,
      "learning_rate": 2.948034934497817e-05,
      "loss": 0.1865,
      "step": 4700
    },
    {
      "epoch": 10.480349344978166,
      "grad_norm": 1.1191246509552002,
      "learning_rate": 2.9043668122270744e-05,
      "loss": 0.2082,
      "step": 4800
    },
    {
      "epoch": 10.698689956331878,
      "grad_norm": 4.833591461181641,
      "learning_rate": 2.860698689956332e-05,
      "loss": 0.1922,
      "step": 4900
    },
    {
      "epoch": 10.91703056768559,
      "grad_norm": 1.3311655521392822,
      "learning_rate": 2.8170305676855897e-05,
      "loss": 0.1791,
      "step": 5000
    },
    {
      "epoch": 11.135371179039302,
      "grad_norm": 2.5609874725341797,
      "learning_rate": 2.7733624454148472e-05,
      "loss": 0.1688,
      "step": 5100
    },
    {
      "epoch": 11.353711790393014,
      "grad_norm": 8.94747257232666,
      "learning_rate": 2.7296943231441047e-05,
      "loss": 0.1707,
      "step": 5200
    },
    {
      "epoch": 11.572052401746724,
      "grad_norm": 7.85179328918457,
      "learning_rate": 2.686026200873363e-05,
      "loss": 0.1582,
      "step": 5300
    },
    {
      "epoch": 11.790393013100436,
      "grad_norm": 1.0634857416152954,
      "learning_rate": 2.6423580786026203e-05,
      "loss": 0.1676,
      "step": 5400
    },
    {
      "epoch": 12.008733624454148,
      "grad_norm": 4.931596755981445,
      "learning_rate": 2.5986899563318778e-05,
      "loss": 0.1689,
      "step": 5500
    },
    {
      "epoch": 12.22707423580786,
      "grad_norm": 2.3094184398651123,
      "learning_rate": 2.5550218340611353e-05,
      "loss": 0.158,
      "step": 5600
    },
    {
      "epoch": 12.445414847161572,
      "grad_norm": 0.5288086533546448,
      "learning_rate": 2.511353711790393e-05,
      "loss": 0.1584,
      "step": 5700
    },
    {
      "epoch": 12.663755458515285,
      "grad_norm": 5.815174579620361,
      "learning_rate": 2.467685589519651e-05,
      "loss": 0.1551,
      "step": 5800
    },
    {
      "epoch": 12.882096069868995,
      "grad_norm": 3.5986385345458984,
      "learning_rate": 2.4240174672489087e-05,
      "loss": 0.1656,
      "step": 5900
    },
    {
      "epoch": 13.100436681222707,
      "grad_norm": 1.4932994842529297,
      "learning_rate": 2.3803493449781662e-05,
      "loss": 0.1629,
      "step": 6000
    },
    {
      "epoch": 13.100436681222707,
      "eval_f1_macro": 0.879732671190084,
      "eval_iou_Block": 0.788542164276829,
      "eval_iou_unlabeled": 0.7810766084135512,
      "eval_loss": 0.45266810059547424,
      "eval_macro_precision": 0.8794576132116845,
      "eval_macro_recall": 0.880007901276838,
      "eval_mean_accuracy": 0.880007901276838,
      "eval_mean_iou": 0.7848093863451902,
      "eval_overall_accuracy": 0.8794728103949099,
      "eval_precision_Block": 0.898180869453203,
      "eval_precision_unlabeled": 0.8607343569701659,
      "eval_recall_Block": 0.8659496859562691,
      "eval_recall_unlabeled": 0.8940661165974069,
      "eval_runtime": 2.4811,
      "eval_samples_per_second": 39.498,
      "eval_steps_per_second": 10.076,
      "step": 6000
    },
    {
      "epoch": 13.318777292576419,
      "grad_norm": 3.2962231636047363,
      "learning_rate": 2.3366812227074237e-05,
      "loss": 0.1681,
      "step": 6100
    },
    {
      "epoch": 13.537117903930131,
      "grad_norm": 7.63782262802124,
      "learning_rate": 2.2930131004366815e-05,
      "loss": 0.1828,
      "step": 6200
    },
    {
      "epoch": 13.755458515283843,
      "grad_norm": 3.259075164794922,
      "learning_rate": 2.249344978165939e-05,
      "loss": 0.1533,
      "step": 6300
    },
    {
      "epoch": 13.973799126637555,
      "grad_norm": 1.6935347318649292,
      "learning_rate": 2.2056768558951964e-05,
      "loss": 0.1456,
      "step": 6400
    },
    {
      "epoch": 14.192139737991265,
      "grad_norm": 0.7526381611824036,
      "learning_rate": 2.1620087336244542e-05,
      "loss": 0.1583,
      "step": 6500
    },
    {
      "epoch": 14.410480349344978,
      "grad_norm": 2.9646973609924316,
      "learning_rate": 2.1183406113537117e-05,
      "loss": 0.1397,
      "step": 6600
    },
    {
      "epoch": 14.62882096069869,
      "grad_norm": 0.9281635284423828,
      "learning_rate": 2.0746724890829695e-05,
      "loss": 0.1573,
      "step": 6700
    },
    {
      "epoch": 14.847161572052402,
      "grad_norm": 6.803644180297852,
      "learning_rate": 2.0310043668122273e-05,
      "loss": 0.1482,
      "step": 6800
    },
    {
      "epoch": 15.065502183406114,
      "grad_norm": 1.493457555770874,
      "learning_rate": 1.9873362445414848e-05,
      "loss": 0.1569,
      "step": 6900
    },
    {
      "epoch": 15.283842794759826,
      "grad_norm": 1.7640150785446167,
      "learning_rate": 1.9436681222707426e-05,
      "loss": 0.1426,
      "step": 7000
    },
    {
      "epoch": 15.502183406113538,
      "grad_norm": 1.2459313869476318,
      "learning_rate": 1.9e-05,
      "loss": 0.1715,
      "step": 7100
    },
    {
      "epoch": 15.720524017467248,
      "grad_norm": 23.28874969482422,
      "learning_rate": 1.8563318777292576e-05,
      "loss": 0.1705,
      "step": 7200
    },
    {
      "epoch": 15.93886462882096,
      "grad_norm": 1.6246145963668823,
      "learning_rate": 1.8126637554585154e-05,
      "loss": 0.1552,
      "step": 7300
    },
    {
      "epoch": 16.157205240174672,
      "grad_norm": 6.393835544586182,
      "learning_rate": 1.768995633187773e-05,
      "loss": 0.1395,
      "step": 7400
    },
    {
      "epoch": 16.375545851528383,
      "grad_norm": 2.1721384525299072,
      "learning_rate": 1.7253275109170307e-05,
      "loss": 0.1554,
      "step": 7500
    },
    {
      "epoch": 16.593886462882097,
      "grad_norm": 0.7352665066719055,
      "learning_rate": 1.6816593886462885e-05,
      "loss": 0.1333,
      "step": 7600
    },
    {
      "epoch": 16.812227074235807,
      "grad_norm": 2.329925775527954,
      "learning_rate": 1.637991266375546e-05,
      "loss": 0.1324,
      "step": 7700
    },
    {
      "epoch": 17.03056768558952,
      "grad_norm": 0.7591439485549927,
      "learning_rate": 1.5943231441048035e-05,
      "loss": 0.1403,
      "step": 7800
    },
    {
      "epoch": 17.24890829694323,
      "grad_norm": 0.6788544058799744,
      "learning_rate": 1.5506550218340613e-05,
      "loss": 0.1396,
      "step": 7900
    },
    {
      "epoch": 17.467248908296945,
      "grad_norm": 0.6304286122322083,
      "learning_rate": 1.5069868995633187e-05,
      "loss": 0.1453,
      "step": 8000
    },
    {
      "epoch": 17.467248908296945,
      "eval_f1_macro": 0.8800281494754253,
      "eval_iou_Block": 0.788027250383753,
      "eval_iou_unlabeled": 0.7820741548696853,
      "eval_loss": 0.4670972228050232,
      "eval_macro_precision": 0.8797621452675667,
      "eval_macro_recall": 0.8802943145905928,
      "eval_mean_accuracy": 0.8802943145905928,
      "eval_mean_iou": 0.7850507026267192,
      "eval_overall_accuracy": 0.8796095166887555,
      "eval_precision_Block": 0.901464226806112,
      "eval_precision_unlabeled": 0.8580600637290213,
      "eval_recall_Block": 0.8623029103633119,
      "eval_recall_unlabeled": 0.8982857188178737,
      "eval_runtime": 2.4631,
      "eval_samples_per_second": 39.788,
      "eval_steps_per_second": 10.15,
      "step": 8000
    }
  ],
  "logging_steps": 100,
  "max_steps": 11450,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 25,
  "save_steps": 2000,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 30,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.605966014452859e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
