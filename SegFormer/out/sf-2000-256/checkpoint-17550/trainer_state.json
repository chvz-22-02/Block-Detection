{
  "best_global_step": 6000,
  "best_metric": 0.7379811722405503,
  "best_model_checkpoint": "out/sf-2000-256\\checkpoint-6000",
  "epoch": 25.0,
  "eval_steps": 2000,
  "global_step": 17550,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.14245014245014245,
      "grad_norm": 1.6842381954193115,
      "learning_rate": 4.971794871794872e-05,
      "loss": 0.4836,
      "step": 100
    },
    {
      "epoch": 0.2849002849002849,
      "grad_norm": 2.1249120235443115,
      "learning_rate": 4.943304843304844e-05,
      "loss": 0.4373,
      "step": 200
    },
    {
      "epoch": 0.42735042735042733,
      "grad_norm": 5.119114875793457,
      "learning_rate": 4.9148148148148145e-05,
      "loss": 0.3963,
      "step": 300
    },
    {
      "epoch": 0.5698005698005698,
      "grad_norm": 1.4787745475769043,
      "learning_rate": 4.886324786324786e-05,
      "loss": 0.4065,
      "step": 400
    },
    {
      "epoch": 0.7122507122507122,
      "grad_norm": 1.8916351795196533,
      "learning_rate": 4.857834757834758e-05,
      "loss": 0.3975,
      "step": 500
    },
    {
      "epoch": 0.8547008547008547,
      "grad_norm": 4.815206050872803,
      "learning_rate": 4.8293447293447296e-05,
      "loss": 0.3883,
      "step": 600
    },
    {
      "epoch": 0.9971509971509972,
      "grad_norm": 4.219009876251221,
      "learning_rate": 4.800854700854701e-05,
      "loss": 0.3863,
      "step": 700
    },
    {
      "epoch": 1.1396011396011396,
      "grad_norm": 9.050135612487793,
      "learning_rate": 4.7723646723646726e-05,
      "loss": 0.3662,
      "step": 800
    },
    {
      "epoch": 1.282051282051282,
      "grad_norm": 3.013221502304077,
      "learning_rate": 4.743874643874644e-05,
      "loss": 0.3683,
      "step": 900
    },
    {
      "epoch": 1.4245014245014245,
      "grad_norm": 22.13205909729004,
      "learning_rate": 4.7153846153846155e-05,
      "loss": 0.3738,
      "step": 1000
    },
    {
      "epoch": 1.566951566951567,
      "grad_norm": 4.12197732925415,
      "learning_rate": 4.686894586894588e-05,
      "loss": 0.3537,
      "step": 1100
    },
    {
      "epoch": 1.7094017094017095,
      "grad_norm": 2.59728741645813,
      "learning_rate": 4.6584045584045585e-05,
      "loss": 0.3599,
      "step": 1200
    },
    {
      "epoch": 1.8518518518518519,
      "grad_norm": 5.609375,
      "learning_rate": 4.62991452991453e-05,
      "loss": 0.3403,
      "step": 1300
    },
    {
      "epoch": 1.9943019943019942,
      "grad_norm": 5.306839942932129,
      "learning_rate": 4.6014245014245014e-05,
      "loss": 0.3472,
      "step": 1400
    },
    {
      "epoch": 2.1367521367521367,
      "grad_norm": 6.676325798034668,
      "learning_rate": 4.572934472934473e-05,
      "loss": 0.3511,
      "step": 1500
    },
    {
      "epoch": 2.2792022792022792,
      "grad_norm": 1.3603672981262207,
      "learning_rate": 4.5444444444444444e-05,
      "loss": 0.3616,
      "step": 1600
    },
    {
      "epoch": 2.421652421652422,
      "grad_norm": 1.0907559394836426,
      "learning_rate": 4.515954415954416e-05,
      "loss": 0.3059,
      "step": 1700
    },
    {
      "epoch": 2.564102564102564,
      "grad_norm": 4.222354888916016,
      "learning_rate": 4.487464387464388e-05,
      "loss": 0.3337,
      "step": 1800
    },
    {
      "epoch": 2.7065527065527064,
      "grad_norm": 3.6803572177886963,
      "learning_rate": 4.4589743589743595e-05,
      "loss": 0.3383,
      "step": 1900
    },
    {
      "epoch": 2.849002849002849,
      "grad_norm": 0.5980291366577148,
      "learning_rate": 4.430484330484331e-05,
      "loss": 0.3283,
      "step": 2000
    },
    {
      "epoch": 2.849002849002849,
      "eval_f1_macro": 0.8345401382299893,
      "eval_iou_Block": 0.7416285893559679,
      "eval_iou_unlabeled": 0.6847596514533404,
      "eval_loss": 0.45441117882728577,
      "eval_macro_precision": 0.8305138912188563,
      "eval_macro_recall": 0.8386056130880855,
      "eval_mean_accuracy": 0.8386056130880855,
      "eval_mean_iou": 0.7131941204046541,
      "eval_overall_accuracy": 0.8345077771406907,
      "eval_precision_Block": 0.8928621670943042,
      "eval_precision_unlabeled": 0.7681656153434083,
      "eval_recall_Block": 0.8140736165035819,
      "eval_recall_unlabeled": 0.8631376096725891,
      "eval_runtime": 4.6626,
      "eval_samples_per_second": 44.61,
      "eval_steps_per_second": 11.153,
      "step": 2000
    },
    {
      "epoch": 2.9914529914529915,
      "grad_norm": 1.4416956901550293,
      "learning_rate": 4.4019943019943024e-05,
      "loss": 0.347,
      "step": 2100
    },
    {
      "epoch": 3.133903133903134,
      "grad_norm": 0.8590454459190369,
      "learning_rate": 4.373504273504274e-05,
      "loss": 0.3197,
      "step": 2200
    },
    {
      "epoch": 3.2763532763532766,
      "grad_norm": 1.9328043460845947,
      "learning_rate": 4.345014245014245e-05,
      "loss": 0.3152,
      "step": 2300
    },
    {
      "epoch": 3.4188034188034186,
      "grad_norm": 5.44299840927124,
      "learning_rate": 4.316524216524216e-05,
      "loss": 0.3281,
      "step": 2400
    },
    {
      "epoch": 3.561253561253561,
      "grad_norm": 1.2191959619522095,
      "learning_rate": 4.288034188034188e-05,
      "loss": 0.3076,
      "step": 2500
    },
    {
      "epoch": 3.7037037037037037,
      "grad_norm": 1.5574930906295776,
      "learning_rate": 4.25954415954416e-05,
      "loss": 0.2938,
      "step": 2600
    },
    {
      "epoch": 3.8461538461538463,
      "grad_norm": 7.60322380065918,
      "learning_rate": 4.231054131054131e-05,
      "loss": 0.3171,
      "step": 2700
    },
    {
      "epoch": 3.9886039886039883,
      "grad_norm": 0.9114205837249756,
      "learning_rate": 4.202564102564103e-05,
      "loss": 0.3028,
      "step": 2800
    },
    {
      "epoch": 4.131054131054131,
      "grad_norm": 2.592663288116455,
      "learning_rate": 4.174074074074074e-05,
      "loss": 0.2984,
      "step": 2900
    },
    {
      "epoch": 4.273504273504273,
      "grad_norm": 2.3506722450256348,
      "learning_rate": 4.145584045584046e-05,
      "loss": 0.2965,
      "step": 3000
    },
    {
      "epoch": 4.415954415954416,
      "grad_norm": 1.2890206575393677,
      "learning_rate": 4.117094017094018e-05,
      "loss": 0.3045,
      "step": 3100
    },
    {
      "epoch": 4.5584045584045585,
      "grad_norm": 1.277919888496399,
      "learning_rate": 4.0886039886039886e-05,
      "loss": 0.2984,
      "step": 3200
    },
    {
      "epoch": 4.700854700854701,
      "grad_norm": 1.9931524991989136,
      "learning_rate": 4.06011396011396e-05,
      "loss": 0.2767,
      "step": 3300
    },
    {
      "epoch": 4.843304843304844,
      "grad_norm": 1.3136433362960815,
      "learning_rate": 4.0316239316239316e-05,
      "loss": 0.2958,
      "step": 3400
    },
    {
      "epoch": 4.985754985754986,
      "grad_norm": 2.403637170791626,
      "learning_rate": 4.003133903133903e-05,
      "loss": 0.2977,
      "step": 3500
    },
    {
      "epoch": 5.128205128205128,
      "grad_norm": 1.4234241247177124,
      "learning_rate": 3.9746438746438745e-05,
      "loss": 0.2722,
      "step": 3600
    },
    {
      "epoch": 5.27065527065527,
      "grad_norm": 1.009745478630066,
      "learning_rate": 3.946153846153846e-05,
      "loss": 0.2601,
      "step": 3700
    },
    {
      "epoch": 5.413105413105413,
      "grad_norm": 2.5382258892059326,
      "learning_rate": 3.917663817663818e-05,
      "loss": 0.2825,
      "step": 3800
    },
    {
      "epoch": 5.555555555555555,
      "grad_norm": 2.8646950721740723,
      "learning_rate": 3.8891737891737896e-05,
      "loss": 0.2885,
      "step": 3900
    },
    {
      "epoch": 5.698005698005698,
      "grad_norm": 34.01416778564453,
      "learning_rate": 3.860683760683761e-05,
      "loss": 0.2852,
      "step": 4000
    },
    {
      "epoch": 5.698005698005698,
      "eval_f1_macro": 0.8423964197747638,
      "eval_iou_Block": 0.7583827309005122,
      "eval_iou_unlabeled": 0.695261628429562,
      "eval_loss": 0.42165467143058777,
      "eval_macro_precision": 0.8392842051438156,
      "eval_macro_recall": 0.845531801602031,
      "eval_mean_accuracy": 0.845531801602031,
      "eval_mean_iou": 0.7268221796650371,
      "eval_overall_accuracy": 0.8442435631385217,
      "eval_precision_Block": 0.8888721756775403,
      "eval_precision_unlabeled": 0.7896962346100911,
      "eval_recall_Block": 0.8378196671992542,
      "eval_recall_unlabeled": 0.853243936004808,
      "eval_runtime": 4.6966,
      "eval_samples_per_second": 44.287,
      "eval_steps_per_second": 11.072,
      "step": 4000
    },
    {
      "epoch": 5.84045584045584,
      "grad_norm": 0.7375732064247131,
      "learning_rate": 3.8321937321937326e-05,
      "loss": 0.3024,
      "step": 4100
    },
    {
      "epoch": 5.982905982905983,
      "grad_norm": 1.0427076816558838,
      "learning_rate": 3.803703703703704e-05,
      "loss": 0.2699,
      "step": 4200
    },
    {
      "epoch": 6.1253561253561255,
      "grad_norm": 6.378363132476807,
      "learning_rate": 3.7752136752136755e-05,
      "loss": 0.2679,
      "step": 4300
    },
    {
      "epoch": 6.267806267806268,
      "grad_norm": 3.833421468734741,
      "learning_rate": 3.746723646723647e-05,
      "loss": 0.2567,
      "step": 4400
    },
    {
      "epoch": 6.410256410256411,
      "grad_norm": 2.591965675354004,
      "learning_rate": 3.7182336182336185e-05,
      "loss": 0.2789,
      "step": 4500
    },
    {
      "epoch": 6.552706552706553,
      "grad_norm": 1.4589958190917969,
      "learning_rate": 3.68974358974359e-05,
      "loss": 0.2524,
      "step": 4600
    },
    {
      "epoch": 6.695156695156696,
      "grad_norm": 2.2366857528686523,
      "learning_rate": 3.6612535612535614e-05,
      "loss": 0.2712,
      "step": 4700
    },
    {
      "epoch": 6.837606837606837,
      "grad_norm": 0.47310706973075867,
      "learning_rate": 3.632763532763533e-05,
      "loss": 0.2504,
      "step": 4800
    },
    {
      "epoch": 6.98005698005698,
      "grad_norm": 39.0793571472168,
      "learning_rate": 3.6042735042735044e-05,
      "loss": 0.2604,
      "step": 4900
    },
    {
      "epoch": 7.122507122507122,
      "grad_norm": 1.4487494230270386,
      "learning_rate": 3.575783475783476e-05,
      "loss": 0.2407,
      "step": 5000
    },
    {
      "epoch": 7.264957264957265,
      "grad_norm": 0.9961695075035095,
      "learning_rate": 3.547293447293448e-05,
      "loss": 0.2572,
      "step": 5100
    },
    {
      "epoch": 7.407407407407407,
      "grad_norm": 0.8051223158836365,
      "learning_rate": 3.518803418803419e-05,
      "loss": 0.2538,
      "step": 5200
    },
    {
      "epoch": 7.54985754985755,
      "grad_norm": 1.1898478269577026,
      "learning_rate": 3.49031339031339e-05,
      "loss": 0.2369,
      "step": 5300
    },
    {
      "epoch": 7.6923076923076925,
      "grad_norm": 2.3531434535980225,
      "learning_rate": 3.461823361823362e-05,
      "loss": 0.2457,
      "step": 5400
    },
    {
      "epoch": 7.834757834757835,
      "grad_norm": 26.851741790771484,
      "learning_rate": 3.433333333333333e-05,
      "loss": 0.2632,
      "step": 5500
    },
    {
      "epoch": 7.977207977207978,
      "grad_norm": 4.999186038970947,
      "learning_rate": 3.404843304843305e-05,
      "loss": 0.2632,
      "step": 5600
    },
    {
      "epoch": 8.11965811965812,
      "grad_norm": 8.755919456481934,
      "learning_rate": 3.376353276353276e-05,
      "loss": 0.2248,
      "step": 5700
    },
    {
      "epoch": 8.262108262108262,
      "grad_norm": 10.244897842407227,
      "learning_rate": 3.347863247863248e-05,
      "loss": 0.2471,
      "step": 5800
    },
    {
      "epoch": 8.404558404558404,
      "grad_norm": 1.7644786834716797,
      "learning_rate": 3.31937321937322e-05,
      "loss": 0.2343,
      "step": 5900
    },
    {
      "epoch": 8.547008547008547,
      "grad_norm": 3.1792287826538086,
      "learning_rate": 3.290883190883191e-05,
      "loss": 0.2245,
      "step": 6000
    },
    {
      "epoch": 8.547008547008547,
      "eval_f1_macro": 0.8488962171704987,
      "eval_iou_Block": 0.7733299035198807,
      "eval_iou_unlabeled": 0.7026324409612197,
      "eval_loss": 0.4532497823238373,
      "eval_macro_precision": 0.8475458638475221,
      "eval_macro_recall": 0.8502508802646774,
      "eval_mean_accuracy": 0.8502508802646774,
      "eval_mean_iou": 0.7379811722405503,
      "eval_overall_accuracy": 0.852388491997352,
      "eval_precision_Block": 0.8815039413701883,
      "eval_precision_unlabeled": 0.8135877863248558,
      "eval_recall_Block": 0.86304785027474,
      "eval_recall_unlabeled": 0.8374539102546149,
      "eval_runtime": 4.5822,
      "eval_samples_per_second": 45.393,
      "eval_steps_per_second": 11.348,
      "step": 6000
    },
    {
      "epoch": 8.68945868945869,
      "grad_norm": 3.904900074005127,
      "learning_rate": 3.262393162393163e-05,
      "loss": 0.2411,
      "step": 6100
    },
    {
      "epoch": 8.831908831908832,
      "grad_norm": 26.136592864990234,
      "learning_rate": 3.233903133903134e-05,
      "loss": 0.2386,
      "step": 6200
    },
    {
      "epoch": 8.974358974358974,
      "grad_norm": 0.6664454340934753,
      "learning_rate": 3.205413105413106e-05,
      "loss": 0.2305,
      "step": 6300
    },
    {
      "epoch": 9.116809116809117,
      "grad_norm": 1.379019021987915,
      "learning_rate": 3.176923076923077e-05,
      "loss": 0.2301,
      "step": 6400
    },
    {
      "epoch": 9.25925925925926,
      "grad_norm": 9.97450065612793,
      "learning_rate": 3.1484330484330486e-05,
      "loss": 0.219,
      "step": 6500
    },
    {
      "epoch": 9.401709401709402,
      "grad_norm": 1.9956945180892944,
      "learning_rate": 3.11994301994302e-05,
      "loss": 0.2343,
      "step": 6600
    },
    {
      "epoch": 9.544159544159545,
      "grad_norm": 8.102910041809082,
      "learning_rate": 3.0914529914529916e-05,
      "loss": 0.2259,
      "step": 6700
    },
    {
      "epoch": 9.686609686609687,
      "grad_norm": 5.026116371154785,
      "learning_rate": 3.062962962962963e-05,
      "loss": 0.2248,
      "step": 6800
    },
    {
      "epoch": 9.82905982905983,
      "grad_norm": 2.224022388458252,
      "learning_rate": 3.0344729344729345e-05,
      "loss": 0.2281,
      "step": 6900
    },
    {
      "epoch": 9.971509971509972,
      "grad_norm": 2.387406826019287,
      "learning_rate": 3.005982905982906e-05,
      "loss": 0.213,
      "step": 7000
    },
    {
      "epoch": 10.113960113960115,
      "grad_norm": 3.3787426948547363,
      "learning_rate": 2.9774928774928778e-05,
      "loss": 0.1952,
      "step": 7100
    },
    {
      "epoch": 10.256410256410255,
      "grad_norm": 1.5078576803207397,
      "learning_rate": 2.9490028490028493e-05,
      "loss": 0.2194,
      "step": 7200
    },
    {
      "epoch": 10.398860398860398,
      "grad_norm": 3.006258964538574,
      "learning_rate": 2.9205128205128208e-05,
      "loss": 0.2078,
      "step": 7300
    },
    {
      "epoch": 10.54131054131054,
      "grad_norm": 7.590031623840332,
      "learning_rate": 2.8920227920227922e-05,
      "loss": 0.2112,
      "step": 7400
    },
    {
      "epoch": 10.683760683760683,
      "grad_norm": 6.421568870544434,
      "learning_rate": 2.8635327635327637e-05,
      "loss": 0.1983,
      "step": 7500
    },
    {
      "epoch": 10.826210826210826,
      "grad_norm": 1.1680850982666016,
      "learning_rate": 2.835042735042735e-05,
      "loss": 0.2321,
      "step": 7600
    },
    {
      "epoch": 10.968660968660968,
      "grad_norm": 2.573547840118408,
      "learning_rate": 2.8065527065527063e-05,
      "loss": 0.2284,
      "step": 7700
    },
    {
      "epoch": 11.11111111111111,
      "grad_norm": 3.578498601913452,
      "learning_rate": 2.7780626780626785e-05,
      "loss": 0.1992,
      "step": 7800
    },
    {
      "epoch": 11.253561253561253,
      "grad_norm": 0.6722696423530579,
      "learning_rate": 2.74957264957265e-05,
      "loss": 0.206,
      "step": 7900
    },
    {
      "epoch": 11.396011396011396,
      "grad_norm": 4.3273138999938965,
      "learning_rate": 2.721082621082621e-05,
      "loss": 0.1938,
      "step": 8000
    },
    {
      "epoch": 11.396011396011396,
      "eval_f1_macro": 0.8427481680896665,
      "eval_iou_Block": 0.7626888228815031,
      "eval_iou_unlabeled": 0.6939767422267343,
      "eval_loss": 0.517774224281311,
      "eval_macro_precision": 0.8405988382266931,
      "eval_macro_recall": 0.8449085173860944,
      "eval_mean_accuracy": 0.8449085173860944,
      "eval_mean_iou": 0.7283327825541187,
      "eval_overall_accuracy": 0.8457171550163856,
      "eval_precision_Block": 0.881575107908391,
      "eval_precision_unlabeled": 0.7996225685449951,
      "eval_recall_Block": 0.849749486092276,
      "eval_recall_unlabeled": 0.8400675486799128,
      "eval_runtime": 4.3851,
      "eval_samples_per_second": 47.433,
      "eval_steps_per_second": 11.858,
      "step": 8000
    },
    {
      "epoch": 11.538461538461538,
      "grad_norm": 0.6943550705909729,
      "learning_rate": 2.6925925925925925e-05,
      "loss": 0.224,
      "step": 8100
    },
    {
      "epoch": 11.68091168091168,
      "grad_norm": 7.959578514099121,
      "learning_rate": 2.664102564102564e-05,
      "loss": 0.2103,
      "step": 8200
    },
    {
      "epoch": 11.823361823361823,
      "grad_norm": 1.4251176118850708,
      "learning_rate": 2.6356125356125355e-05,
      "loss": 0.2082,
      "step": 8300
    },
    {
      "epoch": 11.965811965811966,
      "grad_norm": 1.7541230916976929,
      "learning_rate": 2.6071225071225076e-05,
      "loss": 0.2015,
      "step": 8400
    },
    {
      "epoch": 12.108262108262108,
      "grad_norm": 2.347205877304077,
      "learning_rate": 2.5786324786324788e-05,
      "loss": 0.1964,
      "step": 8500
    },
    {
      "epoch": 12.250712250712251,
      "grad_norm": 1.6443254947662354,
      "learning_rate": 2.5501424501424503e-05,
      "loss": 0.1834,
      "step": 8600
    },
    {
      "epoch": 12.393162393162394,
      "grad_norm": 1.5901765823364258,
      "learning_rate": 2.5216524216524217e-05,
      "loss": 0.1723,
      "step": 8700
    },
    {
      "epoch": 12.535612535612536,
      "grad_norm": 0.8206125497817993,
      "learning_rate": 2.4931623931623932e-05,
      "loss": 0.2043,
      "step": 8800
    },
    {
      "epoch": 12.678062678062679,
      "grad_norm": 2.721773147583008,
      "learning_rate": 2.464672364672365e-05,
      "loss": 0.2147,
      "step": 8900
    },
    {
      "epoch": 12.820512820512821,
      "grad_norm": 2.687621593475342,
      "learning_rate": 2.436182336182336e-05,
      "loss": 0.1986,
      "step": 9000
    },
    {
      "epoch": 12.962962962962964,
      "grad_norm": 4.348321437835693,
      "learning_rate": 2.4076923076923076e-05,
      "loss": 0.2324,
      "step": 9100
    },
    {
      "epoch": 13.105413105413106,
      "grad_norm": 7.607950687408447,
      "learning_rate": 2.3792022792022794e-05,
      "loss": 0.1958,
      "step": 9200
    },
    {
      "epoch": 13.247863247863247,
      "grad_norm": 3.825556993484497,
      "learning_rate": 2.350712250712251e-05,
      "loss": 0.202,
      "step": 9300
    },
    {
      "epoch": 13.39031339031339,
      "grad_norm": 1.0926506519317627,
      "learning_rate": 2.3222222222222224e-05,
      "loss": 0.1797,
      "step": 9400
    },
    {
      "epoch": 13.532763532763532,
      "grad_norm": 3.271010160446167,
      "learning_rate": 2.293732193732194e-05,
      "loss": 0.1845,
      "step": 9500
    },
    {
      "epoch": 13.675213675213675,
      "grad_norm": 1.6854727268218994,
      "learning_rate": 2.2652421652421653e-05,
      "loss": 0.1904,
      "step": 9600
    },
    {
      "epoch": 13.817663817663817,
      "grad_norm": 13.6510591506958,
      "learning_rate": 2.2367521367521368e-05,
      "loss": 0.2183,
      "step": 9700
    },
    {
      "epoch": 13.96011396011396,
      "grad_norm": 2.207395315170288,
      "learning_rate": 2.2082621082621083e-05,
      "loss": 0.1948,
      "step": 9800
    },
    {
      "epoch": 14.102564102564102,
      "grad_norm": 9.576787948608398,
      "learning_rate": 2.17977207977208e-05,
      "loss": 0.1818,
      "step": 9900
    },
    {
      "epoch": 14.245014245014245,
      "grad_norm": 1.0135083198547363,
      "learning_rate": 2.1512820512820516e-05,
      "loss": 0.1978,
      "step": 10000
    },
    {
      "epoch": 14.245014245014245,
      "eval_f1_macro": 0.8486951512147735,
      "eval_iou_Block": 0.7637177352512012,
      "eval_iou_unlabeled": 0.7066493460407313,
      "eval_loss": 0.552802324295044,
      "eval_macro_precision": 0.8449232656397584,
      "eval_macro_recall": 0.8525008645205694,
      "eval_mean_accuracy": 0.8525008645205694,
      "eval_mean_iou": 0.7351835406459662,
      "eval_overall_accuracy": 0.8494228949913611,
      "eval_precision_Block": 0.900535467184565,
      "eval_precision_unlabeled": 0.7893110640949518,
      "eval_recall_Block": 0.8340743733317878,
      "eval_recall_unlabeled": 0.870927355709351,
      "eval_runtime": 4.5188,
      "eval_samples_per_second": 46.03,
      "eval_steps_per_second": 11.507,
      "step": 10000
    },
    {
      "epoch": 14.387464387464387,
      "grad_norm": 2.1974093914031982,
      "learning_rate": 2.1227920227920227e-05,
      "loss": 0.1844,
      "step": 10100
    },
    {
      "epoch": 14.52991452991453,
      "grad_norm": 5.072781562805176,
      "learning_rate": 2.0943019943019945e-05,
      "loss": 0.1935,
      "step": 10200
    },
    {
      "epoch": 14.672364672364672,
      "grad_norm": 2.283625364303589,
      "learning_rate": 2.065811965811966e-05,
      "loss": 0.1968,
      "step": 10300
    },
    {
      "epoch": 14.814814814814815,
      "grad_norm": 5.134234428405762,
      "learning_rate": 2.0373219373219375e-05,
      "loss": 0.1804,
      "step": 10400
    },
    {
      "epoch": 14.957264957264957,
      "grad_norm": 1.7886883020401,
      "learning_rate": 2.008831908831909e-05,
      "loss": 0.2044,
      "step": 10500
    },
    {
      "epoch": 15.0997150997151,
      "grad_norm": 2.2859976291656494,
      "learning_rate": 1.9803418803418804e-05,
      "loss": 0.183,
      "step": 10600
    },
    {
      "epoch": 15.242165242165242,
      "grad_norm": 3.7081069946289062,
      "learning_rate": 1.951851851851852e-05,
      "loss": 0.1822,
      "step": 10700
    },
    {
      "epoch": 15.384615384615385,
      "grad_norm": 2.9289932250976562,
      "learning_rate": 1.9233618233618234e-05,
      "loss": 0.1903,
      "step": 10800
    },
    {
      "epoch": 15.527065527065528,
      "grad_norm": 2.284263849258423,
      "learning_rate": 1.8948717948717952e-05,
      "loss": 0.1742,
      "step": 10900
    },
    {
      "epoch": 15.66951566951567,
      "grad_norm": 10.085226058959961,
      "learning_rate": 1.8663817663817666e-05,
      "loss": 0.1935,
      "step": 11000
    },
    {
      "epoch": 15.811965811965813,
      "grad_norm": 1.2177280187606812,
      "learning_rate": 1.8378917378917378e-05,
      "loss": 0.1794,
      "step": 11100
    },
    {
      "epoch": 15.954415954415955,
      "grad_norm": 1.35563063621521,
      "learning_rate": 1.8094017094017096e-05,
      "loss": 0.1617,
      "step": 11200
    },
    {
      "epoch": 16.096866096866098,
      "grad_norm": 0.9613946676254272,
      "learning_rate": 1.780911680911681e-05,
      "loss": 0.1656,
      "step": 11300
    },
    {
      "epoch": 16.23931623931624,
      "grad_norm": 1.6873141527175903,
      "learning_rate": 1.7524216524216525e-05,
      "loss": 0.1633,
      "step": 11400
    },
    {
      "epoch": 16.381766381766383,
      "grad_norm": 2.4600770473480225,
      "learning_rate": 1.723931623931624e-05,
      "loss": 0.1692,
      "step": 11500
    },
    {
      "epoch": 16.524216524216524,
      "grad_norm": 6.045141696929932,
      "learning_rate": 1.6954415954415955e-05,
      "loss": 0.1732,
      "step": 11600
    },
    {
      "epoch": 16.666666666666668,
      "grad_norm": 13.331477165222168,
      "learning_rate": 1.666951566951567e-05,
      "loss": 0.1708,
      "step": 11700
    },
    {
      "epoch": 16.80911680911681,
      "grad_norm": 1.9836958646774292,
      "learning_rate": 1.6384615384615384e-05,
      "loss": 0.184,
      "step": 11800
    },
    {
      "epoch": 16.951566951566953,
      "grad_norm": 6.286946773529053,
      "learning_rate": 1.6099715099715103e-05,
      "loss": 0.1761,
      "step": 11900
    },
    {
      "epoch": 17.094017094017094,
      "grad_norm": 3.39241886138916,
      "learning_rate": 1.5814814814814817e-05,
      "loss": 0.1714,
      "step": 12000
    },
    {
      "epoch": 17.094017094017094,
      "eval_f1_macro": 0.8484136876308296,
      "eval_iou_Block": 0.773418061275296,
      "eval_iou_unlabeled": 0.701307626621292,
      "eval_loss": 0.5574035048484802,
      "eval_macro_precision": 0.8473502204792482,
      "eval_macro_recall": 0.8494798275474101,
      "eval_mean_accuracy": 0.8494798275474101,
      "eval_mean_iou": 0.737362843948294,
      "eval_overall_accuracy": 0.8521003356346717,
      "eval_precision_Block": 0.879417367528812,
      "eval_precision_unlabeled": 0.8152830734296844,
      "eval_recall_Block": 0.8651676921353606,
      "eval_recall_unlabeled": 0.8337919629594597,
      "eval_runtime": 4.4602,
      "eval_samples_per_second": 46.635,
      "eval_steps_per_second": 11.659,
      "step": 12000
    },
    {
      "epoch": 17.236467236467238,
      "grad_norm": 1.7432746887207031,
      "learning_rate": 1.552991452991453e-05,
      "loss": 0.1635,
      "step": 12100
    },
    {
      "epoch": 17.37891737891738,
      "grad_norm": 7.293126583099365,
      "learning_rate": 1.5245014245014247e-05,
      "loss": 0.1613,
      "step": 12200
    },
    {
      "epoch": 17.521367521367523,
      "grad_norm": 1.2932168245315552,
      "learning_rate": 1.4960113960113961e-05,
      "loss": 0.1651,
      "step": 12300
    },
    {
      "epoch": 17.663817663817664,
      "grad_norm": 1.8502213954925537,
      "learning_rate": 1.4675213675213676e-05,
      "loss": 0.1798,
      "step": 12400
    },
    {
      "epoch": 17.806267806267805,
      "grad_norm": 4.927793979644775,
      "learning_rate": 1.439031339031339e-05,
      "loss": 0.1857,
      "step": 12500
    },
    {
      "epoch": 17.94871794871795,
      "grad_norm": 7.4024176597595215,
      "learning_rate": 1.4105413105413107e-05,
      "loss": 0.1804,
      "step": 12600
    },
    {
      "epoch": 18.09116809116809,
      "grad_norm": 6.056798934936523,
      "learning_rate": 1.382051282051282e-05,
      "loss": 0.1804,
      "step": 12700
    },
    {
      "epoch": 18.233618233618234,
      "grad_norm": 1.963045358657837,
      "learning_rate": 1.3535612535612535e-05,
      "loss": 0.164,
      "step": 12800
    },
    {
      "epoch": 18.376068376068375,
      "grad_norm": 1.6317555904388428,
      "learning_rate": 1.3250712250712252e-05,
      "loss": 0.1676,
      "step": 12900
    },
    {
      "epoch": 18.51851851851852,
      "grad_norm": 2.0842134952545166,
      "learning_rate": 1.2965811965811966e-05,
      "loss": 0.1656,
      "step": 13000
    },
    {
      "epoch": 18.66096866096866,
      "grad_norm": 4.170253753662109,
      "learning_rate": 1.2680911680911681e-05,
      "loss": 0.1716,
      "step": 13100
    },
    {
      "epoch": 18.803418803418804,
      "grad_norm": 6.912015438079834,
      "learning_rate": 1.2396011396011396e-05,
      "loss": 0.1686,
      "step": 13200
    },
    {
      "epoch": 18.945868945868945,
      "grad_norm": 2.5312488079071045,
      "learning_rate": 1.2111111111111112e-05,
      "loss": 0.1575,
      "step": 13300
    },
    {
      "epoch": 19.08831908831909,
      "grad_norm": 1.438463807106018,
      "learning_rate": 1.1826210826210827e-05,
      "loss": 0.1503,
      "step": 13400
    },
    {
      "epoch": 19.23076923076923,
      "grad_norm": 5.972098350524902,
      "learning_rate": 1.1541310541310542e-05,
      "loss": 0.1583,
      "step": 13500
    },
    {
      "epoch": 19.373219373219374,
      "grad_norm": 1.2999413013458252,
      "learning_rate": 1.1256410256410258e-05,
      "loss": 0.1663,
      "step": 13600
    },
    {
      "epoch": 19.515669515669515,
      "grad_norm": 1.763546109199524,
      "learning_rate": 1.0971509971509971e-05,
      "loss": 0.157,
      "step": 13700
    },
    {
      "epoch": 19.65811965811966,
      "grad_norm": 1.5508067607879639,
      "learning_rate": 1.0686609686609688e-05,
      "loss": 0.1722,
      "step": 13800
    },
    {
      "epoch": 19.8005698005698,
      "grad_norm": 1.3186548948287964,
      "learning_rate": 1.0401709401709402e-05,
      "loss": 0.1684,
      "step": 13900
    },
    {
      "epoch": 19.943019943019944,
      "grad_norm": 11.593215942382812,
      "learning_rate": 1.0116809116809117e-05,
      "loss": 0.1705,
      "step": 14000
    },
    {
      "epoch": 19.943019943019944,
      "eval_f1_macro": 0.8467106551864872,
      "eval_iou_Block": 0.7693018007621163,
      "eval_iou_unlabeled": 0.6997229944349299,
      "eval_loss": 0.6859096884727478,
      "eval_macro_precision": 0.8449666009980834,
      "eval_macro_recall": 0.8484619239007527,
      "eval_mean_accuracy": 0.8484619239007527,
      "eval_mean_iou": 0.734512397598523,
      "eval_overall_accuracy": 0.8499608223254864,
      "eval_precision_Block": 0.8821367690035623,
      "eval_precision_unlabeled": 0.8077964329926044,
      "eval_recall_Block": 0.8574351896703258,
      "eval_recall_unlabeled": 0.8394886581311796,
      "eval_runtime": 4.3508,
      "eval_samples_per_second": 47.808,
      "eval_steps_per_second": 11.952,
      "step": 14000
    },
    {
      "epoch": 20.085470085470085,
      "grad_norm": 2.567328691482544,
      "learning_rate": 9.831908831908834e-06,
      "loss": 0.1571,
      "step": 14100
    },
    {
      "epoch": 20.22792022792023,
      "grad_norm": 2.3947174549102783,
      "learning_rate": 9.547008547008547e-06,
      "loss": 0.157,
      "step": 14200
    },
    {
      "epoch": 20.37037037037037,
      "grad_norm": 1.1873764991760254,
      "learning_rate": 9.262108262108263e-06,
      "loss": 0.1555,
      "step": 14300
    },
    {
      "epoch": 20.51282051282051,
      "grad_norm": 1.2092257738113403,
      "learning_rate": 8.977207977207978e-06,
      "loss": 0.1598,
      "step": 14400
    },
    {
      "epoch": 20.655270655270655,
      "grad_norm": 0.9145981669425964,
      "learning_rate": 8.692307692307692e-06,
      "loss": 0.1585,
      "step": 14500
    },
    {
      "epoch": 20.797720797720796,
      "grad_norm": 7.661986827850342,
      "learning_rate": 8.407407407407409e-06,
      "loss": 0.1639,
      "step": 14600
    },
    {
      "epoch": 20.94017094017094,
      "grad_norm": 2.5130069255828857,
      "learning_rate": 8.122507122507122e-06,
      "loss": 0.1756,
      "step": 14700
    },
    {
      "epoch": 21.08262108262108,
      "grad_norm": 2.7418127059936523,
      "learning_rate": 7.837606837606838e-06,
      "loss": 0.1751,
      "step": 14800
    },
    {
      "epoch": 21.225071225071225,
      "grad_norm": 2.2590746879577637,
      "learning_rate": 7.552706552706552e-06,
      "loss": 0.1491,
      "step": 14900
    },
    {
      "epoch": 21.367521367521366,
      "grad_norm": 2.0644419193267822,
      "learning_rate": 7.267806267806268e-06,
      "loss": 0.1802,
      "step": 15000
    },
    {
      "epoch": 21.50997150997151,
      "grad_norm": 0.6048689484596252,
      "learning_rate": 6.9829059829059835e-06,
      "loss": 0.1434,
      "step": 15100
    },
    {
      "epoch": 21.65242165242165,
      "grad_norm": 8.9369535446167,
      "learning_rate": 6.698005698005698e-06,
      "loss": 0.1547,
      "step": 15200
    },
    {
      "epoch": 21.794871794871796,
      "grad_norm": 2.273254632949829,
      "learning_rate": 6.413105413105414e-06,
      "loss": 0.1622,
      "step": 15300
    },
    {
      "epoch": 21.937321937321936,
      "grad_norm": 10.13156795501709,
      "learning_rate": 6.1282051282051285e-06,
      "loss": 0.1536,
      "step": 15400
    },
    {
      "epoch": 22.07977207977208,
      "grad_norm": 1.6290888786315918,
      "learning_rate": 5.843304843304843e-06,
      "loss": 0.1594,
      "step": 15500
    },
    {
      "epoch": 22.22222222222222,
      "grad_norm": 0.6631240844726562,
      "learning_rate": 5.558404558404558e-06,
      "loss": 0.1519,
      "step": 15600
    },
    {
      "epoch": 22.364672364672366,
      "grad_norm": 1.3439102172851562,
      "learning_rate": 5.2735042735042744e-06,
      "loss": 0.1575,
      "step": 15700
    },
    {
      "epoch": 22.507122507122507,
      "grad_norm": 6.353684425354004,
      "learning_rate": 4.988603988603989e-06,
      "loss": 0.1525,
      "step": 15800
    },
    {
      "epoch": 22.64957264957265,
      "grad_norm": 0.8852589726448059,
      "learning_rate": 4.703703703703704e-06,
      "loss": 0.1475,
      "step": 15900
    },
    {
      "epoch": 22.79202279202279,
      "grad_norm": 7.316915035247803,
      "learning_rate": 4.418803418803419e-06,
      "loss": 0.1706,
      "step": 16000
    },
    {
      "epoch": 22.79202279202279,
      "eval_f1_macro": 0.8471532333617235,
      "eval_iou_Block": 0.7683081878668522,
      "eval_iou_unlabeled": 0.7013800812692828,
      "eval_loss": 0.6284128427505493,
      "eval_macro_precision": 0.8449037668830339,
      "eval_macro_recall": 0.8494147097473463,
      "eval_mean_accuracy": 0.8494147097473463,
      "eval_mean_iou": 0.7348441345680674,
      "eval_overall_accuracy": 0.8499583647801325,
      "eval_precision_Block": 0.8859173492953203,
      "eval_precision_unlabeled": 0.8038901844707477,
      "eval_recall_Block": 0.8526693406253689,
      "eval_recall_unlabeled": 0.8461600788693237,
      "eval_runtime": 4.619,
      "eval_samples_per_second": 45.031,
      "eval_steps_per_second": 11.258,
      "step": 16000
    },
    {
      "epoch": 22.934472934472936,
      "grad_norm": 8.290144920349121,
      "learning_rate": 4.133903133903133e-06,
      "loss": 0.1601,
      "step": 16100
    },
    {
      "epoch": 23.076923076923077,
      "grad_norm": 0.7727014422416687,
      "learning_rate": 3.84900284900285e-06,
      "loss": 0.1546,
      "step": 16200
    },
    {
      "epoch": 23.21937321937322,
      "grad_norm": 26.398679733276367,
      "learning_rate": 3.5641025641025646e-06,
      "loss": 0.1603,
      "step": 16300
    },
    {
      "epoch": 23.36182336182336,
      "grad_norm": 0.7470170259475708,
      "learning_rate": 3.2792022792022793e-06,
      "loss": 0.1507,
      "step": 16400
    },
    {
      "epoch": 23.504273504273506,
      "grad_norm": 1.2547361850738525,
      "learning_rate": 2.9943019943019945e-06,
      "loss": 0.1566,
      "step": 16500
    },
    {
      "epoch": 23.646723646723647,
      "grad_norm": 1.2505273818969727,
      "learning_rate": 2.7094017094017096e-06,
      "loss": 0.1502,
      "step": 16600
    },
    {
      "epoch": 23.789173789173788,
      "grad_norm": 2.2529711723327637,
      "learning_rate": 2.4245014245014244e-06,
      "loss": 0.1561,
      "step": 16700
    },
    {
      "epoch": 23.931623931623932,
      "grad_norm": 0.8053486943244934,
      "learning_rate": 2.13960113960114e-06,
      "loss": 0.1555,
      "step": 16800
    },
    {
      "epoch": 24.074074074074073,
      "grad_norm": 4.81893253326416,
      "learning_rate": 1.8547008547008547e-06,
      "loss": 0.1575,
      "step": 16900
    },
    {
      "epoch": 24.216524216524217,
      "grad_norm": 17.603574752807617,
      "learning_rate": 1.56980056980057e-06,
      "loss": 0.1553,
      "step": 17000
    },
    {
      "epoch": 24.358974358974358,
      "grad_norm": 2.204195737838745,
      "learning_rate": 1.284900284900285e-06,
      "loss": 0.1388,
      "step": 17100
    },
    {
      "epoch": 24.501424501424502,
      "grad_norm": 1.3375566005706787,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.1434,
      "step": 17200
    },
    {
      "epoch": 24.643874643874643,
      "grad_norm": 2.515045166015625,
      "learning_rate": 7.150997150997151e-07,
      "loss": 0.1567,
      "step": 17300
    },
    {
      "epoch": 24.786324786324787,
      "grad_norm": 1.4225186109542847,
      "learning_rate": 4.301994301994302e-07,
      "loss": 0.1522,
      "step": 17400
    },
    {
      "epoch": 24.928774928774928,
      "grad_norm": 3.491158962249756,
      "learning_rate": 1.452991452991453e-07,
      "loss": 0.1491,
      "step": 17500
    }
  ],
  "logging_steps": 100,
  "max_steps": 17550,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 25,
  "save_steps": 2000,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 30,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 5
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2295860798357504e+18,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
