{
  "best_global_step": 1080,
  "best_metric": 0.38096383213996887,
  "best_model_checkpoint": "segformer-finetuned\\checkpoint-1080",
  "epoch": 20.0,
  "eval_steps": 20,
  "global_step": 1360,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014705882352941176,
      "grad_norm": 3.4295787811279297,
      "learning_rate": 6e-05,
      "loss": 0.6897,
      "step": 1
    },
    {
      "epoch": 0.029411764705882353,
      "grad_norm": 3.0562849044799805,
      "learning_rate": 5.995588235294118e-05,
      "loss": 0.671,
      "step": 2
    },
    {
      "epoch": 0.04411764705882353,
      "grad_norm": 2.3979079723358154,
      "learning_rate": 5.991176470588235e-05,
      "loss": 0.6742,
      "step": 3
    },
    {
      "epoch": 0.058823529411764705,
      "grad_norm": 3.796483039855957,
      "learning_rate": 5.986764705882353e-05,
      "loss": 0.6108,
      "step": 4
    },
    {
      "epoch": 0.07352941176470588,
      "grad_norm": 2.0798792839050293,
      "learning_rate": 5.9823529411764705e-05,
      "loss": 0.604,
      "step": 5
    },
    {
      "epoch": 0.08823529411764706,
      "grad_norm": 3.100675582885742,
      "learning_rate": 5.977941176470589e-05,
      "loss": 0.632,
      "step": 6
    },
    {
      "epoch": 0.10294117647058823,
      "grad_norm": 3.2142741680145264,
      "learning_rate": 5.973529411764706e-05,
      "loss": 0.6486,
      "step": 7
    },
    {
      "epoch": 0.11764705882352941,
      "grad_norm": 3.5533463954925537,
      "learning_rate": 5.969117647058824e-05,
      "loss": 0.5935,
      "step": 8
    },
    {
      "epoch": 0.1323529411764706,
      "grad_norm": 3.54404616355896,
      "learning_rate": 5.9647058823529415e-05,
      "loss": 0.6113,
      "step": 9
    },
    {
      "epoch": 0.14705882352941177,
      "grad_norm": 5.908632278442383,
      "learning_rate": 5.960294117647059e-05,
      "loss": 0.6414,
      "step": 10
    },
    {
      "epoch": 0.16176470588235295,
      "grad_norm": 2.9669761657714844,
      "learning_rate": 5.9558823529411766e-05,
      "loss": 0.5956,
      "step": 11
    },
    {
      "epoch": 0.17647058823529413,
      "grad_norm": 3.9899935722351074,
      "learning_rate": 5.951470588235294e-05,
      "loss": 0.6484,
      "step": 12
    },
    {
      "epoch": 0.19117647058823528,
      "grad_norm": 4.441514492034912,
      "learning_rate": 5.947058823529412e-05,
      "loss": 0.6084,
      "step": 13
    },
    {
      "epoch": 0.20588235294117646,
      "grad_norm": 3.3576748371124268,
      "learning_rate": 5.94264705882353e-05,
      "loss": 0.4986,
      "step": 14
    },
    {
      "epoch": 0.22058823529411764,
      "grad_norm": 3.362976312637329,
      "learning_rate": 5.9382352941176476e-05,
      "loss": 0.5286,
      "step": 15
    },
    {
      "epoch": 0.23529411764705882,
      "grad_norm": 4.25726318359375,
      "learning_rate": 5.933823529411765e-05,
      "loss": 0.5096,
      "step": 16
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.9186179637908936,
      "learning_rate": 5.929411764705883e-05,
      "loss": 0.458,
      "step": 17
    },
    {
      "epoch": 0.2647058823529412,
      "grad_norm": 2.030529737472534,
      "learning_rate": 5.9250000000000004e-05,
      "loss": 0.5131,
      "step": 18
    },
    {
      "epoch": 0.27941176470588236,
      "grad_norm": 3.2523157596588135,
      "learning_rate": 5.920588235294118e-05,
      "loss": 0.5615,
      "step": 19
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 2.6655099391937256,
      "learning_rate": 5.9161764705882355e-05,
      "loss": 0.4631,
      "step": 20
    },
    {
      "epoch": 0.29411764705882354,
      "eval_accuracy_Block": 0.8332116842520683,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.8332116842520683,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.5931628942489624,
      "eval_mean_accuracy": 0.8332116842520683,
      "eval_mean_iou": 0.41660584212603413,
      "eval_overall_accuracy": 0.8332116842520683,
      "eval_runtime": 11.3906,
      "eval_samples_per_second": 11.94,
      "eval_steps_per_second": 1.492,
      "step": 20
    },
    {
      "epoch": 0.3088235294117647,
      "grad_norm": 4.118381500244141,
      "learning_rate": 5.911764705882353e-05,
      "loss": 0.6178,
      "step": 21
    },
    {
      "epoch": 0.3235294117647059,
      "grad_norm": 2.4435577392578125,
      "learning_rate": 5.9073529411764714e-05,
      "loss": 0.5149,
      "step": 22
    },
    {
      "epoch": 0.3382352941176471,
      "grad_norm": 2.5741991996765137,
      "learning_rate": 5.902941176470588e-05,
      "loss": 0.4322,
      "step": 23
    },
    {
      "epoch": 0.35294117647058826,
      "grad_norm": 2.4785120487213135,
      "learning_rate": 5.898529411764706e-05,
      "loss": 0.5388,
      "step": 24
    },
    {
      "epoch": 0.36764705882352944,
      "grad_norm": 3.287637948989868,
      "learning_rate": 5.8941176470588234e-05,
      "loss": 0.525,
      "step": 25
    },
    {
      "epoch": 0.38235294117647056,
      "grad_norm": 2.598292112350464,
      "learning_rate": 5.889705882352941e-05,
      "loss": 0.4414,
      "step": 26
    },
    {
      "epoch": 0.39705882352941174,
      "grad_norm": 5.197774410247803,
      "learning_rate": 5.8852941176470586e-05,
      "loss": 0.5105,
      "step": 27
    },
    {
      "epoch": 0.4117647058823529,
      "grad_norm": 4.349524974822998,
      "learning_rate": 5.880882352941176e-05,
      "loss": 0.6338,
      "step": 28
    },
    {
      "epoch": 0.4264705882352941,
      "grad_norm": 10.486778259277344,
      "learning_rate": 5.876470588235294e-05,
      "loss": 0.6313,
      "step": 29
    },
    {
      "epoch": 0.4411764705882353,
      "grad_norm": 3.68101167678833,
      "learning_rate": 5.872058823529412e-05,
      "loss": 0.4678,
      "step": 30
    },
    {
      "epoch": 0.45588235294117646,
      "grad_norm": 7.305324554443359,
      "learning_rate": 5.8676470588235296e-05,
      "loss": 0.5846,
      "step": 31
    },
    {
      "epoch": 0.47058823529411764,
      "grad_norm": 4.730391025543213,
      "learning_rate": 5.863235294117647e-05,
      "loss": 0.5732,
      "step": 32
    },
    {
      "epoch": 0.4852941176470588,
      "grad_norm": 3.9290621280670166,
      "learning_rate": 5.858823529411765e-05,
      "loss": 0.4651,
      "step": 33
    },
    {
      "epoch": 0.5,
      "grad_norm": 3.6548938751220703,
      "learning_rate": 5.854411764705882e-05,
      "loss": 0.5219,
      "step": 34
    },
    {
      "epoch": 0.5147058823529411,
      "grad_norm": 3.768810987472534,
      "learning_rate": 5.85e-05,
      "loss": 0.448,
      "step": 35
    },
    {
      "epoch": 0.5294117647058824,
      "grad_norm": 3.070966958999634,
      "learning_rate": 5.8455882352941175e-05,
      "loss": 0.4146,
      "step": 36
    },
    {
      "epoch": 0.5441176470588235,
      "grad_norm": 4.050268173217773,
      "learning_rate": 5.841176470588235e-05,
      "loss": 0.5186,
      "step": 37
    },
    {
      "epoch": 0.5588235294117647,
      "grad_norm": 4.671914100646973,
      "learning_rate": 5.836764705882353e-05,
      "loss": 0.6231,
      "step": 38
    },
    {
      "epoch": 0.5735294117647058,
      "grad_norm": 6.168744087219238,
      "learning_rate": 5.832352941176471e-05,
      "loss": 0.5404,
      "step": 39
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 6.59290075302124,
      "learning_rate": 5.8279411764705885e-05,
      "loss": 0.5688,
      "step": 40
    },
    {
      "epoch": 0.5882352941176471,
      "eval_accuracy_Block": 0.6548955381960737,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6548955381960737,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.4848770797252655,
      "eval_mean_accuracy": 0.6548955381960737,
      "eval_mean_iou": 0.32744776909803686,
      "eval_overall_accuracy": 0.6548955381960737,
      "eval_runtime": 7.0163,
      "eval_samples_per_second": 19.383,
      "eval_steps_per_second": 2.423,
      "step": 40
    },
    {
      "epoch": 0.6029411764705882,
      "grad_norm": 2.352306842803955,
      "learning_rate": 5.823529411764706e-05,
      "loss": 0.4029,
      "step": 41
    },
    {
      "epoch": 0.6176470588235294,
      "grad_norm": 4.565891742706299,
      "learning_rate": 5.8191176470588236e-05,
      "loss": 0.5416,
      "step": 42
    },
    {
      "epoch": 0.6323529411764706,
      "grad_norm": 2.503056526184082,
      "learning_rate": 5.814705882352941e-05,
      "loss": 0.3689,
      "step": 43
    },
    {
      "epoch": 0.6470588235294118,
      "grad_norm": 6.9688825607299805,
      "learning_rate": 5.810294117647059e-05,
      "loss": 0.428,
      "step": 44
    },
    {
      "epoch": 0.6617647058823529,
      "grad_norm": 3.7489588260650635,
      "learning_rate": 5.8058823529411764e-05,
      "loss": 0.4046,
      "step": 45
    },
    {
      "epoch": 0.6764705882352942,
      "grad_norm": 5.502505302429199,
      "learning_rate": 5.8014705882352946e-05,
      "loss": 0.5478,
      "step": 46
    },
    {
      "epoch": 0.6911764705882353,
      "grad_norm": 2.6418914794921875,
      "learning_rate": 5.797058823529412e-05,
      "loss": 0.4444,
      "step": 47
    },
    {
      "epoch": 0.7058823529411765,
      "grad_norm": 7.085026741027832,
      "learning_rate": 5.79264705882353e-05,
      "loss": 0.4125,
      "step": 48
    },
    {
      "epoch": 0.7205882352941176,
      "grad_norm": 6.612506866455078,
      "learning_rate": 5.7882352941176474e-05,
      "loss": 0.4478,
      "step": 49
    },
    {
      "epoch": 0.7352941176470589,
      "grad_norm": 4.379765510559082,
      "learning_rate": 5.783823529411765e-05,
      "loss": 0.4549,
      "step": 50
    },
    {
      "epoch": 0.75,
      "grad_norm": 6.318816184997559,
      "learning_rate": 5.7794117647058825e-05,
      "loss": 0.4588,
      "step": 51
    },
    {
      "epoch": 0.7647058823529411,
      "grad_norm": 6.905216693878174,
      "learning_rate": 5.775e-05,
      "loss": 0.476,
      "step": 52
    },
    {
      "epoch": 0.7794117647058824,
      "grad_norm": 3.0062994956970215,
      "learning_rate": 5.770588235294118e-05,
      "loss": 0.4582,
      "step": 53
    },
    {
      "epoch": 0.7941176470588235,
      "grad_norm": 3.3687844276428223,
      "learning_rate": 5.766176470588236e-05,
      "loss": 0.3531,
      "step": 54
    },
    {
      "epoch": 0.8088235294117647,
      "grad_norm": 3.2266697883605957,
      "learning_rate": 5.7617647058823535e-05,
      "loss": 0.4627,
      "step": 55
    },
    {
      "epoch": 0.8235294117647058,
      "grad_norm": 3.3207380771636963,
      "learning_rate": 5.757352941176471e-05,
      "loss": 0.4929,
      "step": 56
    },
    {
      "epoch": 0.8382352941176471,
      "grad_norm": 1.5305954217910767,
      "learning_rate": 5.752941176470589e-05,
      "loss": 0.3068,
      "step": 57
    },
    {
      "epoch": 0.8529411764705882,
      "grad_norm": 6.9555983543396,
      "learning_rate": 5.748529411764706e-05,
      "loss": 0.6286,
      "step": 58
    },
    {
      "epoch": 0.8676470588235294,
      "grad_norm": 6.149715900421143,
      "learning_rate": 5.744117647058824e-05,
      "loss": 0.5648,
      "step": 59
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 3.9048869609832764,
      "learning_rate": 5.7397058823529414e-05,
      "loss": 0.5093,
      "step": 60
    },
    {
      "epoch": 0.8823529411764706,
      "eval_accuracy_Block": 0.5829642784582227,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.5829642784582227,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.44140204787254333,
      "eval_mean_accuracy": 0.5829642784582227,
      "eval_mean_iou": 0.29148213922911137,
      "eval_overall_accuracy": 0.5829642784582227,
      "eval_runtime": 6.9912,
      "eval_samples_per_second": 19.453,
      "eval_steps_per_second": 2.432,
      "step": 60
    },
    {
      "epoch": 0.8970588235294118,
      "grad_norm": 4.590242862701416,
      "learning_rate": 5.735294117647059e-05,
      "loss": 0.4253,
      "step": 61
    },
    {
      "epoch": 0.9117647058823529,
      "grad_norm": 5.252738952636719,
      "learning_rate": 5.7308823529411766e-05,
      "loss": 0.5282,
      "step": 62
    },
    {
      "epoch": 0.9264705882352942,
      "grad_norm": 5.46886682510376,
      "learning_rate": 5.726470588235295e-05,
      "loss": 0.6829,
      "step": 63
    },
    {
      "epoch": 0.9411764705882353,
      "grad_norm": 3.8229217529296875,
      "learning_rate": 5.7220588235294124e-05,
      "loss": 0.4302,
      "step": 64
    },
    {
      "epoch": 0.9558823529411765,
      "grad_norm": 3.9328603744506836,
      "learning_rate": 5.717647058823529e-05,
      "loss": 0.4223,
      "step": 65
    },
    {
      "epoch": 0.9705882352941176,
      "grad_norm": 4.785073757171631,
      "learning_rate": 5.713235294117647e-05,
      "loss": 0.5565,
      "step": 66
    },
    {
      "epoch": 0.9852941176470589,
      "grad_norm": 4.040011405944824,
      "learning_rate": 5.7088235294117645e-05,
      "loss": 0.5256,
      "step": 67
    },
    {
      "epoch": 1.0,
      "grad_norm": 5.5570268630981445,
      "learning_rate": 5.704411764705882e-05,
      "loss": 0.4598,
      "step": 68
    },
    {
      "epoch": 1.0147058823529411,
      "grad_norm": 5.372171878814697,
      "learning_rate": 5.6999999999999996e-05,
      "loss": 0.3972,
      "step": 69
    },
    {
      "epoch": 1.0294117647058822,
      "grad_norm": 3.7961676120758057,
      "learning_rate": 5.695588235294117e-05,
      "loss": 0.4849,
      "step": 70
    },
    {
      "epoch": 1.0441176470588236,
      "grad_norm": 3.475931167602539,
      "learning_rate": 5.6911764705882355e-05,
      "loss": 0.3542,
      "step": 71
    },
    {
      "epoch": 1.0588235294117647,
      "grad_norm": 3.1064648628234863,
      "learning_rate": 5.686764705882353e-05,
      "loss": 0.5283,
      "step": 72
    },
    {
      "epoch": 1.0735294117647058,
      "grad_norm": 1.7371065616607666,
      "learning_rate": 5.6823529411764706e-05,
      "loss": 0.4227,
      "step": 73
    },
    {
      "epoch": 1.088235294117647,
      "grad_norm": 2.9691033363342285,
      "learning_rate": 5.677941176470588e-05,
      "loss": 0.3687,
      "step": 74
    },
    {
      "epoch": 1.1029411764705883,
      "grad_norm": 3.233380079269409,
      "learning_rate": 5.673529411764706e-05,
      "loss": 0.5281,
      "step": 75
    },
    {
      "epoch": 1.1176470588235294,
      "grad_norm": 3.802279472351074,
      "learning_rate": 5.6691176470588234e-05,
      "loss": 0.4398,
      "step": 76
    },
    {
      "epoch": 1.1323529411764706,
      "grad_norm": 5.650386810302734,
      "learning_rate": 5.664705882352941e-05,
      "loss": 0.46,
      "step": 77
    },
    {
      "epoch": 1.1470588235294117,
      "grad_norm": 5.118638038635254,
      "learning_rate": 5.6602941176470585e-05,
      "loss": 0.6164,
      "step": 78
    },
    {
      "epoch": 1.161764705882353,
      "grad_norm": 3.3516945838928223,
      "learning_rate": 5.655882352941177e-05,
      "loss": 0.4707,
      "step": 79
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 3.358774423599243,
      "learning_rate": 5.6514705882352944e-05,
      "loss": 0.4893,
      "step": 80
    },
    {
      "epoch": 1.1764705882352942,
      "eval_accuracy_Block": 0.6491329264250558,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6491329264250558,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.43940630555152893,
      "eval_mean_accuracy": 0.6491329264250558,
      "eval_mean_iou": 0.3245664632125279,
      "eval_overall_accuracy": 0.6491329264250558,
      "eval_runtime": 7.8255,
      "eval_samples_per_second": 17.379,
      "eval_steps_per_second": 2.172,
      "step": 80
    },
    {
      "epoch": 1.1911764705882353,
      "grad_norm": 2.2053096294403076,
      "learning_rate": 5.647058823529412e-05,
      "loss": 0.4094,
      "step": 81
    },
    {
      "epoch": 1.2058823529411764,
      "grad_norm": 1.864769697189331,
      "learning_rate": 5.6426470588235295e-05,
      "loss": 0.3226,
      "step": 82
    },
    {
      "epoch": 1.2205882352941178,
      "grad_norm": 3.6861660480499268,
      "learning_rate": 5.638235294117647e-05,
      "loss": 0.4231,
      "step": 83
    },
    {
      "epoch": 1.2352941176470589,
      "grad_norm": 2.658902406692505,
      "learning_rate": 5.633823529411765e-05,
      "loss": 0.4717,
      "step": 84
    },
    {
      "epoch": 1.25,
      "grad_norm": 3.1273105144500732,
      "learning_rate": 5.629411764705882e-05,
      "loss": 0.5155,
      "step": 85
    },
    {
      "epoch": 1.2647058823529411,
      "grad_norm": 4.61905574798584,
      "learning_rate": 5.625e-05,
      "loss": 0.6556,
      "step": 86
    },
    {
      "epoch": 1.2794117647058822,
      "grad_norm": 2.441610097885132,
      "learning_rate": 5.620588235294118e-05,
      "loss": 0.4379,
      "step": 87
    },
    {
      "epoch": 1.2941176470588236,
      "grad_norm": 4.422626972198486,
      "learning_rate": 5.616176470588236e-05,
      "loss": 0.4697,
      "step": 88
    },
    {
      "epoch": 1.3088235294117647,
      "grad_norm": 9.543048858642578,
      "learning_rate": 5.611764705882353e-05,
      "loss": 0.5497,
      "step": 89
    },
    {
      "epoch": 1.3235294117647058,
      "grad_norm": 4.054163455963135,
      "learning_rate": 5.607352941176471e-05,
      "loss": 0.418,
      "step": 90
    },
    {
      "epoch": 1.3382352941176472,
      "grad_norm": 5.680728912353516,
      "learning_rate": 5.6029411764705884e-05,
      "loss": 0.4681,
      "step": 91
    },
    {
      "epoch": 1.3529411764705883,
      "grad_norm": 3.8628079891204834,
      "learning_rate": 5.598529411764706e-05,
      "loss": 0.4026,
      "step": 92
    },
    {
      "epoch": 1.3676470588235294,
      "grad_norm": 4.047710418701172,
      "learning_rate": 5.5941176470588236e-05,
      "loss": 0.3493,
      "step": 93
    },
    {
      "epoch": 1.3823529411764706,
      "grad_norm": 6.220058441162109,
      "learning_rate": 5.589705882352941e-05,
      "loss": 0.4051,
      "step": 94
    },
    {
      "epoch": 1.3970588235294117,
      "grad_norm": 3.3443753719329834,
      "learning_rate": 5.5852941176470594e-05,
      "loss": 0.4095,
      "step": 95
    },
    {
      "epoch": 1.4117647058823528,
      "grad_norm": 4.615993976593018,
      "learning_rate": 5.580882352941177e-05,
      "loss": 0.4884,
      "step": 96
    },
    {
      "epoch": 1.4264705882352942,
      "grad_norm": 2.4281647205352783,
      "learning_rate": 5.5764705882352946e-05,
      "loss": 0.3643,
      "step": 97
    },
    {
      "epoch": 1.4411764705882353,
      "grad_norm": 5.012691497802734,
      "learning_rate": 5.572058823529412e-05,
      "loss": 0.4834,
      "step": 98
    },
    {
      "epoch": 1.4558823529411764,
      "grad_norm": 3.6769654750823975,
      "learning_rate": 5.56764705882353e-05,
      "loss": 0.3984,
      "step": 99
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 4.60044002532959,
      "learning_rate": 5.563235294117647e-05,
      "loss": 0.5457,
      "step": 100
    },
    {
      "epoch": 1.4705882352941178,
      "eval_accuracy_Block": 0.6332973757607412,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6332973757607412,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.43040940165519714,
      "eval_mean_accuracy": 0.6332973757607412,
      "eval_mean_iou": 0.3166486878803706,
      "eval_overall_accuracy": 0.6332973757607412,
      "eval_runtime": 7.1514,
      "eval_samples_per_second": 19.017,
      "eval_steps_per_second": 2.377,
      "step": 100
    },
    {
      "epoch": 1.4852941176470589,
      "grad_norm": 4.19520378112793,
      "learning_rate": 5.558823529411765e-05,
      "loss": 0.435,
      "step": 101
    },
    {
      "epoch": 1.5,
      "grad_norm": 3.813746929168701,
      "learning_rate": 5.5544117647058825e-05,
      "loss": 0.4776,
      "step": 102
    },
    {
      "epoch": 1.5147058823529411,
      "grad_norm": 2.902026414871216,
      "learning_rate": 5.550000000000001e-05,
      "loss": 0.4571,
      "step": 103
    },
    {
      "epoch": 1.5294117647058822,
      "grad_norm": 4.59580135345459,
      "learning_rate": 5.545588235294118e-05,
      "loss": 0.44,
      "step": 104
    },
    {
      "epoch": 1.5441176470588234,
      "grad_norm": 5.286240577697754,
      "learning_rate": 5.541176470588236e-05,
      "loss": 0.5382,
      "step": 105
    },
    {
      "epoch": 1.5588235294117647,
      "grad_norm": 5.355868339538574,
      "learning_rate": 5.5367647058823535e-05,
      "loss": 0.5379,
      "step": 106
    },
    {
      "epoch": 1.5735294117647058,
      "grad_norm": 5.240298271179199,
      "learning_rate": 5.532352941176471e-05,
      "loss": 0.5283,
      "step": 107
    },
    {
      "epoch": 1.5882352941176472,
      "grad_norm": 4.757483959197998,
      "learning_rate": 5.527941176470588e-05,
      "loss": 0.5996,
      "step": 108
    },
    {
      "epoch": 1.6029411764705883,
      "grad_norm": 2.1131584644317627,
      "learning_rate": 5.5235294117647055e-05,
      "loss": 0.3893,
      "step": 109
    },
    {
      "epoch": 1.6176470588235294,
      "grad_norm": 4.934449672698975,
      "learning_rate": 5.519117647058823e-05,
      "loss": 0.4723,
      "step": 110
    },
    {
      "epoch": 1.6323529411764706,
      "grad_norm": 2.326707124710083,
      "learning_rate": 5.5147058823529414e-05,
      "loss": 0.3656,
      "step": 111
    },
    {
      "epoch": 1.6470588235294117,
      "grad_norm": 2.139239549636841,
      "learning_rate": 5.510294117647059e-05,
      "loss": 0.2959,
      "step": 112
    },
    {
      "epoch": 1.6617647058823528,
      "grad_norm": 4.045134544372559,
      "learning_rate": 5.5058823529411765e-05,
      "loss": 0.3765,
      "step": 113
    },
    {
      "epoch": 1.6764705882352942,
      "grad_norm": 3.9177236557006836,
      "learning_rate": 5.501470588235294e-05,
      "loss": 0.4689,
      "step": 114
    },
    {
      "epoch": 1.6911764705882353,
      "grad_norm": 5.884509086608887,
      "learning_rate": 5.497058823529412e-05,
      "loss": 0.4291,
      "step": 115
    },
    {
      "epoch": 1.7058823529411766,
      "grad_norm": 4.165690898895264,
      "learning_rate": 5.492647058823529e-05,
      "loss": 0.4991,
      "step": 116
    },
    {
      "epoch": 1.7205882352941178,
      "grad_norm": 6.938704967498779,
      "learning_rate": 5.488235294117647e-05,
      "loss": 0.5279,
      "step": 117
    },
    {
      "epoch": 1.7352941176470589,
      "grad_norm": 4.734641075134277,
      "learning_rate": 5.4838235294117644e-05,
      "loss": 0.4654,
      "step": 118
    },
    {
      "epoch": 1.75,
      "grad_norm": 5.981232166290283,
      "learning_rate": 5.479411764705882e-05,
      "loss": 0.5316,
      "step": 119
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 4.751570224761963,
      "learning_rate": 5.475e-05,
      "loss": 0.3963,
      "step": 120
    },
    {
      "epoch": 1.7647058823529411,
      "eval_accuracy_Block": 0.651394730414577,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.651394730414577,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.42168572545051575,
      "eval_mean_accuracy": 0.651394730414577,
      "eval_mean_iou": 0.3256973652072885,
      "eval_overall_accuracy": 0.651394730414577,
      "eval_runtime": 7.4281,
      "eval_samples_per_second": 18.309,
      "eval_steps_per_second": 2.289,
      "step": 120
    },
    {
      "epoch": 1.7794117647058822,
      "grad_norm": 3.0293796062469482,
      "learning_rate": 5.470588235294118e-05,
      "loss": 0.4443,
      "step": 121
    },
    {
      "epoch": 1.7941176470588234,
      "grad_norm": 4.207193374633789,
      "learning_rate": 5.4661764705882354e-05,
      "loss": 0.391,
      "step": 122
    },
    {
      "epoch": 1.8088235294117647,
      "grad_norm": 5.933248043060303,
      "learning_rate": 5.461764705882353e-05,
      "loss": 0.4818,
      "step": 123
    },
    {
      "epoch": 1.8235294117647058,
      "grad_norm": 6.431387424468994,
      "learning_rate": 5.4573529411764706e-05,
      "loss": 0.5234,
      "step": 124
    },
    {
      "epoch": 1.8382352941176472,
      "grad_norm": 5.476358413696289,
      "learning_rate": 5.452941176470588e-05,
      "loss": 0.4179,
      "step": 125
    },
    {
      "epoch": 1.8529411764705883,
      "grad_norm": 5.892322540283203,
      "learning_rate": 5.448529411764706e-05,
      "loss": 0.7906,
      "step": 126
    },
    {
      "epoch": 1.8676470588235294,
      "grad_norm": 5.440023899078369,
      "learning_rate": 5.444117647058823e-05,
      "loss": 0.5384,
      "step": 127
    },
    {
      "epoch": 1.8823529411764706,
      "grad_norm": 4.394577980041504,
      "learning_rate": 5.4397058823529416e-05,
      "loss": 0.3956,
      "step": 128
    },
    {
      "epoch": 1.8970588235294117,
      "grad_norm": 2.869908571243286,
      "learning_rate": 5.435294117647059e-05,
      "loss": 0.3463,
      "step": 129
    },
    {
      "epoch": 1.9117647058823528,
      "grad_norm": 4.421678066253662,
      "learning_rate": 5.430882352941177e-05,
      "loss": 0.3779,
      "step": 130
    },
    {
      "epoch": 1.9264705882352942,
      "grad_norm": 1.785967230796814,
      "learning_rate": 5.426470588235294e-05,
      "loss": 0.3898,
      "step": 131
    },
    {
      "epoch": 1.9411764705882353,
      "grad_norm": 3.017869234085083,
      "learning_rate": 5.422058823529412e-05,
      "loss": 0.3742,
      "step": 132
    },
    {
      "epoch": 1.9558823529411766,
      "grad_norm": 1.3864916563034058,
      "learning_rate": 5.4176470588235295e-05,
      "loss": 0.3102,
      "step": 133
    },
    {
      "epoch": 1.9705882352941178,
      "grad_norm": 3.9381778240203857,
      "learning_rate": 5.413235294117647e-05,
      "loss": 0.5148,
      "step": 134
    },
    {
      "epoch": 1.9852941176470589,
      "grad_norm": 3.9648454189300537,
      "learning_rate": 5.4088235294117646e-05,
      "loss": 0.4865,
      "step": 135
    },
    {
      "epoch": 2.0,
      "grad_norm": 5.597010135650635,
      "learning_rate": 5.404411764705883e-05,
      "loss": 0.5999,
      "step": 136
    },
    {
      "epoch": 2.014705882352941,
      "grad_norm": 1.7337850332260132,
      "learning_rate": 5.4000000000000005e-05,
      "loss": 0.3997,
      "step": 137
    },
    {
      "epoch": 2.0294117647058822,
      "grad_norm": 2.694758176803589,
      "learning_rate": 5.395588235294118e-05,
      "loss": 0.3708,
      "step": 138
    },
    {
      "epoch": 2.0441176470588234,
      "grad_norm": 3.460444450378418,
      "learning_rate": 5.3911764705882356e-05,
      "loss": 0.4165,
      "step": 139
    },
    {
      "epoch": 2.0588235294117645,
      "grad_norm": 6.2753682136535645,
      "learning_rate": 5.386764705882353e-05,
      "loss": 0.6038,
      "step": 140
    },
    {
      "epoch": 2.0588235294117645,
      "eval_accuracy_Block": 0.592636407326624,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.592636407326624,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.4327356517314911,
      "eval_mean_accuracy": 0.592636407326624,
      "eval_mean_iou": 0.296318203663312,
      "eval_overall_accuracy": 0.592636407326624,
      "eval_runtime": 7.143,
      "eval_samples_per_second": 19.039,
      "eval_steps_per_second": 2.38,
      "step": 140
    },
    {
      "epoch": 2.073529411764706,
      "grad_norm": 4.649940490722656,
      "learning_rate": 5.382352941176471e-05,
      "loss": 0.4838,
      "step": 141
    },
    {
      "epoch": 2.088235294117647,
      "grad_norm": 3.327688455581665,
      "learning_rate": 5.3779411764705884e-05,
      "loss": 0.3626,
      "step": 142
    },
    {
      "epoch": 2.1029411764705883,
      "grad_norm": 3.1433281898498535,
      "learning_rate": 5.373529411764706e-05,
      "loss": 0.3549,
      "step": 143
    },
    {
      "epoch": 2.1176470588235294,
      "grad_norm": 2.7666780948638916,
      "learning_rate": 5.369117647058824e-05,
      "loss": 0.3921,
      "step": 144
    },
    {
      "epoch": 2.1323529411764706,
      "grad_norm": 2.496177911758423,
      "learning_rate": 5.364705882352942e-05,
      "loss": 0.3552,
      "step": 145
    },
    {
      "epoch": 2.1470588235294117,
      "grad_norm": 3.255006790161133,
      "learning_rate": 5.3602941176470594e-05,
      "loss": 0.3939,
      "step": 146
    },
    {
      "epoch": 2.161764705882353,
      "grad_norm": 3.9600462913513184,
      "learning_rate": 5.355882352941177e-05,
      "loss": 0.5683,
      "step": 147
    },
    {
      "epoch": 2.176470588235294,
      "grad_norm": 1.8268581628799438,
      "learning_rate": 5.3514705882352945e-05,
      "loss": 0.3562,
      "step": 148
    },
    {
      "epoch": 2.1911764705882355,
      "grad_norm": 2.611828565597534,
      "learning_rate": 5.347058823529412e-05,
      "loss": 0.2966,
      "step": 149
    },
    {
      "epoch": 2.2058823529411766,
      "grad_norm": 6.572973251342773,
      "learning_rate": 5.342647058823529e-05,
      "loss": 0.4868,
      "step": 150
    },
    {
      "epoch": 2.2205882352941178,
      "grad_norm": 6.2090349197387695,
      "learning_rate": 5.3382352941176466e-05,
      "loss": 0.7089,
      "step": 151
    },
    {
      "epoch": 2.235294117647059,
      "grad_norm": 3.6750850677490234,
      "learning_rate": 5.333823529411765e-05,
      "loss": 0.427,
      "step": 152
    },
    {
      "epoch": 2.25,
      "grad_norm": 6.591277122497559,
      "learning_rate": 5.3294117647058824e-05,
      "loss": 0.4576,
      "step": 153
    },
    {
      "epoch": 2.264705882352941,
      "grad_norm": 5.613512992858887,
      "learning_rate": 5.325e-05,
      "loss": 0.682,
      "step": 154
    },
    {
      "epoch": 2.2794117647058822,
      "grad_norm": 3.2062225341796875,
      "learning_rate": 5.3205882352941176e-05,
      "loss": 0.5732,
      "step": 155
    },
    {
      "epoch": 2.2941176470588234,
      "grad_norm": 4.0438232421875,
      "learning_rate": 5.316176470588235e-05,
      "loss": 0.551,
      "step": 156
    },
    {
      "epoch": 2.3088235294117645,
      "grad_norm": 1.4627835750579834,
      "learning_rate": 5.311764705882353e-05,
      "loss": 0.3527,
      "step": 157
    },
    {
      "epoch": 2.323529411764706,
      "grad_norm": 2.9595115184783936,
      "learning_rate": 5.30735294117647e-05,
      "loss": 0.3749,
      "step": 158
    },
    {
      "epoch": 2.338235294117647,
      "grad_norm": 2.7509350776672363,
      "learning_rate": 5.302941176470588e-05,
      "loss": 0.4414,
      "step": 159
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 4.261216163635254,
      "learning_rate": 5.298529411764706e-05,
      "loss": 0.3567,
      "step": 160
    },
    {
      "epoch": 2.3529411764705883,
      "eval_accuracy_Block": 0.6237645113925154,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6237645113925154,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.41266128420829773,
      "eval_mean_accuracy": 0.6237645113925154,
      "eval_mean_iou": 0.3118822556962577,
      "eval_overall_accuracy": 0.6237645113925154,
      "eval_runtime": 7.2174,
      "eval_samples_per_second": 18.843,
      "eval_steps_per_second": 2.355,
      "step": 160
    },
    {
      "epoch": 2.3676470588235294,
      "grad_norm": 4.073674201965332,
      "learning_rate": 5.294117647058824e-05,
      "loss": 0.4613,
      "step": 161
    },
    {
      "epoch": 2.3823529411764706,
      "grad_norm": 3.6297786235809326,
      "learning_rate": 5.289705882352941e-05,
      "loss": 0.529,
      "step": 162
    },
    {
      "epoch": 2.3970588235294117,
      "grad_norm": 1.7894420623779297,
      "learning_rate": 5.285294117647059e-05,
      "loss": 0.3217,
      "step": 163
    },
    {
      "epoch": 2.411764705882353,
      "grad_norm": 3.4956188201904297,
      "learning_rate": 5.2808823529411765e-05,
      "loss": 0.3663,
      "step": 164
    },
    {
      "epoch": 2.426470588235294,
      "grad_norm": 2.3146517276763916,
      "learning_rate": 5.276470588235294e-05,
      "loss": 0.2963,
      "step": 165
    },
    {
      "epoch": 2.4411764705882355,
      "grad_norm": 4.3130693435668945,
      "learning_rate": 5.2720588235294116e-05,
      "loss": 0.3584,
      "step": 166
    },
    {
      "epoch": 2.4558823529411766,
      "grad_norm": 6.922300338745117,
      "learning_rate": 5.267647058823529e-05,
      "loss": 0.4419,
      "step": 167
    },
    {
      "epoch": 2.4705882352941178,
      "grad_norm": 2.540811538696289,
      "learning_rate": 5.2632352941176475e-05,
      "loss": 0.4238,
      "step": 168
    },
    {
      "epoch": 2.485294117647059,
      "grad_norm": 4.33503532409668,
      "learning_rate": 5.258823529411765e-05,
      "loss": 0.4581,
      "step": 169
    },
    {
      "epoch": 2.5,
      "grad_norm": 2.4218568801879883,
      "learning_rate": 5.2544117647058826e-05,
      "loss": 0.3663,
      "step": 170
    },
    {
      "epoch": 2.514705882352941,
      "grad_norm": 2.01356840133667,
      "learning_rate": 5.25e-05,
      "loss": 0.4417,
      "step": 171
    },
    {
      "epoch": 2.5294117647058822,
      "grad_norm": 3.8192994594573975,
      "learning_rate": 5.245588235294118e-05,
      "loss": 0.4019,
      "step": 172
    },
    {
      "epoch": 2.5441176470588234,
      "grad_norm": 3.379965305328369,
      "learning_rate": 5.2411764705882354e-05,
      "loss": 0.4825,
      "step": 173
    },
    {
      "epoch": 2.5588235294117645,
      "grad_norm": 4.133735179901123,
      "learning_rate": 5.236764705882353e-05,
      "loss": 0.4565,
      "step": 174
    },
    {
      "epoch": 2.5735294117647056,
      "grad_norm": 4.243278980255127,
      "learning_rate": 5.2323529411764705e-05,
      "loss": 0.4849,
      "step": 175
    },
    {
      "epoch": 2.588235294117647,
      "grad_norm": 2.148087978363037,
      "learning_rate": 5.227941176470588e-05,
      "loss": 0.3603,
      "step": 176
    },
    {
      "epoch": 2.6029411764705883,
      "grad_norm": 2.3123388290405273,
      "learning_rate": 5.2235294117647064e-05,
      "loss": 0.4369,
      "step": 177
    },
    {
      "epoch": 2.6176470588235294,
      "grad_norm": 1.8138998746871948,
      "learning_rate": 5.219117647058824e-05,
      "loss": 0.3381,
      "step": 178
    },
    {
      "epoch": 2.6323529411764706,
      "grad_norm": 4.018731117248535,
      "learning_rate": 5.2147058823529415e-05,
      "loss": 0.4068,
      "step": 179
    },
    {
      "epoch": 2.6470588235294117,
      "grad_norm": 3.680788278579712,
      "learning_rate": 5.210294117647059e-05,
      "loss": 0.3141,
      "step": 180
    },
    {
      "epoch": 2.6470588235294117,
      "eval_accuracy_Block": 0.6191823696672282,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6191823696672282,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.4275880753993988,
      "eval_mean_accuracy": 0.6191823696672282,
      "eval_mean_iou": 0.3095911848336141,
      "eval_overall_accuracy": 0.6191823696672282,
      "eval_runtime": 9.4191,
      "eval_samples_per_second": 14.439,
      "eval_steps_per_second": 1.805,
      "step": 180
    },
    {
      "epoch": 2.661764705882353,
      "grad_norm": 4.762103080749512,
      "learning_rate": 5.205882352941177e-05,
      "loss": 0.4438,
      "step": 181
    },
    {
      "epoch": 2.6764705882352944,
      "grad_norm": 4.459348678588867,
      "learning_rate": 5.201470588235294e-05,
      "loss": 0.4755,
      "step": 182
    },
    {
      "epoch": 2.6911764705882355,
      "grad_norm": 3.3067853450775146,
      "learning_rate": 5.197058823529412e-05,
      "loss": 0.4455,
      "step": 183
    },
    {
      "epoch": 2.7058823529411766,
      "grad_norm": 7.094894886016846,
      "learning_rate": 5.1926470588235294e-05,
      "loss": 0.485,
      "step": 184
    },
    {
      "epoch": 2.7205882352941178,
      "grad_norm": 3.538835048675537,
      "learning_rate": 5.188235294117648e-05,
      "loss": 0.4053,
      "step": 185
    },
    {
      "epoch": 2.735294117647059,
      "grad_norm": 1.8728280067443848,
      "learning_rate": 5.183823529411765e-05,
      "loss": 0.336,
      "step": 186
    },
    {
      "epoch": 2.75,
      "grad_norm": 2.825624704360962,
      "learning_rate": 5.179411764705883e-05,
      "loss": 0.4104,
      "step": 187
    },
    {
      "epoch": 2.764705882352941,
      "grad_norm": 4.669223785400391,
      "learning_rate": 5.1750000000000004e-05,
      "loss": 0.4393,
      "step": 188
    },
    {
      "epoch": 2.7794117647058822,
      "grad_norm": 2.4262115955352783,
      "learning_rate": 5.170588235294118e-05,
      "loss": 0.334,
      "step": 189
    },
    {
      "epoch": 2.7941176470588234,
      "grad_norm": 9.169524192810059,
      "learning_rate": 5.1661764705882356e-05,
      "loss": 0.37,
      "step": 190
    },
    {
      "epoch": 2.8088235294117645,
      "grad_norm": 1.437999963760376,
      "learning_rate": 5.161764705882353e-05,
      "loss": 0.284,
      "step": 191
    },
    {
      "epoch": 2.8235294117647056,
      "grad_norm": 4.614598751068115,
      "learning_rate": 5.157352941176471e-05,
      "loss": 0.5201,
      "step": 192
    },
    {
      "epoch": 2.838235294117647,
      "grad_norm": 3.522094488143921,
      "learning_rate": 5.152941176470588e-05,
      "loss": 0.4356,
      "step": 193
    },
    {
      "epoch": 2.8529411764705883,
      "grad_norm": 3.2383110523223877,
      "learning_rate": 5.148529411764706e-05,
      "loss": 0.3693,
      "step": 194
    },
    {
      "epoch": 2.8676470588235294,
      "grad_norm": 1.581756353378296,
      "learning_rate": 5.1441176470588235e-05,
      "loss": 0.3193,
      "step": 195
    },
    {
      "epoch": 2.8823529411764706,
      "grad_norm": 6.747081756591797,
      "learning_rate": 5.139705882352941e-05,
      "loss": 0.4652,
      "step": 196
    },
    {
      "epoch": 2.8970588235294117,
      "grad_norm": 6.235405445098877,
      "learning_rate": 5.1352941176470586e-05,
      "loss": 0.4881,
      "step": 197
    },
    {
      "epoch": 2.911764705882353,
      "grad_norm": 5.94028377532959,
      "learning_rate": 5.130882352941176e-05,
      "loss": 0.4432,
      "step": 198
    },
    {
      "epoch": 2.9264705882352944,
      "grad_norm": 2.6848559379577637,
      "learning_rate": 5.126470588235294e-05,
      "loss": 0.3117,
      "step": 199
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 5.114099502563477,
      "learning_rate": 5.1220588235294114e-05,
      "loss": 0.4673,
      "step": 200
    },
    {
      "epoch": 2.9411764705882355,
      "eval_accuracy_Block": 0.7070256452061888,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7070256452061888,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.4127533435821533,
      "eval_mean_accuracy": 0.7070256452061888,
      "eval_mean_iou": 0.3535128226030944,
      "eval_overall_accuracy": 0.7070256452061888,
      "eval_runtime": 7.9366,
      "eval_samples_per_second": 17.136,
      "eval_steps_per_second": 2.142,
      "step": 200
    },
    {
      "epoch": 2.9558823529411766,
      "grad_norm": 2.849787473678589,
      "learning_rate": 5.1176470588235296e-05,
      "loss": 0.4678,
      "step": 201
    },
    {
      "epoch": 2.9705882352941178,
      "grad_norm": 9.637513160705566,
      "learning_rate": 5.113235294117647e-05,
      "loss": 0.6902,
      "step": 202
    },
    {
      "epoch": 2.985294117647059,
      "grad_norm": 3.748443841934204,
      "learning_rate": 5.108823529411765e-05,
      "loss": 0.4296,
      "step": 203
    },
    {
      "epoch": 3.0,
      "grad_norm": 4.922562599182129,
      "learning_rate": 5.1044117647058824e-05,
      "loss": 0.3795,
      "step": 204
    },
    {
      "epoch": 3.014705882352941,
      "grad_norm": 4.090829372406006,
      "learning_rate": 5.1e-05,
      "loss": 0.3432,
      "step": 205
    },
    {
      "epoch": 3.0294117647058822,
      "grad_norm": 1.7180876731872559,
      "learning_rate": 5.0955882352941175e-05,
      "loss": 0.2914,
      "step": 206
    },
    {
      "epoch": 3.0441176470588234,
      "grad_norm": 1.7770112752914429,
      "learning_rate": 5.091176470588235e-05,
      "loss": 0.2571,
      "step": 207
    },
    {
      "epoch": 3.0588235294117645,
      "grad_norm": 6.191362380981445,
      "learning_rate": 5.086764705882353e-05,
      "loss": 0.4791,
      "step": 208
    },
    {
      "epoch": 3.073529411764706,
      "grad_norm": 2.768573045730591,
      "learning_rate": 5.082352941176471e-05,
      "loss": 0.4661,
      "step": 209
    },
    {
      "epoch": 3.088235294117647,
      "grad_norm": 3.8685719966888428,
      "learning_rate": 5.0779411764705885e-05,
      "loss": 0.5726,
      "step": 210
    },
    {
      "epoch": 3.1029411764705883,
      "grad_norm": 4.269258499145508,
      "learning_rate": 5.073529411764706e-05,
      "loss": 0.3602,
      "step": 211
    },
    {
      "epoch": 3.1176470588235294,
      "grad_norm": 7.370918273925781,
      "learning_rate": 5.069117647058824e-05,
      "loss": 0.3724,
      "step": 212
    },
    {
      "epoch": 3.1323529411764706,
      "grad_norm": 5.318857669830322,
      "learning_rate": 5.064705882352941e-05,
      "loss": 0.585,
      "step": 213
    },
    {
      "epoch": 3.1470588235294117,
      "grad_norm": 3.6798012256622314,
      "learning_rate": 5.060294117647059e-05,
      "loss": 0.4348,
      "step": 214
    },
    {
      "epoch": 3.161764705882353,
      "grad_norm": 3.8471436500549316,
      "learning_rate": 5.0558823529411764e-05,
      "loss": 0.4373,
      "step": 215
    },
    {
      "epoch": 3.176470588235294,
      "grad_norm": 3.8133153915405273,
      "learning_rate": 5.051470588235294e-05,
      "loss": 0.4662,
      "step": 216
    },
    {
      "epoch": 3.1911764705882355,
      "grad_norm": 4.316136837005615,
      "learning_rate": 5.047058823529412e-05,
      "loss": 0.5011,
      "step": 217
    },
    {
      "epoch": 3.2058823529411766,
      "grad_norm": 4.07050895690918,
      "learning_rate": 5.04264705882353e-05,
      "loss": 0.5075,
      "step": 218
    },
    {
      "epoch": 3.2205882352941178,
      "grad_norm": 3.146350860595703,
      "learning_rate": 5.0382352941176474e-05,
      "loss": 0.3265,
      "step": 219
    },
    {
      "epoch": 3.235294117647059,
      "grad_norm": 2.9377145767211914,
      "learning_rate": 5.033823529411765e-05,
      "loss": 0.4429,
      "step": 220
    },
    {
      "epoch": 3.235294117647059,
      "eval_accuracy_Block": 0.584406373021583,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.584406373021583,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.42589372396469116,
      "eval_mean_accuracy": 0.584406373021583,
      "eval_mean_iou": 0.2922031865107915,
      "eval_overall_accuracy": 0.584406373021583,
      "eval_runtime": 7.6122,
      "eval_samples_per_second": 17.866,
      "eval_steps_per_second": 2.233,
      "step": 220
    },
    {
      "epoch": 3.25,
      "grad_norm": 1.7715247869491577,
      "learning_rate": 5.0294117647058826e-05,
      "loss": 0.2908,
      "step": 221
    },
    {
      "epoch": 3.264705882352941,
      "grad_norm": 4.210348606109619,
      "learning_rate": 5.025e-05,
      "loss": 0.4607,
      "step": 222
    },
    {
      "epoch": 3.2794117647058822,
      "grad_norm": 3.989919424057007,
      "learning_rate": 5.020588235294118e-05,
      "loss": 0.4426,
      "step": 223
    },
    {
      "epoch": 3.2941176470588234,
      "grad_norm": 2.528143882751465,
      "learning_rate": 5.016176470588235e-05,
      "loss": 0.4427,
      "step": 224
    },
    {
      "epoch": 3.3088235294117645,
      "grad_norm": 3.4360787868499756,
      "learning_rate": 5.0117647058823536e-05,
      "loss": 0.3746,
      "step": 225
    },
    {
      "epoch": 3.323529411764706,
      "grad_norm": 5.619775772094727,
      "learning_rate": 5.007352941176471e-05,
      "loss": 0.4611,
      "step": 226
    },
    {
      "epoch": 3.338235294117647,
      "grad_norm": 2.34110164642334,
      "learning_rate": 5.002941176470589e-05,
      "loss": 0.3236,
      "step": 227
    },
    {
      "epoch": 3.3529411764705883,
      "grad_norm": 2.8855979442596436,
      "learning_rate": 4.998529411764706e-05,
      "loss": 0.4012,
      "step": 228
    },
    {
      "epoch": 3.3676470588235294,
      "grad_norm": 2.280158758163452,
      "learning_rate": 4.994117647058824e-05,
      "loss": 0.3273,
      "step": 229
    },
    {
      "epoch": 3.3823529411764706,
      "grad_norm": 6.656337261199951,
      "learning_rate": 4.9897058823529415e-05,
      "loss": 0.591,
      "step": 230
    },
    {
      "epoch": 3.3970588235294117,
      "grad_norm": 4.944630146026611,
      "learning_rate": 4.985294117647059e-05,
      "loss": 0.4619,
      "step": 231
    },
    {
      "epoch": 3.411764705882353,
      "grad_norm": 2.324659824371338,
      "learning_rate": 4.9808823529411766e-05,
      "loss": 0.287,
      "step": 232
    },
    {
      "epoch": 3.426470588235294,
      "grad_norm": 2.7836720943450928,
      "learning_rate": 4.976470588235294e-05,
      "loss": 0.3978,
      "step": 233
    },
    {
      "epoch": 3.4411764705882355,
      "grad_norm": 8.231468200683594,
      "learning_rate": 4.9720588235294125e-05,
      "loss": 0.5166,
      "step": 234
    },
    {
      "epoch": 3.4558823529411766,
      "grad_norm": 11.787344932556152,
      "learning_rate": 4.9676470588235294e-05,
      "loss": 0.4696,
      "step": 235
    },
    {
      "epoch": 3.4705882352941178,
      "grad_norm": 2.35373854637146,
      "learning_rate": 4.963235294117647e-05,
      "loss": 0.3332,
      "step": 236
    },
    {
      "epoch": 3.485294117647059,
      "grad_norm": 4.691058158874512,
      "learning_rate": 4.9588235294117645e-05,
      "loss": 0.4901,
      "step": 237
    },
    {
      "epoch": 3.5,
      "grad_norm": 2.9407737255096436,
      "learning_rate": 4.954411764705882e-05,
      "loss": 0.422,
      "step": 238
    },
    {
      "epoch": 3.514705882352941,
      "grad_norm": 1.6135015487670898,
      "learning_rate": 4.95e-05,
      "loss": 0.263,
      "step": 239
    },
    {
      "epoch": 3.5294117647058822,
      "grad_norm": 1.9428715705871582,
      "learning_rate": 4.945588235294117e-05,
      "loss": 0.3382,
      "step": 240
    },
    {
      "epoch": 3.5294117647058822,
      "eval_accuracy_Block": 0.6390207280555327,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6390207280555327,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.40887030959129333,
      "eval_mean_accuracy": 0.6390207280555327,
      "eval_mean_iou": 0.31951036402776634,
      "eval_overall_accuracy": 0.6390207280555327,
      "eval_runtime": 7.4494,
      "eval_samples_per_second": 18.257,
      "eval_steps_per_second": 2.282,
      "step": 240
    },
    {
      "epoch": 3.5441176470588234,
      "grad_norm": 2.70841383934021,
      "learning_rate": 4.941176470588235e-05,
      "loss": 0.373,
      "step": 241
    },
    {
      "epoch": 3.5588235294117645,
      "grad_norm": 3.454838752746582,
      "learning_rate": 4.936764705882353e-05,
      "loss": 0.3067,
      "step": 242
    },
    {
      "epoch": 3.5735294117647056,
      "grad_norm": 3.0033435821533203,
      "learning_rate": 4.932352941176471e-05,
      "loss": 0.3615,
      "step": 243
    },
    {
      "epoch": 3.588235294117647,
      "grad_norm": 4.633476734161377,
      "learning_rate": 4.927941176470588e-05,
      "loss": 0.429,
      "step": 244
    },
    {
      "epoch": 3.6029411764705883,
      "grad_norm": 2.0991368293762207,
      "learning_rate": 4.923529411764706e-05,
      "loss": 0.3215,
      "step": 245
    },
    {
      "epoch": 3.6176470588235294,
      "grad_norm": 2.3389172554016113,
      "learning_rate": 4.9191176470588234e-05,
      "loss": 0.3262,
      "step": 246
    },
    {
      "epoch": 3.6323529411764706,
      "grad_norm": 3.96657395362854,
      "learning_rate": 4.914705882352941e-05,
      "loss": 0.4725,
      "step": 247
    },
    {
      "epoch": 3.6470588235294117,
      "grad_norm": 5.155498027801514,
      "learning_rate": 4.9102941176470586e-05,
      "loss": 0.4228,
      "step": 248
    },
    {
      "epoch": 3.661764705882353,
      "grad_norm": 3.6848223209381104,
      "learning_rate": 4.905882352941176e-05,
      "loss": 0.4013,
      "step": 249
    },
    {
      "epoch": 3.6764705882352944,
      "grad_norm": 5.158482551574707,
      "learning_rate": 4.9014705882352944e-05,
      "loss": 0.4943,
      "step": 250
    },
    {
      "epoch": 3.6911764705882355,
      "grad_norm": 2.4393186569213867,
      "learning_rate": 4.897058823529412e-05,
      "loss": 0.4293,
      "step": 251
    },
    {
      "epoch": 3.7058823529411766,
      "grad_norm": 4.059905052185059,
      "learning_rate": 4.8926470588235296e-05,
      "loss": 0.4064,
      "step": 252
    },
    {
      "epoch": 3.7205882352941178,
      "grad_norm": 2.7699146270751953,
      "learning_rate": 4.888235294117647e-05,
      "loss": 0.293,
      "step": 253
    },
    {
      "epoch": 3.735294117647059,
      "grad_norm": 1.5934873819351196,
      "learning_rate": 4.883823529411765e-05,
      "loss": 0.2986,
      "step": 254
    },
    {
      "epoch": 3.75,
      "grad_norm": 4.785207271575928,
      "learning_rate": 4.879411764705882e-05,
      "loss": 0.502,
      "step": 255
    },
    {
      "epoch": 3.764705882352941,
      "grad_norm": 4.323680877685547,
      "learning_rate": 4.875e-05,
      "loss": 0.3576,
      "step": 256
    },
    {
      "epoch": 3.7794117647058822,
      "grad_norm": 2.89776873588562,
      "learning_rate": 4.8705882352941175e-05,
      "loss": 0.374,
      "step": 257
    },
    {
      "epoch": 3.7941176470588234,
      "grad_norm": 4.323446273803711,
      "learning_rate": 4.866176470588236e-05,
      "loss": 0.474,
      "step": 258
    },
    {
      "epoch": 3.8088235294117645,
      "grad_norm": 3.8340811729431152,
      "learning_rate": 4.861764705882353e-05,
      "loss": 0.4654,
      "step": 259
    },
    {
      "epoch": 3.8235294117647056,
      "grad_norm": 14.098822593688965,
      "learning_rate": 4.857352941176471e-05,
      "loss": 0.5295,
      "step": 260
    },
    {
      "epoch": 3.8235294117647056,
      "eval_accuracy_Block": 0.6560064154881714,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6560064154881714,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.40971922874450684,
      "eval_mean_accuracy": 0.6560064154881714,
      "eval_mean_iou": 0.3280032077440857,
      "eval_overall_accuracy": 0.6560064154881714,
      "eval_runtime": 7.3452,
      "eval_samples_per_second": 18.516,
      "eval_steps_per_second": 2.314,
      "step": 260
    },
    {
      "epoch": 3.838235294117647,
      "grad_norm": 2.814095973968506,
      "learning_rate": 4.8529411764705885e-05,
      "loss": 0.326,
      "step": 261
    },
    {
      "epoch": 3.8529411764705883,
      "grad_norm": 3.9903125762939453,
      "learning_rate": 4.848529411764706e-05,
      "loss": 0.4552,
      "step": 262
    },
    {
      "epoch": 3.8676470588235294,
      "grad_norm": 2.763601541519165,
      "learning_rate": 4.8441176470588236e-05,
      "loss": 0.3251,
      "step": 263
    },
    {
      "epoch": 3.8823529411764706,
      "grad_norm": 7.461148738861084,
      "learning_rate": 4.839705882352941e-05,
      "loss": 0.4007,
      "step": 264
    },
    {
      "epoch": 3.8970588235294117,
      "grad_norm": 3.2979514598846436,
      "learning_rate": 4.835294117647059e-05,
      "loss": 0.332,
      "step": 265
    },
    {
      "epoch": 3.911764705882353,
      "grad_norm": 3.0532407760620117,
      "learning_rate": 4.830882352941177e-05,
      "loss": 0.453,
      "step": 266
    },
    {
      "epoch": 3.9264705882352944,
      "grad_norm": 3.4534218311309814,
      "learning_rate": 4.8264705882352946e-05,
      "loss": 0.3438,
      "step": 267
    },
    {
      "epoch": 3.9411764705882355,
      "grad_norm": 1.4433172941207886,
      "learning_rate": 4.822058823529412e-05,
      "loss": 0.2424,
      "step": 268
    },
    {
      "epoch": 3.9558823529411766,
      "grad_norm": 6.027442932128906,
      "learning_rate": 4.81764705882353e-05,
      "loss": 0.4151,
      "step": 269
    },
    {
      "epoch": 3.9705882352941178,
      "grad_norm": 4.193851470947266,
      "learning_rate": 4.8132352941176474e-05,
      "loss": 0.4086,
      "step": 270
    },
    {
      "epoch": 3.985294117647059,
      "grad_norm": 10.610859870910645,
      "learning_rate": 4.808823529411765e-05,
      "loss": 0.5428,
      "step": 271
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.0561437606811523,
      "learning_rate": 4.8044117647058825e-05,
      "loss": 0.2752,
      "step": 272
    },
    {
      "epoch": 4.014705882352941,
      "grad_norm": 4.2258830070495605,
      "learning_rate": 4.8e-05,
      "loss": 0.3971,
      "step": 273
    },
    {
      "epoch": 4.029411764705882,
      "grad_norm": 5.115236282348633,
      "learning_rate": 4.7955882352941184e-05,
      "loss": 0.5798,
      "step": 274
    },
    {
      "epoch": 4.044117647058823,
      "grad_norm": 1.8331031799316406,
      "learning_rate": 4.791176470588236e-05,
      "loss": 0.3701,
      "step": 275
    },
    {
      "epoch": 4.0588235294117645,
      "grad_norm": 3.1225242614746094,
      "learning_rate": 4.7867647058823535e-05,
      "loss": 0.2983,
      "step": 276
    },
    {
      "epoch": 4.073529411764706,
      "grad_norm": 4.567796230316162,
      "learning_rate": 4.782352941176471e-05,
      "loss": 0.525,
      "step": 277
    },
    {
      "epoch": 4.088235294117647,
      "grad_norm": 9.024065971374512,
      "learning_rate": 4.777941176470588e-05,
      "loss": 0.4676,
      "step": 278
    },
    {
      "epoch": 4.102941176470588,
      "grad_norm": 4.575440406799316,
      "learning_rate": 4.7735294117647056e-05,
      "loss": 0.3576,
      "step": 279
    },
    {
      "epoch": 4.117647058823529,
      "grad_norm": 3.9710099697113037,
      "learning_rate": 4.769117647058823e-05,
      "loss": 0.5398,
      "step": 280
    },
    {
      "epoch": 4.117647058823529,
      "eval_accuracy_Block": 0.6943995764716142,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6943995764716142,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.4127093553543091,
      "eval_mean_accuracy": 0.6943995764716142,
      "eval_mean_iou": 0.3471997882358071,
      "eval_overall_accuracy": 0.6943995764716142,
      "eval_runtime": 7.9153,
      "eval_samples_per_second": 17.182,
      "eval_steps_per_second": 2.148,
      "step": 280
    },
    {
      "epoch": 4.132352941176471,
      "grad_norm": 9.534916877746582,
      "learning_rate": 4.764705882352941e-05,
      "loss": 0.451,
      "step": 281
    },
    {
      "epoch": 4.147058823529412,
      "grad_norm": 5.033523082733154,
      "learning_rate": 4.760294117647059e-05,
      "loss": 0.4108,
      "step": 282
    },
    {
      "epoch": 4.161764705882353,
      "grad_norm": 8.79138469696045,
      "learning_rate": 4.7558823529411766e-05,
      "loss": 0.4279,
      "step": 283
    },
    {
      "epoch": 4.176470588235294,
      "grad_norm": 5.7698540687561035,
      "learning_rate": 4.751470588235294e-05,
      "loss": 0.337,
      "step": 284
    },
    {
      "epoch": 4.1911764705882355,
      "grad_norm": 2.062784433364868,
      "learning_rate": 4.747058823529412e-05,
      "loss": 0.3267,
      "step": 285
    },
    {
      "epoch": 4.205882352941177,
      "grad_norm": 4.142970085144043,
      "learning_rate": 4.742647058823529e-05,
      "loss": 0.3573,
      "step": 286
    },
    {
      "epoch": 4.220588235294118,
      "grad_norm": 3.204749345779419,
      "learning_rate": 4.738235294117647e-05,
      "loss": 0.3361,
      "step": 287
    },
    {
      "epoch": 4.235294117647059,
      "grad_norm": 5.429441452026367,
      "learning_rate": 4.7338235294117645e-05,
      "loss": 0.4314,
      "step": 288
    },
    {
      "epoch": 4.25,
      "grad_norm": 3.5000057220458984,
      "learning_rate": 4.729411764705882e-05,
      "loss": 0.3569,
      "step": 289
    },
    {
      "epoch": 4.264705882352941,
      "grad_norm": 2.3070526123046875,
      "learning_rate": 4.7249999999999997e-05,
      "loss": 0.2899,
      "step": 290
    },
    {
      "epoch": 4.279411764705882,
      "grad_norm": 5.857407093048096,
      "learning_rate": 4.720588235294118e-05,
      "loss": 0.3823,
      "step": 291
    },
    {
      "epoch": 4.294117647058823,
      "grad_norm": 2.908334732055664,
      "learning_rate": 4.7161764705882355e-05,
      "loss": 0.3446,
      "step": 292
    },
    {
      "epoch": 4.3088235294117645,
      "grad_norm": 5.865830898284912,
      "learning_rate": 4.711764705882353e-05,
      "loss": 0.3521,
      "step": 293
    },
    {
      "epoch": 4.323529411764706,
      "grad_norm": 5.871904373168945,
      "learning_rate": 4.7073529411764707e-05,
      "loss": 0.3652,
      "step": 294
    },
    {
      "epoch": 4.338235294117647,
      "grad_norm": 4.0743513107299805,
      "learning_rate": 4.702941176470588e-05,
      "loss": 0.3077,
      "step": 295
    },
    {
      "epoch": 4.352941176470588,
      "grad_norm": 2.9040706157684326,
      "learning_rate": 4.698529411764706e-05,
      "loss": 0.3461,
      "step": 296
    },
    {
      "epoch": 4.367647058823529,
      "grad_norm": 3.0135207176208496,
      "learning_rate": 4.6941176470588234e-05,
      "loss": 0.3321,
      "step": 297
    },
    {
      "epoch": 4.382352941176471,
      "grad_norm": 2.2974603176116943,
      "learning_rate": 4.689705882352941e-05,
      "loss": 0.2892,
      "step": 298
    },
    {
      "epoch": 4.397058823529412,
      "grad_norm": 3.10387921333313,
      "learning_rate": 4.685294117647059e-05,
      "loss": 0.328,
      "step": 299
    },
    {
      "epoch": 4.411764705882353,
      "grad_norm": 6.263105869293213,
      "learning_rate": 4.680882352941177e-05,
      "loss": 0.5264,
      "step": 300
    },
    {
      "epoch": 4.411764705882353,
      "eval_accuracy_Block": 0.6745524498703095,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6745524498703095,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.4257274568080902,
      "eval_mean_accuracy": 0.6745524498703095,
      "eval_mean_iou": 0.33727622493515474,
      "eval_overall_accuracy": 0.6745524498703095,
      "eval_runtime": 7.5631,
      "eval_samples_per_second": 17.982,
      "eval_steps_per_second": 2.248,
      "step": 300
    },
    {
      "epoch": 4.426470588235294,
      "grad_norm": 3.12136173248291,
      "learning_rate": 4.6764705882352944e-05,
      "loss": 0.3989,
      "step": 301
    },
    {
      "epoch": 4.4411764705882355,
      "grad_norm": 3.3351662158966064,
      "learning_rate": 4.672058823529412e-05,
      "loss": 0.32,
      "step": 302
    },
    {
      "epoch": 4.455882352941177,
      "grad_norm": 7.280804634094238,
      "learning_rate": 4.6676470588235295e-05,
      "loss": 0.3785,
      "step": 303
    },
    {
      "epoch": 4.470588235294118,
      "grad_norm": 4.100052833557129,
      "learning_rate": 4.663235294117647e-05,
      "loss": 0.4279,
      "step": 304
    },
    {
      "epoch": 4.485294117647059,
      "grad_norm": 7.263789653778076,
      "learning_rate": 4.658823529411765e-05,
      "loss": 0.4325,
      "step": 305
    },
    {
      "epoch": 4.5,
      "grad_norm": 5.908096790313721,
      "learning_rate": 4.654411764705882e-05,
      "loss": 0.3311,
      "step": 306
    },
    {
      "epoch": 4.514705882352941,
      "grad_norm": 4.948602676391602,
      "learning_rate": 4.6500000000000005e-05,
      "loss": 0.4266,
      "step": 307
    },
    {
      "epoch": 4.529411764705882,
      "grad_norm": 8.763449668884277,
      "learning_rate": 4.645588235294118e-05,
      "loss": 0.5189,
      "step": 308
    },
    {
      "epoch": 4.544117647058823,
      "grad_norm": 2.869884490966797,
      "learning_rate": 4.641176470588236e-05,
      "loss": 0.3089,
      "step": 309
    },
    {
      "epoch": 4.5588235294117645,
      "grad_norm": 6.66515588760376,
      "learning_rate": 4.636764705882353e-05,
      "loss": 0.4344,
      "step": 310
    },
    {
      "epoch": 4.573529411764706,
      "grad_norm": 3.564469337463379,
      "learning_rate": 4.632352941176471e-05,
      "loss": 0.382,
      "step": 311
    },
    {
      "epoch": 4.588235294117647,
      "grad_norm": 2.9460232257843018,
      "learning_rate": 4.6279411764705884e-05,
      "loss": 0.3477,
      "step": 312
    },
    {
      "epoch": 4.602941176470588,
      "grad_norm": 3.3134121894836426,
      "learning_rate": 4.623529411764706e-05,
      "loss": 0.4237,
      "step": 313
    },
    {
      "epoch": 4.617647058823529,
      "grad_norm": 4.3406662940979,
      "learning_rate": 4.6191176470588236e-05,
      "loss": 0.4444,
      "step": 314
    },
    {
      "epoch": 4.632352941176471,
      "grad_norm": 2.1468122005462646,
      "learning_rate": 4.614705882352942e-05,
      "loss": 0.2796,
      "step": 315
    },
    {
      "epoch": 4.647058823529412,
      "grad_norm": 1.3981564044952393,
      "learning_rate": 4.6102941176470594e-05,
      "loss": 0.3044,
      "step": 316
    },
    {
      "epoch": 4.661764705882353,
      "grad_norm": 3.726856231689453,
      "learning_rate": 4.605882352941177e-05,
      "loss": 0.3458,
      "step": 317
    },
    {
      "epoch": 4.676470588235294,
      "grad_norm": 3.1176328659057617,
      "learning_rate": 4.6014705882352946e-05,
      "loss": 0.2417,
      "step": 318
    },
    {
      "epoch": 4.6911764705882355,
      "grad_norm": 5.4503045082092285,
      "learning_rate": 4.597058823529412e-05,
      "loss": 0.3973,
      "step": 319
    },
    {
      "epoch": 4.705882352941177,
      "grad_norm": 6.632286548614502,
      "learning_rate": 4.592647058823529e-05,
      "loss": 0.5189,
      "step": 320
    },
    {
      "epoch": 4.705882352941177,
      "eval_accuracy_Block": 0.5853236386914856,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.5853236386914856,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.4299883246421814,
      "eval_mean_accuracy": 0.5853236386914856,
      "eval_mean_iou": 0.2926618193457428,
      "eval_overall_accuracy": 0.5853236386914856,
      "eval_runtime": 8.4064,
      "eval_samples_per_second": 16.178,
      "eval_steps_per_second": 2.022,
      "step": 320
    },
    {
      "epoch": 4.720588235294118,
      "grad_norm": 2.127901315689087,
      "learning_rate": 4.5882352941176467e-05,
      "loss": 0.3907,
      "step": 321
    },
    {
      "epoch": 4.735294117647059,
      "grad_norm": 3.157654285430908,
      "learning_rate": 4.583823529411764e-05,
      "loss": 0.3315,
      "step": 322
    },
    {
      "epoch": 4.75,
      "grad_norm": 9.045167922973633,
      "learning_rate": 4.5794117647058825e-05,
      "loss": 0.5085,
      "step": 323
    },
    {
      "epoch": 4.764705882352941,
      "grad_norm": 1.5959035158157349,
      "learning_rate": 4.575e-05,
      "loss": 0.2781,
      "step": 324
    },
    {
      "epoch": 4.779411764705882,
      "grad_norm": 6.9848713874816895,
      "learning_rate": 4.5705882352941177e-05,
      "loss": 0.5351,
      "step": 325
    },
    {
      "epoch": 4.794117647058823,
      "grad_norm": 3.9177584648132324,
      "learning_rate": 4.566176470588235e-05,
      "loss": 0.5457,
      "step": 326
    },
    {
      "epoch": 4.8088235294117645,
      "grad_norm": 3.3021042346954346,
      "learning_rate": 4.561764705882353e-05,
      "loss": 0.3391,
      "step": 327
    },
    {
      "epoch": 4.823529411764706,
      "grad_norm": 2.602977991104126,
      "learning_rate": 4.5573529411764704e-05,
      "loss": 0.3399,
      "step": 328
    },
    {
      "epoch": 4.838235294117647,
      "grad_norm": 2.754582643508911,
      "learning_rate": 4.552941176470588e-05,
      "loss": 0.3831,
      "step": 329
    },
    {
      "epoch": 4.852941176470588,
      "grad_norm": 2.8679299354553223,
      "learning_rate": 4.5485294117647056e-05,
      "loss": 0.3109,
      "step": 330
    },
    {
      "epoch": 4.867647058823529,
      "grad_norm": 3.930673360824585,
      "learning_rate": 4.544117647058824e-05,
      "loss": 0.3427,
      "step": 331
    },
    {
      "epoch": 4.882352941176471,
      "grad_norm": 3.046095132827759,
      "learning_rate": 4.5397058823529414e-05,
      "loss": 0.4003,
      "step": 332
    },
    {
      "epoch": 4.897058823529412,
      "grad_norm": 2.7095584869384766,
      "learning_rate": 4.535294117647059e-05,
      "loss": 0.3929,
      "step": 333
    },
    {
      "epoch": 4.911764705882353,
      "grad_norm": 1.614127278327942,
      "learning_rate": 4.5308823529411765e-05,
      "loss": 0.356,
      "step": 334
    },
    {
      "epoch": 4.926470588235294,
      "grad_norm": 3.279341459274292,
      "learning_rate": 4.526470588235294e-05,
      "loss": 0.3538,
      "step": 335
    },
    {
      "epoch": 4.9411764705882355,
      "grad_norm": 6.4096550941467285,
      "learning_rate": 4.522058823529412e-05,
      "loss": 0.394,
      "step": 336
    },
    {
      "epoch": 4.955882352941177,
      "grad_norm": 4.372416973114014,
      "learning_rate": 4.517647058823529e-05,
      "loss": 0.3346,
      "step": 337
    },
    {
      "epoch": 4.970588235294118,
      "grad_norm": 2.080500841140747,
      "learning_rate": 4.513235294117647e-05,
      "loss": 0.3686,
      "step": 338
    },
    {
      "epoch": 4.985294117647059,
      "grad_norm": 7.0085272789001465,
      "learning_rate": 4.508823529411765e-05,
      "loss": 0.3811,
      "step": 339
    },
    {
      "epoch": 5.0,
      "grad_norm": 8.551998138427734,
      "learning_rate": 4.504411764705883e-05,
      "loss": 0.5547,
      "step": 340
    },
    {
      "epoch": 5.0,
      "eval_accuracy_Block": 0.6022514243211586,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6022514243211586,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.4619840979576111,
      "eval_mean_accuracy": 0.6022514243211586,
      "eval_mean_iou": 0.3011257121605793,
      "eval_overall_accuracy": 0.6022514243211586,
      "eval_runtime": 7.2754,
      "eval_samples_per_second": 18.693,
      "eval_steps_per_second": 2.337,
      "step": 340
    },
    {
      "epoch": 5.014705882352941,
      "grad_norm": 4.294422626495361,
      "learning_rate": 4.5e-05,
      "loss": 0.5215,
      "step": 341
    },
    {
      "epoch": 5.029411764705882,
      "grad_norm": 3.6860463619232178,
      "learning_rate": 4.495588235294118e-05,
      "loss": 0.3685,
      "step": 342
    },
    {
      "epoch": 5.044117647058823,
      "grad_norm": 2.945826292037964,
      "learning_rate": 4.4911764705882354e-05,
      "loss": 0.298,
      "step": 343
    },
    {
      "epoch": 5.0588235294117645,
      "grad_norm": 4.5955681800842285,
      "learning_rate": 4.486764705882353e-05,
      "loss": 0.4667,
      "step": 344
    },
    {
      "epoch": 5.073529411764706,
      "grad_norm": 3.429819345474243,
      "learning_rate": 4.4823529411764706e-05,
      "loss": 0.3646,
      "step": 345
    },
    {
      "epoch": 5.088235294117647,
      "grad_norm": 5.850747108459473,
      "learning_rate": 4.477941176470588e-05,
      "loss": 0.4226,
      "step": 346
    },
    {
      "epoch": 5.102941176470588,
      "grad_norm": 3.6075046062469482,
      "learning_rate": 4.473529411764706e-05,
      "loss": 0.4688,
      "step": 347
    },
    {
      "epoch": 5.117647058823529,
      "grad_norm": 4.794127464294434,
      "learning_rate": 4.469117647058824e-05,
      "loss": 0.3603,
      "step": 348
    },
    {
      "epoch": 5.132352941176471,
      "grad_norm": 3.1776556968688965,
      "learning_rate": 4.4647058823529416e-05,
      "loss": 0.3502,
      "step": 349
    },
    {
      "epoch": 5.147058823529412,
      "grad_norm": 5.959145545959473,
      "learning_rate": 4.460294117647059e-05,
      "loss": 0.4885,
      "step": 350
    },
    {
      "epoch": 5.161764705882353,
      "grad_norm": 5.496561527252197,
      "learning_rate": 4.455882352941177e-05,
      "loss": 0.5289,
      "step": 351
    },
    {
      "epoch": 5.176470588235294,
      "grad_norm": 1.990864634513855,
      "learning_rate": 4.451470588235294e-05,
      "loss": 0.2217,
      "step": 352
    },
    {
      "epoch": 5.1911764705882355,
      "grad_norm": 2.355180025100708,
      "learning_rate": 4.447058823529412e-05,
      "loss": 0.2886,
      "step": 353
    },
    {
      "epoch": 5.205882352941177,
      "grad_norm": 2.6628899574279785,
      "learning_rate": 4.4426470588235295e-05,
      "loss": 0.3104,
      "step": 354
    },
    {
      "epoch": 5.220588235294118,
      "grad_norm": 4.466838836669922,
      "learning_rate": 4.438235294117647e-05,
      "loss": 0.4012,
      "step": 355
    },
    {
      "epoch": 5.235294117647059,
      "grad_norm": 6.778923988342285,
      "learning_rate": 4.433823529411765e-05,
      "loss": 0.4864,
      "step": 356
    },
    {
      "epoch": 5.25,
      "grad_norm": 3.595733165740967,
      "learning_rate": 4.429411764705883e-05,
      "loss": 0.4034,
      "step": 357
    },
    {
      "epoch": 5.264705882352941,
      "grad_norm": 4.503836154937744,
      "learning_rate": 4.4250000000000005e-05,
      "loss": 0.4343,
      "step": 358
    },
    {
      "epoch": 5.279411764705882,
      "grad_norm": 3.891306161880493,
      "learning_rate": 4.420588235294118e-05,
      "loss": 0.4065,
      "step": 359
    },
    {
      "epoch": 5.294117647058823,
      "grad_norm": 2.9068009853363037,
      "learning_rate": 4.4161764705882357e-05,
      "loss": 0.3728,
      "step": 360
    },
    {
      "epoch": 5.294117647058823,
      "eval_accuracy_Block": 0.6124387449480084,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6124387449480084,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.4238101541996002,
      "eval_mean_accuracy": 0.6124387449480084,
      "eval_mean_iou": 0.3062193724740042,
      "eval_overall_accuracy": 0.6124387449480084,
      "eval_runtime": 7.7187,
      "eval_samples_per_second": 17.62,
      "eval_steps_per_second": 2.202,
      "step": 360
    },
    {
      "epoch": 5.3088235294117645,
      "grad_norm": 1.5984890460968018,
      "learning_rate": 4.411764705882353e-05,
      "loss": 0.2657,
      "step": 361
    },
    {
      "epoch": 5.323529411764706,
      "grad_norm": 3.2612733840942383,
      "learning_rate": 4.407352941176471e-05,
      "loss": 0.3142,
      "step": 362
    },
    {
      "epoch": 5.338235294117647,
      "grad_norm": 2.5178050994873047,
      "learning_rate": 4.402941176470588e-05,
      "loss": 0.3636,
      "step": 363
    },
    {
      "epoch": 5.352941176470588,
      "grad_norm": 6.416796684265137,
      "learning_rate": 4.398529411764706e-05,
      "loss": 0.5304,
      "step": 364
    },
    {
      "epoch": 5.367647058823529,
      "grad_norm": 4.854541778564453,
      "learning_rate": 4.3941176470588236e-05,
      "loss": 0.5572,
      "step": 365
    },
    {
      "epoch": 5.382352941176471,
      "grad_norm": 2.646186351776123,
      "learning_rate": 4.389705882352941e-05,
      "loss": 0.3042,
      "step": 366
    },
    {
      "epoch": 5.397058823529412,
      "grad_norm": 3.11240816116333,
      "learning_rate": 4.385294117647059e-05,
      "loss": 0.3918,
      "step": 367
    },
    {
      "epoch": 5.411764705882353,
      "grad_norm": 1.8862059116363525,
      "learning_rate": 4.380882352941176e-05,
      "loss": 0.317,
      "step": 368
    },
    {
      "epoch": 5.426470588235294,
      "grad_norm": 2.268728733062744,
      "learning_rate": 4.376470588235294e-05,
      "loss": 0.2949,
      "step": 369
    },
    {
      "epoch": 5.4411764705882355,
      "grad_norm": 3.9762632846832275,
      "learning_rate": 4.3720588235294114e-05,
      "loss": 0.3636,
      "step": 370
    },
    {
      "epoch": 5.455882352941177,
      "grad_norm": 2.733438014984131,
      "learning_rate": 4.367647058823529e-05,
      "loss": 0.3956,
      "step": 371
    },
    {
      "epoch": 5.470588235294118,
      "grad_norm": 2.575749635696411,
      "learning_rate": 4.363235294117647e-05,
      "loss": 0.4132,
      "step": 372
    },
    {
      "epoch": 5.485294117647059,
      "grad_norm": 3.4195492267608643,
      "learning_rate": 4.358823529411765e-05,
      "loss": 0.3355,
      "step": 373
    },
    {
      "epoch": 5.5,
      "grad_norm": 3.0906789302825928,
      "learning_rate": 4.3544117647058824e-05,
      "loss": 0.3944,
      "step": 374
    },
    {
      "epoch": 5.514705882352941,
      "grad_norm": 1.5420622825622559,
      "learning_rate": 4.35e-05,
      "loss": 0.3687,
      "step": 375
    },
    {
      "epoch": 5.529411764705882,
      "grad_norm": 3.8463351726531982,
      "learning_rate": 4.3455882352941176e-05,
      "loss": 0.3121,
      "step": 376
    },
    {
      "epoch": 5.544117647058823,
      "grad_norm": 2.7195990085601807,
      "learning_rate": 4.341176470588235e-05,
      "loss": 0.3638,
      "step": 377
    },
    {
      "epoch": 5.5588235294117645,
      "grad_norm": 7.038568019866943,
      "learning_rate": 4.336764705882353e-05,
      "loss": 0.4468,
      "step": 378
    },
    {
      "epoch": 5.573529411764706,
      "grad_norm": 4.746292591094971,
      "learning_rate": 4.3323529411764703e-05,
      "loss": 0.4222,
      "step": 379
    },
    {
      "epoch": 5.588235294117647,
      "grad_norm": 9.120553970336914,
      "learning_rate": 4.3279411764705886e-05,
      "loss": 0.7434,
      "step": 380
    },
    {
      "epoch": 5.588235294117647,
      "eval_accuracy_Block": 0.6742952489556348,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6742952489556348,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.42631134390830994,
      "eval_mean_accuracy": 0.6742952489556348,
      "eval_mean_iou": 0.3371476244778174,
      "eval_overall_accuracy": 0.6742952489556348,
      "eval_runtime": 7.1874,
      "eval_samples_per_second": 18.922,
      "eval_steps_per_second": 2.365,
      "step": 380
    },
    {
      "epoch": 5.602941176470588,
      "grad_norm": 8.065903663635254,
      "learning_rate": 4.323529411764706e-05,
      "loss": 0.5896,
      "step": 381
    },
    {
      "epoch": 5.617647058823529,
      "grad_norm": 2.9091081619262695,
      "learning_rate": 4.319117647058824e-05,
      "loss": 0.3298,
      "step": 382
    },
    {
      "epoch": 5.632352941176471,
      "grad_norm": 1.7582298517227173,
      "learning_rate": 4.3147058823529413e-05,
      "loss": 0.3249,
      "step": 383
    },
    {
      "epoch": 5.647058823529412,
      "grad_norm": 4.328554153442383,
      "learning_rate": 4.310294117647059e-05,
      "loss": 0.4027,
      "step": 384
    },
    {
      "epoch": 5.661764705882353,
      "grad_norm": 5.824625492095947,
      "learning_rate": 4.3058823529411765e-05,
      "loss": 0.3727,
      "step": 385
    },
    {
      "epoch": 5.676470588235294,
      "grad_norm": 3.5807504653930664,
      "learning_rate": 4.301470588235294e-05,
      "loss": 0.3735,
      "step": 386
    },
    {
      "epoch": 5.6911764705882355,
      "grad_norm": 6.373931884765625,
      "learning_rate": 4.2970588235294117e-05,
      "loss": 0.3654,
      "step": 387
    },
    {
      "epoch": 5.705882352941177,
      "grad_norm": 3.64097261428833,
      "learning_rate": 4.29264705882353e-05,
      "loss": 0.4011,
      "step": 388
    },
    {
      "epoch": 5.720588235294118,
      "grad_norm": 2.688194990158081,
      "learning_rate": 4.2882352941176475e-05,
      "loss": 0.3054,
      "step": 389
    },
    {
      "epoch": 5.735294117647059,
      "grad_norm": 4.115407943725586,
      "learning_rate": 4.283823529411765e-05,
      "loss": 0.4666,
      "step": 390
    },
    {
      "epoch": 5.75,
      "grad_norm": 4.465144157409668,
      "learning_rate": 4.2794117647058827e-05,
      "loss": 0.3326,
      "step": 391
    },
    {
      "epoch": 5.764705882352941,
      "grad_norm": 3.2989397048950195,
      "learning_rate": 4.275e-05,
      "loss": 0.4005,
      "step": 392
    },
    {
      "epoch": 5.779411764705882,
      "grad_norm": 1.9987201690673828,
      "learning_rate": 4.270588235294118e-05,
      "loss": 0.3237,
      "step": 393
    },
    {
      "epoch": 5.794117647058823,
      "grad_norm": 2.7448582649230957,
      "learning_rate": 4.2661764705882354e-05,
      "loss": 0.368,
      "step": 394
    },
    {
      "epoch": 5.8088235294117645,
      "grad_norm": 4.265299320220947,
      "learning_rate": 4.261764705882353e-05,
      "loss": 0.4912,
      "step": 395
    },
    {
      "epoch": 5.823529411764706,
      "grad_norm": 3.8327279090881348,
      "learning_rate": 4.2573529411764706e-05,
      "loss": 0.3498,
      "step": 396
    },
    {
      "epoch": 5.838235294117647,
      "grad_norm": 3.035737991333008,
      "learning_rate": 4.252941176470589e-05,
      "loss": 0.3958,
      "step": 397
    },
    {
      "epoch": 5.852941176470588,
      "grad_norm": 3.206796884536743,
      "learning_rate": 4.2485294117647064e-05,
      "loss": 0.3748,
      "step": 398
    },
    {
      "epoch": 5.867647058823529,
      "grad_norm": 2.8286070823669434,
      "learning_rate": 4.244117647058824e-05,
      "loss": 0.3366,
      "step": 399
    },
    {
      "epoch": 5.882352941176471,
      "grad_norm": 2.4019832611083984,
      "learning_rate": 4.2397058823529416e-05,
      "loss": 0.3254,
      "step": 400
    },
    {
      "epoch": 5.882352941176471,
      "eval_accuracy_Block": 0.6689166217197009,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6689166217197009,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.3892172574996948,
      "eval_mean_accuracy": 0.6689166217197009,
      "eval_mean_iou": 0.33445831085985045,
      "eval_overall_accuracy": 0.6689166217197009,
      "eval_runtime": 15.1155,
      "eval_samples_per_second": 8.997,
      "eval_steps_per_second": 1.125,
      "step": 400
    },
    {
      "epoch": 5.897058823529412,
      "grad_norm": 1.9830124378204346,
      "learning_rate": 4.235294117647059e-05,
      "loss": 0.2926,
      "step": 401
    },
    {
      "epoch": 5.911764705882353,
      "grad_norm": 5.021200180053711,
      "learning_rate": 4.230882352941177e-05,
      "loss": 0.4745,
      "step": 402
    },
    {
      "epoch": 5.926470588235294,
      "grad_norm": 3.3185057640075684,
      "learning_rate": 4.226470588235294e-05,
      "loss": 0.373,
      "step": 403
    },
    {
      "epoch": 5.9411764705882355,
      "grad_norm": 5.677527904510498,
      "learning_rate": 4.222058823529412e-05,
      "loss": 0.4688,
      "step": 404
    },
    {
      "epoch": 5.955882352941177,
      "grad_norm": 6.547268390655518,
      "learning_rate": 4.2176470588235294e-05,
      "loss": 0.4854,
      "step": 405
    },
    {
      "epoch": 5.970588235294118,
      "grad_norm": 2.9711663722991943,
      "learning_rate": 4.213235294117647e-05,
      "loss": 0.3022,
      "step": 406
    },
    {
      "epoch": 5.985294117647059,
      "grad_norm": 3.129430055618286,
      "learning_rate": 4.2088235294117646e-05,
      "loss": 0.3256,
      "step": 407
    },
    {
      "epoch": 6.0,
      "grad_norm": 3.5957648754119873,
      "learning_rate": 4.204411764705882e-05,
      "loss": 0.4049,
      "step": 408
    },
    {
      "epoch": 6.014705882352941,
      "grad_norm": 3.446847438812256,
      "learning_rate": 4.2e-05,
      "loss": 0.3766,
      "step": 409
    },
    {
      "epoch": 6.029411764705882,
      "grad_norm": 2.286897659301758,
      "learning_rate": 4.1955882352941173e-05,
      "loss": 0.4239,
      "step": 410
    },
    {
      "epoch": 6.044117647058823,
      "grad_norm": 7.553369522094727,
      "learning_rate": 4.191176470588235e-05,
      "loss": 0.5449,
      "step": 411
    },
    {
      "epoch": 6.0588235294117645,
      "grad_norm": 2.6701090335845947,
      "learning_rate": 4.1867647058823525e-05,
      "loss": 0.4781,
      "step": 412
    },
    {
      "epoch": 6.073529411764706,
      "grad_norm": 2.0013887882232666,
      "learning_rate": 4.182352941176471e-05,
      "loss": 0.3359,
      "step": 413
    },
    {
      "epoch": 6.088235294117647,
      "grad_norm": 2.5708563327789307,
      "learning_rate": 4.1779411764705883e-05,
      "loss": 0.3992,
      "step": 414
    },
    {
      "epoch": 6.102941176470588,
      "grad_norm": 2.423135757446289,
      "learning_rate": 4.173529411764706e-05,
      "loss": 0.2962,
      "step": 415
    },
    {
      "epoch": 6.117647058823529,
      "grad_norm": 9.26431941986084,
      "learning_rate": 4.1691176470588235e-05,
      "loss": 0.5382,
      "step": 416
    },
    {
      "epoch": 6.132352941176471,
      "grad_norm": 7.323166847229004,
      "learning_rate": 4.164705882352941e-05,
      "loss": 0.4248,
      "step": 417
    },
    {
      "epoch": 6.147058823529412,
      "grad_norm": 4.327495574951172,
      "learning_rate": 4.160294117647059e-05,
      "loss": 0.3352,
      "step": 418
    },
    {
      "epoch": 6.161764705882353,
      "grad_norm": 1.794695258140564,
      "learning_rate": 4.155882352941176e-05,
      "loss": 0.2669,
      "step": 419
    },
    {
      "epoch": 6.176470588235294,
      "grad_norm": 3.2629363536834717,
      "learning_rate": 4.151470588235294e-05,
      "loss": 0.3091,
      "step": 420
    },
    {
      "epoch": 6.176470588235294,
      "eval_accuracy_Block": 0.6510126417093307,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6510126417093307,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.45212695002555847,
      "eval_mean_accuracy": 0.6510126417093307,
      "eval_mean_iou": 0.32550632085466535,
      "eval_overall_accuracy": 0.6510126417093307,
      "eval_runtime": 7.3089,
      "eval_samples_per_second": 18.607,
      "eval_steps_per_second": 2.326,
      "step": 420
    },
    {
      "epoch": 6.1911764705882355,
      "grad_norm": 1.2662280797958374,
      "learning_rate": 4.147058823529412e-05,
      "loss": 0.293,
      "step": 421
    },
    {
      "epoch": 6.205882352941177,
      "grad_norm": 2.4389195442199707,
      "learning_rate": 4.1426470588235297e-05,
      "loss": 0.3223,
      "step": 422
    },
    {
      "epoch": 6.220588235294118,
      "grad_norm": 4.660746097564697,
      "learning_rate": 4.138235294117647e-05,
      "loss": 0.2888,
      "step": 423
    },
    {
      "epoch": 6.235294117647059,
      "grad_norm": 2.4857375621795654,
      "learning_rate": 4.133823529411765e-05,
      "loss": 0.282,
      "step": 424
    },
    {
      "epoch": 6.25,
      "grad_norm": 2.9734482765197754,
      "learning_rate": 4.1294117647058824e-05,
      "loss": 0.3414,
      "step": 425
    },
    {
      "epoch": 6.264705882352941,
      "grad_norm": 5.550743579864502,
      "learning_rate": 4.125e-05,
      "loss": 0.5855,
      "step": 426
    },
    {
      "epoch": 6.279411764705882,
      "grad_norm": 1.583357810974121,
      "learning_rate": 4.1205882352941176e-05,
      "loss": 0.2781,
      "step": 427
    },
    {
      "epoch": 6.294117647058823,
      "grad_norm": 1.188698410987854,
      "learning_rate": 4.116176470588235e-05,
      "loss": 0.277,
      "step": 428
    },
    {
      "epoch": 6.3088235294117645,
      "grad_norm": 2.280543565750122,
      "learning_rate": 4.1117647058823534e-05,
      "loss": 0.3449,
      "step": 429
    },
    {
      "epoch": 6.323529411764706,
      "grad_norm": 1.4665108919143677,
      "learning_rate": 4.107352941176471e-05,
      "loss": 0.2984,
      "step": 430
    },
    {
      "epoch": 6.338235294117647,
      "grad_norm": 2.698333501815796,
      "learning_rate": 4.1029411764705886e-05,
      "loss": 0.346,
      "step": 431
    },
    {
      "epoch": 6.352941176470588,
      "grad_norm": 8.53382682800293,
      "learning_rate": 4.098529411764706e-05,
      "loss": 0.5259,
      "step": 432
    },
    {
      "epoch": 6.367647058823529,
      "grad_norm": 4.318075180053711,
      "learning_rate": 4.094117647058824e-05,
      "loss": 0.4025,
      "step": 433
    },
    {
      "epoch": 6.382352941176471,
      "grad_norm": 4.880067348480225,
      "learning_rate": 4.089705882352941e-05,
      "loss": 0.2783,
      "step": 434
    },
    {
      "epoch": 6.397058823529412,
      "grad_norm": 3.285606861114502,
      "learning_rate": 4.085294117647059e-05,
      "loss": 0.3484,
      "step": 435
    },
    {
      "epoch": 6.411764705882353,
      "grad_norm": 7.089143753051758,
      "learning_rate": 4.0808823529411765e-05,
      "loss": 0.3722,
      "step": 436
    },
    {
      "epoch": 6.426470588235294,
      "grad_norm": 4.344649314880371,
      "learning_rate": 4.076470588235295e-05,
      "loss": 0.4296,
      "step": 437
    },
    {
      "epoch": 6.4411764705882355,
      "grad_norm": 3.9056413173675537,
      "learning_rate": 4.072058823529412e-05,
      "loss": 0.359,
      "step": 438
    },
    {
      "epoch": 6.455882352941177,
      "grad_norm": 1.826321005821228,
      "learning_rate": 4.06764705882353e-05,
      "loss": 0.2937,
      "step": 439
    },
    {
      "epoch": 6.470588235294118,
      "grad_norm": 4.003102779388428,
      "learning_rate": 4.0632352941176474e-05,
      "loss": 0.4091,
      "step": 440
    },
    {
      "epoch": 6.470588235294118,
      "eval_accuracy_Block": 0.6755478395281154,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6755478395281154,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.3905738294124603,
      "eval_mean_accuracy": 0.6755478395281154,
      "eval_mean_iou": 0.3377739197640577,
      "eval_overall_accuracy": 0.6755478395281154,
      "eval_runtime": 8.0493,
      "eval_samples_per_second": 16.896,
      "eval_steps_per_second": 2.112,
      "step": 440
    },
    {
      "epoch": 6.485294117647059,
      "grad_norm": 1.5126968622207642,
      "learning_rate": 4.058823529411765e-05,
      "loss": 0.2733,
      "step": 441
    },
    {
      "epoch": 6.5,
      "grad_norm": 1.068243145942688,
      "learning_rate": 4.0544117647058826e-05,
      "loss": 0.3279,
      "step": 442
    },
    {
      "epoch": 6.514705882352941,
      "grad_norm": 1.9814797639846802,
      "learning_rate": 4.05e-05,
      "loss": 0.3158,
      "step": 443
    },
    {
      "epoch": 6.529411764705882,
      "grad_norm": 4.183263301849365,
      "learning_rate": 4.045588235294118e-05,
      "loss": 0.3114,
      "step": 444
    },
    {
      "epoch": 6.544117647058823,
      "grad_norm": 5.877117156982422,
      "learning_rate": 4.041176470588236e-05,
      "loss": 0.2615,
      "step": 445
    },
    {
      "epoch": 6.5588235294117645,
      "grad_norm": 4.046482563018799,
      "learning_rate": 4.0367647058823536e-05,
      "loss": 0.402,
      "step": 446
    },
    {
      "epoch": 6.573529411764706,
      "grad_norm": 5.036182880401611,
      "learning_rate": 4.032352941176471e-05,
      "loss": 0.4645,
      "step": 447
    },
    {
      "epoch": 6.588235294117647,
      "grad_norm": 3.7715625762939453,
      "learning_rate": 4.027941176470588e-05,
      "loss": 0.3182,
      "step": 448
    },
    {
      "epoch": 6.602941176470588,
      "grad_norm": 3.4654390811920166,
      "learning_rate": 4.023529411764706e-05,
      "loss": 0.3238,
      "step": 449
    },
    {
      "epoch": 6.617647058823529,
      "grad_norm": 3.640026569366455,
      "learning_rate": 4.019117647058823e-05,
      "loss": 0.3557,
      "step": 450
    },
    {
      "epoch": 6.632352941176471,
      "grad_norm": 4.218992233276367,
      "learning_rate": 4.014705882352941e-05,
      "loss": 0.3936,
      "step": 451
    },
    {
      "epoch": 6.647058823529412,
      "grad_norm": 8.121273040771484,
      "learning_rate": 4.0102941176470584e-05,
      "loss": 0.7588,
      "step": 452
    },
    {
      "epoch": 6.661764705882353,
      "grad_norm": 6.83192777633667,
      "learning_rate": 4.005882352941177e-05,
      "loss": 0.4815,
      "step": 453
    },
    {
      "epoch": 6.676470588235294,
      "grad_norm": 1.9525024890899658,
      "learning_rate": 4.001470588235294e-05,
      "loss": 0.3029,
      "step": 454
    },
    {
      "epoch": 6.6911764705882355,
      "grad_norm": 8.460062980651855,
      "learning_rate": 3.997058823529412e-05,
      "loss": 0.592,
      "step": 455
    },
    {
      "epoch": 6.705882352941177,
      "grad_norm": 4.096501350402832,
      "learning_rate": 3.9926470588235294e-05,
      "loss": 0.3904,
      "step": 456
    },
    {
      "epoch": 6.720588235294118,
      "grad_norm": 4.266054630279541,
      "learning_rate": 3.988235294117647e-05,
      "loss": 0.4298,
      "step": 457
    },
    {
      "epoch": 6.735294117647059,
      "grad_norm": 2.3342151641845703,
      "learning_rate": 3.9838235294117646e-05,
      "loss": 0.3352,
      "step": 458
    },
    {
      "epoch": 6.75,
      "grad_norm": 1.532204031944275,
      "learning_rate": 3.979411764705882e-05,
      "loss": 0.3921,
      "step": 459
    },
    {
      "epoch": 6.764705882352941,
      "grad_norm": 3.195920705795288,
      "learning_rate": 3.975e-05,
      "loss": 0.272,
      "step": 460
    },
    {
      "epoch": 6.764705882352941,
      "eval_accuracy_Block": 0.6853950956777923,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6853950956777923,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.38391968607902527,
      "eval_mean_accuracy": 0.6853950956777923,
      "eval_mean_iou": 0.34269754783889617,
      "eval_overall_accuracy": 0.6853950956777923,
      "eval_runtime": 7.5273,
      "eval_samples_per_second": 18.068,
      "eval_steps_per_second": 2.258,
      "step": 460
    },
    {
      "epoch": 6.779411764705882,
      "grad_norm": 4.531239986419678,
      "learning_rate": 3.970588235294117e-05,
      "loss": 0.4961,
      "step": 461
    },
    {
      "epoch": 6.794117647058823,
      "grad_norm": 1.3146549463272095,
      "learning_rate": 3.9661764705882356e-05,
      "loss": 0.2408,
      "step": 462
    },
    {
      "epoch": 6.8088235294117645,
      "grad_norm": 9.318385124206543,
      "learning_rate": 3.961764705882353e-05,
      "loss": 0.435,
      "step": 463
    },
    {
      "epoch": 6.823529411764706,
      "grad_norm": 10.315536499023438,
      "learning_rate": 3.957352941176471e-05,
      "loss": 0.3048,
      "step": 464
    },
    {
      "epoch": 6.838235294117647,
      "grad_norm": 4.555558681488037,
      "learning_rate": 3.952941176470588e-05,
      "loss": 0.4047,
      "step": 465
    },
    {
      "epoch": 6.852941176470588,
      "grad_norm": 1.6652882099151611,
      "learning_rate": 3.948529411764706e-05,
      "loss": 0.2474,
      "step": 466
    },
    {
      "epoch": 6.867647058823529,
      "grad_norm": 1.8692219257354736,
      "learning_rate": 3.9441176470588235e-05,
      "loss": 0.3251,
      "step": 467
    },
    {
      "epoch": 6.882352941176471,
      "grad_norm": 3.1190621852874756,
      "learning_rate": 3.939705882352941e-05,
      "loss": 0.3099,
      "step": 468
    },
    {
      "epoch": 6.897058823529412,
      "grad_norm": 4.6790852546691895,
      "learning_rate": 3.9352941176470586e-05,
      "loss": 0.3755,
      "step": 469
    },
    {
      "epoch": 6.911764705882353,
      "grad_norm": 4.04844856262207,
      "learning_rate": 3.930882352941177e-05,
      "loss": 0.4668,
      "step": 470
    },
    {
      "epoch": 6.926470588235294,
      "grad_norm": 16.55146026611328,
      "learning_rate": 3.9264705882352945e-05,
      "loss": 0.5199,
      "step": 471
    },
    {
      "epoch": 6.9411764705882355,
      "grad_norm": 3.71349835395813,
      "learning_rate": 3.922058823529412e-05,
      "loss": 0.3393,
      "step": 472
    },
    {
      "epoch": 6.955882352941177,
      "grad_norm": 5.0354766845703125,
      "learning_rate": 3.9176470588235296e-05,
      "loss": 0.3687,
      "step": 473
    },
    {
      "epoch": 6.970588235294118,
      "grad_norm": 3.678835153579712,
      "learning_rate": 3.913235294117647e-05,
      "loss": 0.4926,
      "step": 474
    },
    {
      "epoch": 6.985294117647059,
      "grad_norm": 4.355136394500732,
      "learning_rate": 3.908823529411765e-05,
      "loss": 0.4422,
      "step": 475
    },
    {
      "epoch": 7.0,
      "grad_norm": 9.07699966430664,
      "learning_rate": 3.9044117647058823e-05,
      "loss": 0.5891,
      "step": 476
    },
    {
      "epoch": 7.014705882352941,
      "grad_norm": 2.654533863067627,
      "learning_rate": 3.9e-05,
      "loss": 0.3592,
      "step": 477
    },
    {
      "epoch": 7.029411764705882,
      "grad_norm": 4.285197734832764,
      "learning_rate": 3.895588235294118e-05,
      "loss": 0.4482,
      "step": 478
    },
    {
      "epoch": 7.044117647058823,
      "grad_norm": 3.420252561569214,
      "learning_rate": 3.891176470588236e-05,
      "loss": 0.3619,
      "step": 479
    },
    {
      "epoch": 7.0588235294117645,
      "grad_norm": 3.384539842605591,
      "learning_rate": 3.8867647058823533e-05,
      "loss": 0.3419,
      "step": 480
    },
    {
      "epoch": 7.0588235294117645,
      "eval_accuracy_Block": 0.6190733594515491,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6190733594515491,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.3893354833126068,
      "eval_mean_accuracy": 0.6190733594515491,
      "eval_mean_iou": 0.30953667972577453,
      "eval_overall_accuracy": 0.6190733594515491,
      "eval_runtime": 11.2722,
      "eval_samples_per_second": 12.065,
      "eval_steps_per_second": 1.508,
      "step": 480
    },
    {
      "epoch": 7.073529411764706,
      "grad_norm": 5.821094512939453,
      "learning_rate": 3.882352941176471e-05,
      "loss": 0.3244,
      "step": 481
    },
    {
      "epoch": 7.088235294117647,
      "grad_norm": 2.880067825317383,
      "learning_rate": 3.8779411764705885e-05,
      "loss": 0.314,
      "step": 482
    },
    {
      "epoch": 7.102941176470588,
      "grad_norm": 3.3155102729797363,
      "learning_rate": 3.873529411764706e-05,
      "loss": 0.3902,
      "step": 483
    },
    {
      "epoch": 7.117647058823529,
      "grad_norm": 1.3880466222763062,
      "learning_rate": 3.869117647058824e-05,
      "loss": 0.2399,
      "step": 484
    },
    {
      "epoch": 7.132352941176471,
      "grad_norm": 4.198984146118164,
      "learning_rate": 3.864705882352941e-05,
      "loss": 0.4151,
      "step": 485
    },
    {
      "epoch": 7.147058823529412,
      "grad_norm": 2.2717363834381104,
      "learning_rate": 3.8602941176470595e-05,
      "loss": 0.2762,
      "step": 486
    },
    {
      "epoch": 7.161764705882353,
      "grad_norm": 4.043246746063232,
      "learning_rate": 3.855882352941177e-05,
      "loss": 0.3338,
      "step": 487
    },
    {
      "epoch": 7.176470588235294,
      "grad_norm": 1.2329963445663452,
      "learning_rate": 3.8514705882352947e-05,
      "loss": 0.2786,
      "step": 488
    },
    {
      "epoch": 7.1911764705882355,
      "grad_norm": 1.6513592004776,
      "learning_rate": 3.847058823529412e-05,
      "loss": 0.2858,
      "step": 489
    },
    {
      "epoch": 7.205882352941177,
      "grad_norm": 4.224104881286621,
      "learning_rate": 3.842647058823529e-05,
      "loss": 0.3738,
      "step": 490
    },
    {
      "epoch": 7.220588235294118,
      "grad_norm": 1.6361503601074219,
      "learning_rate": 3.838235294117647e-05,
      "loss": 0.2338,
      "step": 491
    },
    {
      "epoch": 7.235294117647059,
      "grad_norm": 3.051388740539551,
      "learning_rate": 3.833823529411764e-05,
      "loss": 0.3343,
      "step": 492
    },
    {
      "epoch": 7.25,
      "grad_norm": 1.7426214218139648,
      "learning_rate": 3.829411764705882e-05,
      "loss": 0.3222,
      "step": 493
    },
    {
      "epoch": 7.264705882352941,
      "grad_norm": 3.693422555923462,
      "learning_rate": 3.825e-05,
      "loss": 0.3913,
      "step": 494
    },
    {
      "epoch": 7.279411764705882,
      "grad_norm": 3.329594135284424,
      "learning_rate": 3.820588235294118e-05,
      "loss": 0.3887,
      "step": 495
    },
    {
      "epoch": 7.294117647058823,
      "grad_norm": 9.544548988342285,
      "learning_rate": 3.816176470588235e-05,
      "loss": 0.4494,
      "step": 496
    },
    {
      "epoch": 7.3088235294117645,
      "grad_norm": 7.331145763397217,
      "learning_rate": 3.811764705882353e-05,
      "loss": 0.5722,
      "step": 497
    },
    {
      "epoch": 7.323529411764706,
      "grad_norm": 3.1081326007843018,
      "learning_rate": 3.8073529411764705e-05,
      "loss": 0.4112,
      "step": 498
    },
    {
      "epoch": 7.338235294117647,
      "grad_norm": 3.532557725906372,
      "learning_rate": 3.802941176470588e-05,
      "loss": 0.479,
      "step": 499
    },
    {
      "epoch": 7.352941176470588,
      "grad_norm": 4.679332733154297,
      "learning_rate": 3.7985294117647056e-05,
      "loss": 0.3936,
      "step": 500
    },
    {
      "epoch": 7.352941176470588,
      "eval_accuracy_Block": 0.7214427201872069,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7214427201872069,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.40052008628845215,
      "eval_mean_accuracy": 0.7214427201872069,
      "eval_mean_iou": 0.36072136009360345,
      "eval_overall_accuracy": 0.7214427201872069,
      "eval_runtime": 7.2029,
      "eval_samples_per_second": 18.881,
      "eval_steps_per_second": 2.36,
      "step": 500
    },
    {
      "epoch": 7.367647058823529,
      "grad_norm": 1.2356934547424316,
      "learning_rate": 3.794117647058823e-05,
      "loss": 0.2777,
      "step": 501
    },
    {
      "epoch": 7.382352941176471,
      "grad_norm": 5.647619247436523,
      "learning_rate": 3.7897058823529415e-05,
      "loss": 0.4952,
      "step": 502
    },
    {
      "epoch": 7.397058823529412,
      "grad_norm": 4.697364330291748,
      "learning_rate": 3.785294117647059e-05,
      "loss": 0.4069,
      "step": 503
    },
    {
      "epoch": 7.411764705882353,
      "grad_norm": 3.3131179809570312,
      "learning_rate": 3.7808823529411766e-05,
      "loss": 0.3951,
      "step": 504
    },
    {
      "epoch": 7.426470588235294,
      "grad_norm": 1.5777125358581543,
      "learning_rate": 3.776470588235294e-05,
      "loss": 0.2553,
      "step": 505
    },
    {
      "epoch": 7.4411764705882355,
      "grad_norm": 8.3453950881958,
      "learning_rate": 3.772058823529412e-05,
      "loss": 0.4142,
      "step": 506
    },
    {
      "epoch": 7.455882352941177,
      "grad_norm": 5.81790018081665,
      "learning_rate": 3.7676470588235294e-05,
      "loss": 0.4001,
      "step": 507
    },
    {
      "epoch": 7.470588235294118,
      "grad_norm": 3.5951101779937744,
      "learning_rate": 3.763235294117647e-05,
      "loss": 0.3998,
      "step": 508
    },
    {
      "epoch": 7.485294117647059,
      "grad_norm": 6.4552507400512695,
      "learning_rate": 3.7588235294117645e-05,
      "loss": 0.4445,
      "step": 509
    },
    {
      "epoch": 7.5,
      "grad_norm": 2.608152389526367,
      "learning_rate": 3.754411764705883e-05,
      "loss": 0.3914,
      "step": 510
    },
    {
      "epoch": 7.514705882352941,
      "grad_norm": 6.959570407867432,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 0.3744,
      "step": 511
    },
    {
      "epoch": 7.529411764705882,
      "grad_norm": 4.189582347869873,
      "learning_rate": 3.745588235294118e-05,
      "loss": 0.3586,
      "step": 512
    },
    {
      "epoch": 7.544117647058823,
      "grad_norm": 3.3046534061431885,
      "learning_rate": 3.7411764705882355e-05,
      "loss": 0.4019,
      "step": 513
    },
    {
      "epoch": 7.5588235294117645,
      "grad_norm": 1.4311524629592896,
      "learning_rate": 3.736764705882353e-05,
      "loss": 0.2584,
      "step": 514
    },
    {
      "epoch": 7.573529411764706,
      "grad_norm": 2.2761662006378174,
      "learning_rate": 3.732352941176471e-05,
      "loss": 0.2806,
      "step": 515
    },
    {
      "epoch": 7.588235294117647,
      "grad_norm": 5.20179557800293,
      "learning_rate": 3.727941176470588e-05,
      "loss": 0.4505,
      "step": 516
    },
    {
      "epoch": 7.602941176470588,
      "grad_norm": 2.1605989933013916,
      "learning_rate": 3.723529411764706e-05,
      "loss": 0.2679,
      "step": 517
    },
    {
      "epoch": 7.617647058823529,
      "grad_norm": 7.52947473526001,
      "learning_rate": 3.7191176470588234e-05,
      "loss": 0.4249,
      "step": 518
    },
    {
      "epoch": 7.632352941176471,
      "grad_norm": 8.859139442443848,
      "learning_rate": 3.714705882352942e-05,
      "loss": 0.4501,
      "step": 519
    },
    {
      "epoch": 7.647058823529412,
      "grad_norm": 2.56457781791687,
      "learning_rate": 3.710294117647059e-05,
      "loss": 0.4004,
      "step": 520
    },
    {
      "epoch": 7.647058823529412,
      "eval_accuracy_Block": 0.6322805000314392,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6322805000314392,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.399206280708313,
      "eval_mean_accuracy": 0.6322805000314392,
      "eval_mean_iou": 0.3161402500157196,
      "eval_overall_accuracy": 0.6322805000314392,
      "eval_runtime": 7.0671,
      "eval_samples_per_second": 19.244,
      "eval_steps_per_second": 2.406,
      "step": 520
    },
    {
      "epoch": 7.661764705882353,
      "grad_norm": 7.982357025146484,
      "learning_rate": 3.705882352941177e-05,
      "loss": 0.4359,
      "step": 521
    },
    {
      "epoch": 7.676470588235294,
      "grad_norm": 1.7334308624267578,
      "learning_rate": 3.7014705882352944e-05,
      "loss": 0.3074,
      "step": 522
    },
    {
      "epoch": 7.6911764705882355,
      "grad_norm": 4.771156311035156,
      "learning_rate": 3.697058823529412e-05,
      "loss": 0.3284,
      "step": 523
    },
    {
      "epoch": 7.705882352941177,
      "grad_norm": 1.9401158094406128,
      "learning_rate": 3.6926470588235296e-05,
      "loss": 0.2902,
      "step": 524
    },
    {
      "epoch": 7.720588235294118,
      "grad_norm": 1.2228217124938965,
      "learning_rate": 3.688235294117647e-05,
      "loss": 0.3384,
      "step": 525
    },
    {
      "epoch": 7.735294117647059,
      "grad_norm": 1.8605852127075195,
      "learning_rate": 3.683823529411765e-05,
      "loss": 0.2664,
      "step": 526
    },
    {
      "epoch": 7.75,
      "grad_norm": 14.38451099395752,
      "learning_rate": 3.679411764705883e-05,
      "loss": 0.3988,
      "step": 527
    },
    {
      "epoch": 7.764705882352941,
      "grad_norm": 2.5987038612365723,
      "learning_rate": 3.6750000000000006e-05,
      "loss": 0.2843,
      "step": 528
    },
    {
      "epoch": 7.779411764705882,
      "grad_norm": 6.3708906173706055,
      "learning_rate": 3.670588235294118e-05,
      "loss": 0.4657,
      "step": 529
    },
    {
      "epoch": 7.794117647058823,
      "grad_norm": 3.444132089614868,
      "learning_rate": 3.666176470588236e-05,
      "loss": 0.4148,
      "step": 530
    },
    {
      "epoch": 7.8088235294117645,
      "grad_norm": 4.724797248840332,
      "learning_rate": 3.661764705882353e-05,
      "loss": 0.4336,
      "step": 531
    },
    {
      "epoch": 7.823529411764706,
      "grad_norm": 5.7291364669799805,
      "learning_rate": 3.657352941176471e-05,
      "loss": 0.2818,
      "step": 532
    },
    {
      "epoch": 7.838235294117647,
      "grad_norm": 1.2796061038970947,
      "learning_rate": 3.652941176470588e-05,
      "loss": 0.2976,
      "step": 533
    },
    {
      "epoch": 7.852941176470588,
      "grad_norm": 6.44802713394165,
      "learning_rate": 3.6485294117647054e-05,
      "loss": 0.5009,
      "step": 534
    },
    {
      "epoch": 7.867647058823529,
      "grad_norm": 3.0532336235046387,
      "learning_rate": 3.6441176470588236e-05,
      "loss": 0.3552,
      "step": 535
    },
    {
      "epoch": 7.882352941176471,
      "grad_norm": 1.2080645561218262,
      "learning_rate": 3.639705882352941e-05,
      "loss": 0.2811,
      "step": 536
    },
    {
      "epoch": 7.897058823529412,
      "grad_norm": 3.271230459213257,
      "learning_rate": 3.635294117647059e-05,
      "loss": 0.4586,
      "step": 537
    },
    {
      "epoch": 7.911764705882353,
      "grad_norm": 2.767059326171875,
      "learning_rate": 3.6308823529411764e-05,
      "loss": 0.2902,
      "step": 538
    },
    {
      "epoch": 7.926470588235294,
      "grad_norm": 2.4283251762390137,
      "learning_rate": 3.626470588235294e-05,
      "loss": 0.2844,
      "step": 539
    },
    {
      "epoch": 7.9411764705882355,
      "grad_norm": 8.39834976196289,
      "learning_rate": 3.6220588235294115e-05,
      "loss": 0.5127,
      "step": 540
    },
    {
      "epoch": 7.9411764705882355,
      "eval_accuracy_Block": 0.6455033602004019,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6455033602004019,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.40633273124694824,
      "eval_mean_accuracy": 0.6455033602004019,
      "eval_mean_iou": 0.32275168010020094,
      "eval_overall_accuracy": 0.6455033602004019,
      "eval_runtime": 6.9241,
      "eval_samples_per_second": 19.642,
      "eval_steps_per_second": 2.455,
      "step": 540
    },
    {
      "epoch": 7.955882352941177,
      "grad_norm": 4.25529670715332,
      "learning_rate": 3.617647058823529e-05,
      "loss": 0.5306,
      "step": 541
    },
    {
      "epoch": 7.970588235294118,
      "grad_norm": 2.4988791942596436,
      "learning_rate": 3.613235294117647e-05,
      "loss": 0.336,
      "step": 542
    },
    {
      "epoch": 7.985294117647059,
      "grad_norm": 7.971578598022461,
      "learning_rate": 3.608823529411765e-05,
      "loss": 0.6095,
      "step": 543
    },
    {
      "epoch": 8.0,
      "grad_norm": 2.4010372161865234,
      "learning_rate": 3.6044117647058825e-05,
      "loss": 0.2263,
      "step": 544
    },
    {
      "epoch": 8.014705882352942,
      "grad_norm": 2.5299181938171387,
      "learning_rate": 3.6e-05,
      "loss": 0.3657,
      "step": 545
    },
    {
      "epoch": 8.029411764705882,
      "grad_norm": 2.827763557434082,
      "learning_rate": 3.595588235294118e-05,
      "loss": 0.3355,
      "step": 546
    },
    {
      "epoch": 8.044117647058824,
      "grad_norm": 2.000735282897949,
      "learning_rate": 3.591176470588235e-05,
      "loss": 0.2421,
      "step": 547
    },
    {
      "epoch": 8.058823529411764,
      "grad_norm": 1.6733142137527466,
      "learning_rate": 3.586764705882353e-05,
      "loss": 0.3151,
      "step": 548
    },
    {
      "epoch": 8.073529411764707,
      "grad_norm": 1.8463997840881348,
      "learning_rate": 3.5823529411764704e-05,
      "loss": 0.2579,
      "step": 549
    },
    {
      "epoch": 8.088235294117647,
      "grad_norm": 2.691957473754883,
      "learning_rate": 3.577941176470588e-05,
      "loss": 0.2932,
      "step": 550
    },
    {
      "epoch": 8.102941176470589,
      "grad_norm": 1.918431043624878,
      "learning_rate": 3.573529411764706e-05,
      "loss": 0.2833,
      "step": 551
    },
    {
      "epoch": 8.117647058823529,
      "grad_norm": 2.2450857162475586,
      "learning_rate": 3.569117647058824e-05,
      "loss": 0.3029,
      "step": 552
    },
    {
      "epoch": 8.132352941176471,
      "grad_norm": 7.4877471923828125,
      "learning_rate": 3.5647058823529414e-05,
      "loss": 0.3575,
      "step": 553
    },
    {
      "epoch": 8.147058823529411,
      "grad_norm": 2.2393252849578857,
      "learning_rate": 3.560294117647059e-05,
      "loss": 0.2945,
      "step": 554
    },
    {
      "epoch": 8.161764705882353,
      "grad_norm": 2.4346344470977783,
      "learning_rate": 3.5558823529411766e-05,
      "loss": 0.2324,
      "step": 555
    },
    {
      "epoch": 8.176470588235293,
      "grad_norm": 8.655936241149902,
      "learning_rate": 3.551470588235294e-05,
      "loss": 0.3381,
      "step": 556
    },
    {
      "epoch": 8.191176470588236,
      "grad_norm": 3.641730546951294,
      "learning_rate": 3.547058823529412e-05,
      "loss": 0.4032,
      "step": 557
    },
    {
      "epoch": 8.205882352941176,
      "grad_norm": 4.707016468048096,
      "learning_rate": 3.542647058823529e-05,
      "loss": 0.3914,
      "step": 558
    },
    {
      "epoch": 8.220588235294118,
      "grad_norm": 4.43408727645874,
      "learning_rate": 3.5382352941176476e-05,
      "loss": 0.2845,
      "step": 559
    },
    {
      "epoch": 8.235294117647058,
      "grad_norm": 2.2202024459838867,
      "learning_rate": 3.533823529411765e-05,
      "loss": 0.2671,
      "step": 560
    },
    {
      "epoch": 8.235294117647058,
      "eval_accuracy_Block": 0.6896820408987371,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6896820408987371,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.38850435614585876,
      "eval_mean_accuracy": 0.6896820408987371,
      "eval_mean_iou": 0.34484102044936854,
      "eval_overall_accuracy": 0.6896820408987371,
      "eval_runtime": 7.174,
      "eval_samples_per_second": 18.957,
      "eval_steps_per_second": 2.37,
      "step": 560
    },
    {
      "epoch": 8.25,
      "grad_norm": 5.093858242034912,
      "learning_rate": 3.529411764705883e-05,
      "loss": 0.3415,
      "step": 561
    },
    {
      "epoch": 8.264705882352942,
      "grad_norm": 4.254947185516357,
      "learning_rate": 3.525e-05,
      "loss": 0.3903,
      "step": 562
    },
    {
      "epoch": 8.279411764705882,
      "grad_norm": 4.390009880065918,
      "learning_rate": 3.520588235294118e-05,
      "loss": 0.3958,
      "step": 563
    },
    {
      "epoch": 8.294117647058824,
      "grad_norm": 2.2967679500579834,
      "learning_rate": 3.5161764705882355e-05,
      "loss": 0.3105,
      "step": 564
    },
    {
      "epoch": 8.308823529411764,
      "grad_norm": 2.5408992767333984,
      "learning_rate": 3.511764705882353e-05,
      "loss": 0.4168,
      "step": 565
    },
    {
      "epoch": 8.323529411764707,
      "grad_norm": 3.8124799728393555,
      "learning_rate": 3.5073529411764706e-05,
      "loss": 0.3472,
      "step": 566
    },
    {
      "epoch": 8.338235294117647,
      "grad_norm": 2.484776735305786,
      "learning_rate": 3.502941176470588e-05,
      "loss": 0.2067,
      "step": 567
    },
    {
      "epoch": 8.352941176470589,
      "grad_norm": 5.7393035888671875,
      "learning_rate": 3.4985294117647065e-05,
      "loss": 0.4431,
      "step": 568
    },
    {
      "epoch": 8.367647058823529,
      "grad_norm": 8.692943572998047,
      "learning_rate": 3.494117647058824e-05,
      "loss": 0.5522,
      "step": 569
    },
    {
      "epoch": 8.382352941176471,
      "grad_norm": 5.1937575340271,
      "learning_rate": 3.4897058823529416e-05,
      "loss": 0.4635,
      "step": 570
    },
    {
      "epoch": 8.397058823529411,
      "grad_norm": 2.832031011581421,
      "learning_rate": 3.485294117647059e-05,
      "loss": 0.2541,
      "step": 571
    },
    {
      "epoch": 8.411764705882353,
      "grad_norm": 3.0202770233154297,
      "learning_rate": 3.480882352941177e-05,
      "loss": 0.3862,
      "step": 572
    },
    {
      "epoch": 8.426470588235293,
      "grad_norm": 4.502285480499268,
      "learning_rate": 3.4764705882352944e-05,
      "loss": 0.3635,
      "step": 573
    },
    {
      "epoch": 8.441176470588236,
      "grad_norm": 3.296124219894409,
      "learning_rate": 3.472058823529412e-05,
      "loss": 0.2649,
      "step": 574
    },
    {
      "epoch": 8.455882352941176,
      "grad_norm": 6.271303176879883,
      "learning_rate": 3.467647058823529e-05,
      "loss": 0.4966,
      "step": 575
    },
    {
      "epoch": 8.470588235294118,
      "grad_norm": 5.9432597160339355,
      "learning_rate": 3.463235294117647e-05,
      "loss": 1.1713,
      "step": 576
    },
    {
      "epoch": 8.485294117647058,
      "grad_norm": 1.2915675640106201,
      "learning_rate": 3.458823529411765e-05,
      "loss": 0.2692,
      "step": 577
    },
    {
      "epoch": 8.5,
      "grad_norm": 1.721097707748413,
      "learning_rate": 3.454411764705882e-05,
      "loss": 0.2681,
      "step": 578
    },
    {
      "epoch": 8.514705882352942,
      "grad_norm": 2.9010140895843506,
      "learning_rate": 3.45e-05,
      "loss": 0.3273,
      "step": 579
    },
    {
      "epoch": 8.529411764705882,
      "grad_norm": 2.4281222820281982,
      "learning_rate": 3.4455882352941174e-05,
      "loss": 0.3014,
      "step": 580
    },
    {
      "epoch": 8.529411764705882,
      "eval_accuracy_Block": 0.6229581517681299,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6229581517681299,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.39896252751350403,
      "eval_mean_accuracy": 0.6229581517681299,
      "eval_mean_iou": 0.3114790758840649,
      "eval_overall_accuracy": 0.6229581517681299,
      "eval_runtime": 7.3157,
      "eval_samples_per_second": 18.59,
      "eval_steps_per_second": 2.324,
      "step": 580
    },
    {
      "epoch": 8.544117647058824,
      "grad_norm": 1.7216861248016357,
      "learning_rate": 3.441176470588235e-05,
      "loss": 0.2949,
      "step": 581
    },
    {
      "epoch": 8.558823529411764,
      "grad_norm": 1.207430124282837,
      "learning_rate": 3.4367647058823526e-05,
      "loss": 0.2429,
      "step": 582
    },
    {
      "epoch": 8.573529411764707,
      "grad_norm": 2.7943499088287354,
      "learning_rate": 3.43235294117647e-05,
      "loss": 0.3881,
      "step": 583
    },
    {
      "epoch": 8.588235294117647,
      "grad_norm": 2.416348934173584,
      "learning_rate": 3.4279411764705884e-05,
      "loss": 0.4354,
      "step": 584
    },
    {
      "epoch": 8.602941176470589,
      "grad_norm": 3.2190377712249756,
      "learning_rate": 3.423529411764706e-05,
      "loss": 0.3235,
      "step": 585
    },
    {
      "epoch": 8.617647058823529,
      "grad_norm": 7.05153751373291,
      "learning_rate": 3.4191176470588236e-05,
      "loss": 0.3425,
      "step": 586
    },
    {
      "epoch": 8.632352941176471,
      "grad_norm": 4.996293544769287,
      "learning_rate": 3.414705882352941e-05,
      "loss": 0.4574,
      "step": 587
    },
    {
      "epoch": 8.647058823529411,
      "grad_norm": 1.3664937019348145,
      "learning_rate": 3.410294117647059e-05,
      "loss": 0.3011,
      "step": 588
    },
    {
      "epoch": 8.661764705882353,
      "grad_norm": 5.08936071395874,
      "learning_rate": 3.405882352941176e-05,
      "loss": 0.5371,
      "step": 589
    },
    {
      "epoch": 8.676470588235293,
      "grad_norm": 4.763689994812012,
      "learning_rate": 3.401470588235294e-05,
      "loss": 0.2864,
      "step": 590
    },
    {
      "epoch": 8.691176470588236,
      "grad_norm": 7.015601634979248,
      "learning_rate": 3.3970588235294115e-05,
      "loss": 0.325,
      "step": 591
    },
    {
      "epoch": 8.705882352941176,
      "grad_norm": 2.4941108226776123,
      "learning_rate": 3.39264705882353e-05,
      "loss": 0.2405,
      "step": 592
    },
    {
      "epoch": 8.720588235294118,
      "grad_norm": 5.6273722648620605,
      "learning_rate": 3.388235294117647e-05,
      "loss": 0.3631,
      "step": 593
    },
    {
      "epoch": 8.735294117647058,
      "grad_norm": 3.5616323947906494,
      "learning_rate": 3.383823529411765e-05,
      "loss": 0.2744,
      "step": 594
    },
    {
      "epoch": 8.75,
      "grad_norm": 6.419029712677002,
      "learning_rate": 3.3794117647058825e-05,
      "loss": 0.3812,
      "step": 595
    },
    {
      "epoch": 8.764705882352942,
      "grad_norm": 4.277733325958252,
      "learning_rate": 3.375e-05,
      "loss": 0.3374,
      "step": 596
    },
    {
      "epoch": 8.779411764705882,
      "grad_norm": 11.204219818115234,
      "learning_rate": 3.3705882352941176e-05,
      "loss": 0.5967,
      "step": 597
    },
    {
      "epoch": 8.794117647058824,
      "grad_norm": 4.4517011642456055,
      "learning_rate": 3.366176470588235e-05,
      "loss": 0.4002,
      "step": 598
    },
    {
      "epoch": 8.808823529411764,
      "grad_norm": 2.6230580806732178,
      "learning_rate": 3.361764705882353e-05,
      "loss": 0.2986,
      "step": 599
    },
    {
      "epoch": 8.823529411764707,
      "grad_norm": 2.3801963329315186,
      "learning_rate": 3.357352941176471e-05,
      "loss": 0.2887,
      "step": 600
    },
    {
      "epoch": 8.823529411764707,
      "eval_accuracy_Block": 0.6758233667978897,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6758233667978897,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.42164146900177,
      "eval_mean_accuracy": 0.6758233667978897,
      "eval_mean_iou": 0.33791168339894484,
      "eval_overall_accuracy": 0.6758233667978897,
      "eval_runtime": 7.0945,
      "eval_samples_per_second": 19.17,
      "eval_steps_per_second": 2.396,
      "step": 600
    },
    {
      "epoch": 8.838235294117647,
      "grad_norm": 11.206927299499512,
      "learning_rate": 3.3529411764705886e-05,
      "loss": 0.7809,
      "step": 601
    },
    {
      "epoch": 8.852941176470589,
      "grad_norm": 3.6058919429779053,
      "learning_rate": 3.348529411764706e-05,
      "loss": 0.4178,
      "step": 602
    },
    {
      "epoch": 8.867647058823529,
      "grad_norm": 5.871881008148193,
      "learning_rate": 3.344117647058824e-05,
      "loss": 0.6228,
      "step": 603
    },
    {
      "epoch": 8.882352941176471,
      "grad_norm": 3.4579930305480957,
      "learning_rate": 3.3397058823529414e-05,
      "loss": 0.3963,
      "step": 604
    },
    {
      "epoch": 8.897058823529411,
      "grad_norm": 5.708251476287842,
      "learning_rate": 3.335294117647059e-05,
      "loss": 0.3752,
      "step": 605
    },
    {
      "epoch": 8.911764705882353,
      "grad_norm": 5.360845565795898,
      "learning_rate": 3.3308823529411765e-05,
      "loss": 0.4331,
      "step": 606
    },
    {
      "epoch": 8.926470588235293,
      "grad_norm": 3.2263569831848145,
      "learning_rate": 3.326470588235294e-05,
      "loss": 0.2788,
      "step": 607
    },
    {
      "epoch": 8.941176470588236,
      "grad_norm": 4.6753363609313965,
      "learning_rate": 3.3220588235294124e-05,
      "loss": 0.5449,
      "step": 608
    },
    {
      "epoch": 8.955882352941176,
      "grad_norm": 6.162405490875244,
      "learning_rate": 3.31764705882353e-05,
      "loss": 0.3865,
      "step": 609
    },
    {
      "epoch": 8.970588235294118,
      "grad_norm": 4.774177551269531,
      "learning_rate": 3.3132352941176475e-05,
      "loss": 0.5187,
      "step": 610
    },
    {
      "epoch": 8.985294117647058,
      "grad_norm": 2.5992496013641357,
      "learning_rate": 3.308823529411765e-05,
      "loss": 0.3467,
      "step": 611
    },
    {
      "epoch": 9.0,
      "grad_norm": 2.0465097427368164,
      "learning_rate": 3.304411764705883e-05,
      "loss": 0.3054,
      "step": 612
    },
    {
      "epoch": 9.014705882352942,
      "grad_norm": 4.41617488861084,
      "learning_rate": 3.3e-05,
      "loss": 0.3478,
      "step": 613
    },
    {
      "epoch": 9.029411764705882,
      "grad_norm": 2.227073907852173,
      "learning_rate": 3.295588235294118e-05,
      "loss": 0.3839,
      "step": 614
    },
    {
      "epoch": 9.044117647058824,
      "grad_norm": 2.10815167427063,
      "learning_rate": 3.2911764705882354e-05,
      "loss": 0.2973,
      "step": 615
    },
    {
      "epoch": 9.058823529411764,
      "grad_norm": 2.6059696674346924,
      "learning_rate": 3.286764705882354e-05,
      "loss": 0.3844,
      "step": 616
    },
    {
      "epoch": 9.073529411764707,
      "grad_norm": 2.49920916557312,
      "learning_rate": 3.282352941176471e-05,
      "loss": 0.3619,
      "step": 617
    },
    {
      "epoch": 9.088235294117647,
      "grad_norm": 3.7856411933898926,
      "learning_rate": 3.277941176470588e-05,
      "loss": 0.3217,
      "step": 618
    },
    {
      "epoch": 9.102941176470589,
      "grad_norm": 2.114954710006714,
      "learning_rate": 3.273529411764706e-05,
      "loss": 0.3028,
      "step": 619
    },
    {
      "epoch": 9.117647058823529,
      "grad_norm": 5.680638313293457,
      "learning_rate": 3.269117647058823e-05,
      "loss": 0.4824,
      "step": 620
    },
    {
      "epoch": 9.117647058823529,
      "eval_accuracy_Block": 0.7708588677914625,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7708588677914625,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.3964700698852539,
      "eval_mean_accuracy": 0.7708588677914625,
      "eval_mean_iou": 0.38542943389573125,
      "eval_overall_accuracy": 0.7708588677914625,
      "eval_runtime": 7.4015,
      "eval_samples_per_second": 18.375,
      "eval_steps_per_second": 2.297,
      "step": 620
    },
    {
      "epoch": 9.132352941176471,
      "grad_norm": 2.3455779552459717,
      "learning_rate": 3.264705882352941e-05,
      "loss": 0.2894,
      "step": 621
    },
    {
      "epoch": 9.147058823529411,
      "grad_norm": 3.8277037143707275,
      "learning_rate": 3.2602941176470585e-05,
      "loss": 0.2938,
      "step": 622
    },
    {
      "epoch": 9.161764705882353,
      "grad_norm": 1.6529326438903809,
      "learning_rate": 3.255882352941176e-05,
      "loss": 0.2276,
      "step": 623
    },
    {
      "epoch": 9.176470588235293,
      "grad_norm": 2.709320068359375,
      "learning_rate": 3.251470588235294e-05,
      "loss": 0.3726,
      "step": 624
    },
    {
      "epoch": 9.191176470588236,
      "grad_norm": 4.339378833770752,
      "learning_rate": 3.247058823529412e-05,
      "loss": 0.3528,
      "step": 625
    },
    {
      "epoch": 9.205882352941176,
      "grad_norm": 2.2776875495910645,
      "learning_rate": 3.2426470588235295e-05,
      "loss": 0.2651,
      "step": 626
    },
    {
      "epoch": 9.220588235294118,
      "grad_norm": 1.5841883420944214,
      "learning_rate": 3.238235294117647e-05,
      "loss": 0.2935,
      "step": 627
    },
    {
      "epoch": 9.235294117647058,
      "grad_norm": 2.6006298065185547,
      "learning_rate": 3.2338235294117646e-05,
      "loss": 0.3416,
      "step": 628
    },
    {
      "epoch": 9.25,
      "grad_norm": 5.595968723297119,
      "learning_rate": 3.229411764705882e-05,
      "loss": 0.4741,
      "step": 629
    },
    {
      "epoch": 9.264705882352942,
      "grad_norm": 4.710142612457275,
      "learning_rate": 3.225e-05,
      "loss": 0.3448,
      "step": 630
    },
    {
      "epoch": 9.279411764705882,
      "grad_norm": 2.149378776550293,
      "learning_rate": 3.2205882352941174e-05,
      "loss": 0.3202,
      "step": 631
    },
    {
      "epoch": 9.294117647058824,
      "grad_norm": 3.021317958831787,
      "learning_rate": 3.216176470588235e-05,
      "loss": 0.3102,
      "step": 632
    },
    {
      "epoch": 9.308823529411764,
      "grad_norm": 10.73780632019043,
      "learning_rate": 3.211764705882353e-05,
      "loss": 0.4814,
      "step": 633
    },
    {
      "epoch": 9.323529411764707,
      "grad_norm": 6.094594478607178,
      "learning_rate": 3.207352941176471e-05,
      "loss": 0.4859,
      "step": 634
    },
    {
      "epoch": 9.338235294117647,
      "grad_norm": 3.3489460945129395,
      "learning_rate": 3.2029411764705884e-05,
      "loss": 0.3308,
      "step": 635
    },
    {
      "epoch": 9.352941176470589,
      "grad_norm": 4.231950283050537,
      "learning_rate": 3.198529411764706e-05,
      "loss": 0.2589,
      "step": 636
    },
    {
      "epoch": 9.367647058823529,
      "grad_norm": 5.668986797332764,
      "learning_rate": 3.1941176470588235e-05,
      "loss": 0.4101,
      "step": 637
    },
    {
      "epoch": 9.382352941176471,
      "grad_norm": 1.2824056148529053,
      "learning_rate": 3.189705882352941e-05,
      "loss": 0.2943,
      "step": 638
    },
    {
      "epoch": 9.397058823529411,
      "grad_norm": 5.578182220458984,
      "learning_rate": 3.185294117647059e-05,
      "loss": 0.5675,
      "step": 639
    },
    {
      "epoch": 9.411764705882353,
      "grad_norm": 5.4412760734558105,
      "learning_rate": 3.180882352941176e-05,
      "loss": 0.6732,
      "step": 640
    },
    {
      "epoch": 9.411764705882353,
      "eval_accuracy_Block": 0.6198077565350044,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6198077565350044,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.4066388010978699,
      "eval_mean_accuracy": 0.6198077565350044,
      "eval_mean_iou": 0.3099038782675022,
      "eval_overall_accuracy": 0.6198077565350044,
      "eval_runtime": 11.1274,
      "eval_samples_per_second": 12.222,
      "eval_steps_per_second": 1.528,
      "step": 640
    },
    {
      "epoch": 9.426470588235293,
      "grad_norm": 5.063694000244141,
      "learning_rate": 3.1764705882352945e-05,
      "loss": 0.5432,
      "step": 641
    },
    {
      "epoch": 9.441176470588236,
      "grad_norm": 5.192312240600586,
      "learning_rate": 3.172058823529412e-05,
      "loss": 0.4699,
      "step": 642
    },
    {
      "epoch": 9.455882352941176,
      "grad_norm": 3.7846224308013916,
      "learning_rate": 3.16764705882353e-05,
      "loss": 0.3193,
      "step": 643
    },
    {
      "epoch": 9.470588235294118,
      "grad_norm": 2.5610625743865967,
      "learning_rate": 3.163235294117647e-05,
      "loss": 0.2893,
      "step": 644
    },
    {
      "epoch": 9.485294117647058,
      "grad_norm": 10.095426559448242,
      "learning_rate": 3.158823529411765e-05,
      "loss": 0.4069,
      "step": 645
    },
    {
      "epoch": 9.5,
      "grad_norm": 3.3795454502105713,
      "learning_rate": 3.1544117647058824e-05,
      "loss": 0.2889,
      "step": 646
    },
    {
      "epoch": 9.514705882352942,
      "grad_norm": 2.3084957599639893,
      "learning_rate": 3.15e-05,
      "loss": 0.3208,
      "step": 647
    },
    {
      "epoch": 9.529411764705882,
      "grad_norm": 3.1321563720703125,
      "learning_rate": 3.1455882352941176e-05,
      "loss": 0.355,
      "step": 648
    },
    {
      "epoch": 9.544117647058824,
      "grad_norm": 2.697218418121338,
      "learning_rate": 3.141176470588236e-05,
      "loss": 0.262,
      "step": 649
    },
    {
      "epoch": 9.558823529411764,
      "grad_norm": 2.914250135421753,
      "learning_rate": 3.1367647058823534e-05,
      "loss": 0.2637,
      "step": 650
    },
    {
      "epoch": 9.573529411764707,
      "grad_norm": 1.465216875076294,
      "learning_rate": 3.132352941176471e-05,
      "loss": 0.2822,
      "step": 651
    },
    {
      "epoch": 9.588235294117647,
      "grad_norm": 1.8829565048217773,
      "learning_rate": 3.1279411764705886e-05,
      "loss": 0.2913,
      "step": 652
    },
    {
      "epoch": 9.602941176470589,
      "grad_norm": 2.2715981006622314,
      "learning_rate": 3.123529411764706e-05,
      "loss": 0.3088,
      "step": 653
    },
    {
      "epoch": 9.617647058823529,
      "grad_norm": 3.943711757659912,
      "learning_rate": 3.119117647058824e-05,
      "loss": 0.3762,
      "step": 654
    },
    {
      "epoch": 9.632352941176471,
      "grad_norm": 1.4651870727539062,
      "learning_rate": 3.114705882352941e-05,
      "loss": 0.2533,
      "step": 655
    },
    {
      "epoch": 9.647058823529411,
      "grad_norm": 8.830638885498047,
      "learning_rate": 3.110294117647059e-05,
      "loss": 0.6826,
      "step": 656
    },
    {
      "epoch": 9.661764705882353,
      "grad_norm": 2.5369014739990234,
      "learning_rate": 3.105882352941177e-05,
      "loss": 0.2638,
      "step": 657
    },
    {
      "epoch": 9.676470588235293,
      "grad_norm": 1.7382590770721436,
      "learning_rate": 3.101470588235295e-05,
      "loss": 0.3432,
      "step": 658
    },
    {
      "epoch": 9.691176470588236,
      "grad_norm": 3.5250084400177,
      "learning_rate": 3.097058823529412e-05,
      "loss": 0.2941,
      "step": 659
    },
    {
      "epoch": 9.705882352941176,
      "grad_norm": 1.7677364349365234,
      "learning_rate": 3.092647058823529e-05,
      "loss": 0.2925,
      "step": 660
    },
    {
      "epoch": 9.705882352941176,
      "eval_accuracy_Block": 0.685202431970516,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.685202431970516,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.40040329098701477,
      "eval_mean_accuracy": 0.685202431970516,
      "eval_mean_iou": 0.342601215985258,
      "eval_overall_accuracy": 0.685202431970516,
      "eval_runtime": 6.9987,
      "eval_samples_per_second": 19.432,
      "eval_steps_per_second": 2.429,
      "step": 660
    },
    {
      "epoch": 9.720588235294118,
      "grad_norm": 3.5335850715637207,
      "learning_rate": 3.088235294117647e-05,
      "loss": 0.4456,
      "step": 661
    },
    {
      "epoch": 9.735294117647058,
      "grad_norm": 1.1018517017364502,
      "learning_rate": 3.0838235294117644e-05,
      "loss": 0.1858,
      "step": 662
    },
    {
      "epoch": 9.75,
      "grad_norm": 4.70118522644043,
      "learning_rate": 3.079411764705882e-05,
      "loss": 0.3446,
      "step": 663
    },
    {
      "epoch": 9.764705882352942,
      "grad_norm": 1.8775098323822021,
      "learning_rate": 3.0749999999999995e-05,
      "loss": 0.2483,
      "step": 664
    },
    {
      "epoch": 9.779411764705882,
      "grad_norm": 4.173794746398926,
      "learning_rate": 3.070588235294118e-05,
      "loss": 0.4159,
      "step": 665
    },
    {
      "epoch": 9.794117647058824,
      "grad_norm": 5.203517913818359,
      "learning_rate": 3.0661764705882354e-05,
      "loss": 0.7179,
      "step": 666
    },
    {
      "epoch": 9.808823529411764,
      "grad_norm": 13.227526664733887,
      "learning_rate": 3.061764705882353e-05,
      "loss": 0.9841,
      "step": 667
    },
    {
      "epoch": 9.823529411764707,
      "grad_norm": 1.6997746229171753,
      "learning_rate": 3.0573529411764705e-05,
      "loss": 0.2783,
      "step": 668
    },
    {
      "epoch": 9.838235294117647,
      "grad_norm": 1.4191136360168457,
      "learning_rate": 3.052941176470588e-05,
      "loss": 0.2122,
      "step": 669
    },
    {
      "epoch": 9.852941176470589,
      "grad_norm": 3.322840690612793,
      "learning_rate": 3.0485294117647057e-05,
      "loss": 0.3574,
      "step": 670
    },
    {
      "epoch": 9.867647058823529,
      "grad_norm": 2.8602726459503174,
      "learning_rate": 3.0441176470588236e-05,
      "loss": 0.4217,
      "step": 671
    },
    {
      "epoch": 9.882352941176471,
      "grad_norm": 8.081818580627441,
      "learning_rate": 3.0397058823529412e-05,
      "loss": 0.5071,
      "step": 672
    },
    {
      "epoch": 9.897058823529411,
      "grad_norm": 3.0679516792297363,
      "learning_rate": 3.0352941176470588e-05,
      "loss": 0.2795,
      "step": 673
    },
    {
      "epoch": 9.911764705882353,
      "grad_norm": 4.757782936096191,
      "learning_rate": 3.0308823529411763e-05,
      "loss": 0.4071,
      "step": 674
    },
    {
      "epoch": 9.926470588235293,
      "grad_norm": 2.2941935062408447,
      "learning_rate": 3.0264705882352943e-05,
      "loss": 0.3594,
      "step": 675
    },
    {
      "epoch": 9.941176470588236,
      "grad_norm": 1.3688108921051025,
      "learning_rate": 3.022058823529412e-05,
      "loss": 0.3348,
      "step": 676
    },
    {
      "epoch": 9.955882352941176,
      "grad_norm": 5.904361724853516,
      "learning_rate": 3.0176470588235294e-05,
      "loss": 0.5423,
      "step": 677
    },
    {
      "epoch": 9.970588235294118,
      "grad_norm": 6.664627552032471,
      "learning_rate": 3.013235294117647e-05,
      "loss": 0.8565,
      "step": 678
    },
    {
      "epoch": 9.985294117647058,
      "grad_norm": 2.774947166442871,
      "learning_rate": 3.008823529411765e-05,
      "loss": 0.2828,
      "step": 679
    },
    {
      "epoch": 10.0,
      "grad_norm": 6.678658485412598,
      "learning_rate": 3.0044117647058825e-05,
      "loss": 0.3036,
      "step": 680
    },
    {
      "epoch": 10.0,
      "eval_accuracy_Block": 0.7485951900901183,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7485951900901183,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.3815239667892456,
      "eval_mean_accuracy": 0.7485951900901183,
      "eval_mean_iou": 0.37429759504505916,
      "eval_overall_accuracy": 0.7485951900901183,
      "eval_runtime": 7.3525,
      "eval_samples_per_second": 18.497,
      "eval_steps_per_second": 2.312,
      "step": 680
    },
    {
      "epoch": 10.014705882352942,
      "grad_norm": 5.078514099121094,
      "learning_rate": 3e-05,
      "loss": 0.3824,
      "step": 681
    },
    {
      "epoch": 10.029411764705882,
      "grad_norm": 6.204220294952393,
      "learning_rate": 2.9955882352941177e-05,
      "loss": 0.4187,
      "step": 682
    },
    {
      "epoch": 10.044117647058824,
      "grad_norm": 3.5306384563446045,
      "learning_rate": 2.9911764705882352e-05,
      "loss": 0.4433,
      "step": 683
    },
    {
      "epoch": 10.058823529411764,
      "grad_norm": 4.610407829284668,
      "learning_rate": 2.986764705882353e-05,
      "loss": 0.2597,
      "step": 684
    },
    {
      "epoch": 10.073529411764707,
      "grad_norm": 2.325859546661377,
      "learning_rate": 2.9823529411764707e-05,
      "loss": 0.2508,
      "step": 685
    },
    {
      "epoch": 10.088235294117647,
      "grad_norm": 3.38371205329895,
      "learning_rate": 2.9779411764705883e-05,
      "loss": 0.2559,
      "step": 686
    },
    {
      "epoch": 10.102941176470589,
      "grad_norm": 1.9630659818649292,
      "learning_rate": 2.973529411764706e-05,
      "loss": 0.2482,
      "step": 687
    },
    {
      "epoch": 10.117647058823529,
      "grad_norm": 3.5183682441711426,
      "learning_rate": 2.9691176470588238e-05,
      "loss": 0.3478,
      "step": 688
    },
    {
      "epoch": 10.132352941176471,
      "grad_norm": 9.28695011138916,
      "learning_rate": 2.9647058823529414e-05,
      "loss": 0.454,
      "step": 689
    },
    {
      "epoch": 10.147058823529411,
      "grad_norm": 6.544167518615723,
      "learning_rate": 2.960294117647059e-05,
      "loss": 0.4609,
      "step": 690
    },
    {
      "epoch": 10.161764705882353,
      "grad_norm": 3.8677220344543457,
      "learning_rate": 2.9558823529411766e-05,
      "loss": 0.3299,
      "step": 691
    },
    {
      "epoch": 10.176470588235293,
      "grad_norm": 1.3577221632003784,
      "learning_rate": 2.951470588235294e-05,
      "loss": 0.3036,
      "step": 692
    },
    {
      "epoch": 10.191176470588236,
      "grad_norm": 2.754603147506714,
      "learning_rate": 2.9470588235294117e-05,
      "loss": 0.2802,
      "step": 693
    },
    {
      "epoch": 10.205882352941176,
      "grad_norm": 5.401357650756836,
      "learning_rate": 2.9426470588235293e-05,
      "loss": 0.4806,
      "step": 694
    },
    {
      "epoch": 10.220588235294118,
      "grad_norm": 2.705423355102539,
      "learning_rate": 2.938235294117647e-05,
      "loss": 0.3717,
      "step": 695
    },
    {
      "epoch": 10.235294117647058,
      "grad_norm": 2.7302305698394775,
      "learning_rate": 2.9338235294117648e-05,
      "loss": 0.3273,
      "step": 696
    },
    {
      "epoch": 10.25,
      "grad_norm": 5.052133083343506,
      "learning_rate": 2.9294117647058824e-05,
      "loss": 0.4455,
      "step": 697
    },
    {
      "epoch": 10.264705882352942,
      "grad_norm": 4.575026988983154,
      "learning_rate": 2.925e-05,
      "loss": 0.4294,
      "step": 698
    },
    {
      "epoch": 10.279411764705882,
      "grad_norm": 3.4018383026123047,
      "learning_rate": 2.9205882352941175e-05,
      "loss": 0.3399,
      "step": 699
    },
    {
      "epoch": 10.294117647058824,
      "grad_norm": 1.3588988780975342,
      "learning_rate": 2.9161764705882354e-05,
      "loss": 0.3,
      "step": 700
    },
    {
      "epoch": 10.294117647058824,
      "eval_accuracy_Block": 0.7007155335765684,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7007155335765684,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.38759028911590576,
      "eval_mean_accuracy": 0.7007155335765684,
      "eval_mean_iou": 0.3503577667882842,
      "eval_overall_accuracy": 0.7007155335765684,
      "eval_runtime": 6.9323,
      "eval_samples_per_second": 19.618,
      "eval_steps_per_second": 2.452,
      "step": 700
    },
    {
      "epoch": 10.308823529411764,
      "grad_norm": 5.202178955078125,
      "learning_rate": 2.911764705882353e-05,
      "loss": 0.4765,
      "step": 701
    },
    {
      "epoch": 10.323529411764707,
      "grad_norm": 2.748338222503662,
      "learning_rate": 2.9073529411764706e-05,
      "loss": 0.3557,
      "step": 702
    },
    {
      "epoch": 10.338235294117647,
      "grad_norm": 1.9096291065216064,
      "learning_rate": 2.9029411764705882e-05,
      "loss": 0.2824,
      "step": 703
    },
    {
      "epoch": 10.352941176470589,
      "grad_norm": 3.1351888179779053,
      "learning_rate": 2.898529411764706e-05,
      "loss": 0.3352,
      "step": 704
    },
    {
      "epoch": 10.367647058823529,
      "grad_norm": 2.3120908737182617,
      "learning_rate": 2.8941176470588237e-05,
      "loss": 0.3056,
      "step": 705
    },
    {
      "epoch": 10.382352941176471,
      "grad_norm": 5.615477085113525,
      "learning_rate": 2.8897058823529413e-05,
      "loss": 0.4787,
      "step": 706
    },
    {
      "epoch": 10.397058823529411,
      "grad_norm": 3.518296957015991,
      "learning_rate": 2.885294117647059e-05,
      "loss": 0.3043,
      "step": 707
    },
    {
      "epoch": 10.411764705882353,
      "grad_norm": 6.395807266235352,
      "learning_rate": 2.8808823529411768e-05,
      "loss": 0.4654,
      "step": 708
    },
    {
      "epoch": 10.426470588235293,
      "grad_norm": 5.675027370452881,
      "learning_rate": 2.8764705882352943e-05,
      "loss": 0.4161,
      "step": 709
    },
    {
      "epoch": 10.441176470588236,
      "grad_norm": 3.9989190101623535,
      "learning_rate": 2.872058823529412e-05,
      "loss": 0.2897,
      "step": 710
    },
    {
      "epoch": 10.455882352941176,
      "grad_norm": 2.474349021911621,
      "learning_rate": 2.8676470588235295e-05,
      "loss": 0.3165,
      "step": 711
    },
    {
      "epoch": 10.470588235294118,
      "grad_norm": 4.61520528793335,
      "learning_rate": 2.8632352941176474e-05,
      "loss": 0.3777,
      "step": 712
    },
    {
      "epoch": 10.485294117647058,
      "grad_norm": 3.010070562362671,
      "learning_rate": 2.8588235294117647e-05,
      "loss": 0.2974,
      "step": 713
    },
    {
      "epoch": 10.5,
      "grad_norm": 4.986562252044678,
      "learning_rate": 2.8544117647058822e-05,
      "loss": 0.4009,
      "step": 714
    },
    {
      "epoch": 10.514705882352942,
      "grad_norm": 3.1974260807037354,
      "learning_rate": 2.8499999999999998e-05,
      "loss": 0.3012,
      "step": 715
    },
    {
      "epoch": 10.529411764705882,
      "grad_norm": 2.7084155082702637,
      "learning_rate": 2.8455882352941177e-05,
      "loss": 0.3757,
      "step": 716
    },
    {
      "epoch": 10.544117647058824,
      "grad_norm": 3.2325594425201416,
      "learning_rate": 2.8411764705882353e-05,
      "loss": 0.4697,
      "step": 717
    },
    {
      "epoch": 10.558823529411764,
      "grad_norm": 2.158358335494995,
      "learning_rate": 2.836764705882353e-05,
      "loss": 0.4454,
      "step": 718
    },
    {
      "epoch": 10.573529411764707,
      "grad_norm": 2.954484462738037,
      "learning_rate": 2.8323529411764705e-05,
      "loss": 0.2981,
      "step": 719
    },
    {
      "epoch": 10.588235294117647,
      "grad_norm": 2.706026554107666,
      "learning_rate": 2.8279411764705884e-05,
      "loss": 0.2343,
      "step": 720
    },
    {
      "epoch": 10.588235294117647,
      "eval_accuracy_Block": 0.6813031839514213,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6813031839514213,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.3971744477748871,
      "eval_mean_accuracy": 0.6813031839514213,
      "eval_mean_iou": 0.34065159197571065,
      "eval_overall_accuracy": 0.6813031839514213,
      "eval_runtime": 9.237,
      "eval_samples_per_second": 14.723,
      "eval_steps_per_second": 1.84,
      "step": 720
    },
    {
      "epoch": 10.602941176470589,
      "grad_norm": 3.1475677490234375,
      "learning_rate": 2.823529411764706e-05,
      "loss": 0.4175,
      "step": 721
    },
    {
      "epoch": 10.617647058823529,
      "grad_norm": 1.6896976232528687,
      "learning_rate": 2.8191176470588236e-05,
      "loss": 0.3834,
      "step": 722
    },
    {
      "epoch": 10.632352941176471,
      "grad_norm": 3.103271007537842,
      "learning_rate": 2.814705882352941e-05,
      "loss": 0.3125,
      "step": 723
    },
    {
      "epoch": 10.647058823529411,
      "grad_norm": 3.2283284664154053,
      "learning_rate": 2.810294117647059e-05,
      "loss": 0.2955,
      "step": 724
    },
    {
      "epoch": 10.661764705882353,
      "grad_norm": 2.186429738998413,
      "learning_rate": 2.8058823529411766e-05,
      "loss": 0.2562,
      "step": 725
    },
    {
      "epoch": 10.676470588235293,
      "grad_norm": 1.634159803390503,
      "learning_rate": 2.8014705882352942e-05,
      "loss": 0.2433,
      "step": 726
    },
    {
      "epoch": 10.691176470588236,
      "grad_norm": 7.360162258148193,
      "learning_rate": 2.7970588235294118e-05,
      "loss": 0.4743,
      "step": 727
    },
    {
      "epoch": 10.705882352941176,
      "grad_norm": 2.5854690074920654,
      "learning_rate": 2.7926470588235297e-05,
      "loss": 0.3562,
      "step": 728
    },
    {
      "epoch": 10.720588235294118,
      "grad_norm": 1.934119701385498,
      "learning_rate": 2.7882352941176473e-05,
      "loss": 0.3065,
      "step": 729
    },
    {
      "epoch": 10.735294117647058,
      "grad_norm": 5.1931681632995605,
      "learning_rate": 2.783823529411765e-05,
      "loss": 0.5773,
      "step": 730
    },
    {
      "epoch": 10.75,
      "grad_norm": 1.6722332239151,
      "learning_rate": 2.7794117647058824e-05,
      "loss": 0.2644,
      "step": 731
    },
    {
      "epoch": 10.764705882352942,
      "grad_norm": 2.9678125381469727,
      "learning_rate": 2.7750000000000004e-05,
      "loss": 0.4342,
      "step": 732
    },
    {
      "epoch": 10.779411764705882,
      "grad_norm": 6.042565822601318,
      "learning_rate": 2.770588235294118e-05,
      "loss": 0.4595,
      "step": 733
    },
    {
      "epoch": 10.794117647058824,
      "grad_norm": 1.6457988023757935,
      "learning_rate": 2.7661764705882355e-05,
      "loss": 0.3155,
      "step": 734
    },
    {
      "epoch": 10.808823529411764,
      "grad_norm": 5.8237624168396,
      "learning_rate": 2.7617647058823528e-05,
      "loss": 0.3211,
      "step": 735
    },
    {
      "epoch": 10.823529411764707,
      "grad_norm": 3.100790023803711,
      "learning_rate": 2.7573529411764707e-05,
      "loss": 0.3114,
      "step": 736
    },
    {
      "epoch": 10.838235294117647,
      "grad_norm": 1.1081058979034424,
      "learning_rate": 2.7529411764705883e-05,
      "loss": 0.2424,
      "step": 737
    },
    {
      "epoch": 10.852941176470589,
      "grad_norm": 15.881382942199707,
      "learning_rate": 2.748529411764706e-05,
      "loss": 0.5403,
      "step": 738
    },
    {
      "epoch": 10.867647058823529,
      "grad_norm": 6.0814008712768555,
      "learning_rate": 2.7441176470588234e-05,
      "loss": 0.5464,
      "step": 739
    },
    {
      "epoch": 10.882352941176471,
      "grad_norm": 1.922624945640564,
      "learning_rate": 2.739705882352941e-05,
      "loss": 0.3778,
      "step": 740
    },
    {
      "epoch": 10.882352941176471,
      "eval_accuracy_Block": 0.6594092720613769,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6594092720613769,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.3916100561618805,
      "eval_mean_accuracy": 0.6594092720613769,
      "eval_mean_iou": 0.32970463603068845,
      "eval_overall_accuracy": 0.6594092720613769,
      "eval_runtime": 7.1042,
      "eval_samples_per_second": 19.144,
      "eval_steps_per_second": 2.393,
      "step": 740
    },
    {
      "epoch": 10.897058823529411,
      "grad_norm": 2.593324899673462,
      "learning_rate": 2.735294117647059e-05,
      "loss": 0.3129,
      "step": 741
    },
    {
      "epoch": 10.911764705882353,
      "grad_norm": 1.6379308700561523,
      "learning_rate": 2.7308823529411765e-05,
      "loss": 0.199,
      "step": 742
    },
    {
      "epoch": 10.926470588235293,
      "grad_norm": 3.691805362701416,
      "learning_rate": 2.726470588235294e-05,
      "loss": 0.2974,
      "step": 743
    },
    {
      "epoch": 10.941176470588236,
      "grad_norm": 2.109276294708252,
      "learning_rate": 2.7220588235294117e-05,
      "loss": 0.3084,
      "step": 744
    },
    {
      "epoch": 10.955882352941176,
      "grad_norm": 2.341843843460083,
      "learning_rate": 2.7176470588235296e-05,
      "loss": 0.3538,
      "step": 745
    },
    {
      "epoch": 10.970588235294118,
      "grad_norm": 3.279898166656494,
      "learning_rate": 2.713235294117647e-05,
      "loss": 0.3303,
      "step": 746
    },
    {
      "epoch": 10.985294117647058,
      "grad_norm": 4.250845909118652,
      "learning_rate": 2.7088235294117647e-05,
      "loss": 0.4782,
      "step": 747
    },
    {
      "epoch": 11.0,
      "grad_norm": 2.711686849594116,
      "learning_rate": 2.7044117647058823e-05,
      "loss": 0.369,
      "step": 748
    },
    {
      "epoch": 11.014705882352942,
      "grad_norm": 5.239382266998291,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 0.4707,
      "step": 749
    },
    {
      "epoch": 11.029411764705882,
      "grad_norm": 1.6645569801330566,
      "learning_rate": 2.6955882352941178e-05,
      "loss": 0.2513,
      "step": 750
    },
    {
      "epoch": 11.044117647058824,
      "grad_norm": 2.725165367126465,
      "learning_rate": 2.6911764705882354e-05,
      "loss": 0.3826,
      "step": 751
    },
    {
      "epoch": 11.058823529411764,
      "grad_norm": 4.333810329437256,
      "learning_rate": 2.686764705882353e-05,
      "loss": 0.2621,
      "step": 752
    },
    {
      "epoch": 11.073529411764707,
      "grad_norm": 4.425183296203613,
      "learning_rate": 2.682352941176471e-05,
      "loss": 0.3494,
      "step": 753
    },
    {
      "epoch": 11.088235294117647,
      "grad_norm": 1.1783058643341064,
      "learning_rate": 2.6779411764705885e-05,
      "loss": 0.2281,
      "step": 754
    },
    {
      "epoch": 11.102941176470589,
      "grad_norm": 2.311647653579712,
      "learning_rate": 2.673529411764706e-05,
      "loss": 0.3627,
      "step": 755
    },
    {
      "epoch": 11.117647058823529,
      "grad_norm": 5.820001125335693,
      "learning_rate": 2.6691176470588233e-05,
      "loss": 0.3059,
      "step": 756
    },
    {
      "epoch": 11.132352941176471,
      "grad_norm": 2.0035696029663086,
      "learning_rate": 2.6647058823529412e-05,
      "loss": 0.2708,
      "step": 757
    },
    {
      "epoch": 11.147058823529411,
      "grad_norm": 2.0852694511413574,
      "learning_rate": 2.6602941176470588e-05,
      "loss": 0.2714,
      "step": 758
    },
    {
      "epoch": 11.161764705882353,
      "grad_norm": 1.0727691650390625,
      "learning_rate": 2.6558823529411764e-05,
      "loss": 0.224,
      "step": 759
    },
    {
      "epoch": 11.176470588235293,
      "grad_norm": 1.4319281578063965,
      "learning_rate": 2.651470588235294e-05,
      "loss": 0.2973,
      "step": 760
    },
    {
      "epoch": 11.176470588235293,
      "eval_accuracy_Block": 0.7555110983458568,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7555110983458568,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.4026247560977936,
      "eval_mean_accuracy": 0.7555110983458568,
      "eval_mean_iou": 0.3777555491729284,
      "eval_overall_accuracy": 0.7555110983458568,
      "eval_runtime": 8.1676,
      "eval_samples_per_second": 16.651,
      "eval_steps_per_second": 2.081,
      "step": 760
    },
    {
      "epoch": 11.191176470588236,
      "grad_norm": 1.6402299404144287,
      "learning_rate": 2.647058823529412e-05,
      "loss": 0.3049,
      "step": 761
    },
    {
      "epoch": 11.205882352941176,
      "grad_norm": 7.886685371398926,
      "learning_rate": 2.6426470588235295e-05,
      "loss": 0.6607,
      "step": 762
    },
    {
      "epoch": 11.220588235294118,
      "grad_norm": 1.4319874048233032,
      "learning_rate": 2.638235294117647e-05,
      "loss": 0.2235,
      "step": 763
    },
    {
      "epoch": 11.235294117647058,
      "grad_norm": 1.733194351196289,
      "learning_rate": 2.6338235294117646e-05,
      "loss": 0.2236,
      "step": 764
    },
    {
      "epoch": 11.25,
      "grad_norm": 3.7229931354522705,
      "learning_rate": 2.6294117647058825e-05,
      "loss": 0.3111,
      "step": 765
    },
    {
      "epoch": 11.264705882352942,
      "grad_norm": 2.3998820781707764,
      "learning_rate": 2.625e-05,
      "loss": 0.2787,
      "step": 766
    },
    {
      "epoch": 11.279411764705882,
      "grad_norm": 2.8281304836273193,
      "learning_rate": 2.6205882352941177e-05,
      "loss": 0.2952,
      "step": 767
    },
    {
      "epoch": 11.294117647058824,
      "grad_norm": 3.7074220180511475,
      "learning_rate": 2.6161764705882353e-05,
      "loss": 0.2837,
      "step": 768
    },
    {
      "epoch": 11.308823529411764,
      "grad_norm": 2.241598606109619,
      "learning_rate": 2.6117647058823532e-05,
      "loss": 0.3513,
      "step": 769
    },
    {
      "epoch": 11.323529411764707,
      "grad_norm": 1.4331996440887451,
      "learning_rate": 2.6073529411764708e-05,
      "loss": 0.2634,
      "step": 770
    },
    {
      "epoch": 11.338235294117647,
      "grad_norm": 2.299386739730835,
      "learning_rate": 2.6029411764705883e-05,
      "loss": 0.3631,
      "step": 771
    },
    {
      "epoch": 11.352941176470589,
      "grad_norm": 3.5940911769866943,
      "learning_rate": 2.598529411764706e-05,
      "loss": 0.3544,
      "step": 772
    },
    {
      "epoch": 11.367647058823529,
      "grad_norm": 1.5288089513778687,
      "learning_rate": 2.594117647058824e-05,
      "loss": 0.2119,
      "step": 773
    },
    {
      "epoch": 11.382352941176471,
      "grad_norm": 5.1148176193237305,
      "learning_rate": 2.5897058823529414e-05,
      "loss": 0.3321,
      "step": 774
    },
    {
      "epoch": 11.397058823529411,
      "grad_norm": 3.0792689323425293,
      "learning_rate": 2.585294117647059e-05,
      "loss": 0.3625,
      "step": 775
    },
    {
      "epoch": 11.411764705882353,
      "grad_norm": 2.8403167724609375,
      "learning_rate": 2.5808823529411766e-05,
      "loss": 0.2712,
      "step": 776
    },
    {
      "epoch": 11.426470588235293,
      "grad_norm": 5.3753156661987305,
      "learning_rate": 2.576470588235294e-05,
      "loss": 0.4658,
      "step": 777
    },
    {
      "epoch": 11.441176470588236,
      "grad_norm": 7.853067398071289,
      "learning_rate": 2.5720588235294117e-05,
      "loss": 0.6211,
      "step": 778
    },
    {
      "epoch": 11.455882352941176,
      "grad_norm": 2.4858803749084473,
      "learning_rate": 2.5676470588235293e-05,
      "loss": 0.2768,
      "step": 779
    },
    {
      "epoch": 11.470588235294118,
      "grad_norm": 4.337386131286621,
      "learning_rate": 2.563235294117647e-05,
      "loss": 0.2754,
      "step": 780
    },
    {
      "epoch": 11.470588235294118,
      "eval_accuracy_Block": 0.699094836043896,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.699094836043896,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.3982442319393158,
      "eval_mean_accuracy": 0.699094836043896,
      "eval_mean_iou": 0.349547418021948,
      "eval_overall_accuracy": 0.699094836043896,
      "eval_runtime": 9.0453,
      "eval_samples_per_second": 15.036,
      "eval_steps_per_second": 1.879,
      "step": 780
    },
    {
      "epoch": 11.485294117647058,
      "grad_norm": 5.7303009033203125,
      "learning_rate": 2.5588235294117648e-05,
      "loss": 0.3526,
      "step": 781
    },
    {
      "epoch": 11.5,
      "grad_norm": 3.625016689300537,
      "learning_rate": 2.5544117647058824e-05,
      "loss": 0.4869,
      "step": 782
    },
    {
      "epoch": 11.514705882352942,
      "grad_norm": 7.298449516296387,
      "learning_rate": 2.55e-05,
      "loss": 0.4214,
      "step": 783
    },
    {
      "epoch": 11.529411764705882,
      "grad_norm": 1.9987297058105469,
      "learning_rate": 2.5455882352941176e-05,
      "loss": 0.2883,
      "step": 784
    },
    {
      "epoch": 11.544117647058824,
      "grad_norm": 2.931405782699585,
      "learning_rate": 2.5411764705882355e-05,
      "loss": 0.4181,
      "step": 785
    },
    {
      "epoch": 11.558823529411764,
      "grad_norm": 1.7416691780090332,
      "learning_rate": 2.536764705882353e-05,
      "loss": 0.3153,
      "step": 786
    },
    {
      "epoch": 11.573529411764707,
      "grad_norm": 2.5695557594299316,
      "learning_rate": 2.5323529411764706e-05,
      "loss": 0.3243,
      "step": 787
    },
    {
      "epoch": 11.588235294117647,
      "grad_norm": 5.283788204193115,
      "learning_rate": 2.5279411764705882e-05,
      "loss": 0.3817,
      "step": 788
    },
    {
      "epoch": 11.602941176470589,
      "grad_norm": 3.0080833435058594,
      "learning_rate": 2.523529411764706e-05,
      "loss": 0.3326,
      "step": 789
    },
    {
      "epoch": 11.617647058823529,
      "grad_norm": 2.6139872074127197,
      "learning_rate": 2.5191176470588237e-05,
      "loss": 0.3436,
      "step": 790
    },
    {
      "epoch": 11.632352941176471,
      "grad_norm": 8.593419075012207,
      "learning_rate": 2.5147058823529413e-05,
      "loss": 0.4417,
      "step": 791
    },
    {
      "epoch": 11.647058823529411,
      "grad_norm": 6.836676597595215,
      "learning_rate": 2.510294117647059e-05,
      "loss": 0.4645,
      "step": 792
    },
    {
      "epoch": 11.661764705882353,
      "grad_norm": 4.067365646362305,
      "learning_rate": 2.5058823529411768e-05,
      "loss": 0.415,
      "step": 793
    },
    {
      "epoch": 11.676470588235293,
      "grad_norm": 8.091598510742188,
      "learning_rate": 2.5014705882352944e-05,
      "loss": 0.4578,
      "step": 794
    },
    {
      "epoch": 11.691176470588236,
      "grad_norm": 1.523600697517395,
      "learning_rate": 2.497058823529412e-05,
      "loss": 0.3402,
      "step": 795
    },
    {
      "epoch": 11.705882352941176,
      "grad_norm": 1.2611156702041626,
      "learning_rate": 2.4926470588235295e-05,
      "loss": 0.2532,
      "step": 796
    },
    {
      "epoch": 11.720588235294118,
      "grad_norm": 4.845242500305176,
      "learning_rate": 2.488235294117647e-05,
      "loss": 0.3562,
      "step": 797
    },
    {
      "epoch": 11.735294117647058,
      "grad_norm": 4.514313697814941,
      "learning_rate": 2.4838235294117647e-05,
      "loss": 0.3074,
      "step": 798
    },
    {
      "epoch": 11.75,
      "grad_norm": 2.0326123237609863,
      "learning_rate": 2.4794117647058823e-05,
      "loss": 0.266,
      "step": 799
    },
    {
      "epoch": 11.764705882352942,
      "grad_norm": 4.5360283851623535,
      "learning_rate": 2.475e-05,
      "loss": 0.3415,
      "step": 800
    },
    {
      "epoch": 11.764705882352942,
      "eval_accuracy_Block": 0.7305286426711484,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7305286426711484,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.3822929859161377,
      "eval_mean_accuracy": 0.7305286426711484,
      "eval_mean_iou": 0.3652643213355742,
      "eval_overall_accuracy": 0.7305286426711484,
      "eval_runtime": 8.0693,
      "eval_samples_per_second": 16.854,
      "eval_steps_per_second": 2.107,
      "step": 800
    },
    {
      "epoch": 11.779411764705882,
      "grad_norm": 2.8116865158081055,
      "learning_rate": 2.4705882352941174e-05,
      "loss": 0.3083,
      "step": 801
    },
    {
      "epoch": 11.794117647058824,
      "grad_norm": 2.4666860103607178,
      "learning_rate": 2.4661764705882353e-05,
      "loss": 0.2721,
      "step": 802
    },
    {
      "epoch": 11.808823529411764,
      "grad_norm": 1.5657942295074463,
      "learning_rate": 2.461764705882353e-05,
      "loss": 0.317,
      "step": 803
    },
    {
      "epoch": 11.823529411764707,
      "grad_norm": 1.0256552696228027,
      "learning_rate": 2.4573529411764705e-05,
      "loss": 0.2526,
      "step": 804
    },
    {
      "epoch": 11.838235294117647,
      "grad_norm": 5.480611801147461,
      "learning_rate": 2.452941176470588e-05,
      "loss": 0.3699,
      "step": 805
    },
    {
      "epoch": 11.852941176470589,
      "grad_norm": 2.490555763244629,
      "learning_rate": 2.448529411764706e-05,
      "loss": 0.2708,
      "step": 806
    },
    {
      "epoch": 11.867647058823529,
      "grad_norm": 5.154334545135498,
      "learning_rate": 2.4441176470588236e-05,
      "loss": 0.3028,
      "step": 807
    },
    {
      "epoch": 11.882352941176471,
      "grad_norm": 7.2040534019470215,
      "learning_rate": 2.439705882352941e-05,
      "loss": 0.5406,
      "step": 808
    },
    {
      "epoch": 11.897058823529411,
      "grad_norm": 7.3798909187316895,
      "learning_rate": 2.4352941176470587e-05,
      "loss": 0.5223,
      "step": 809
    },
    {
      "epoch": 11.911764705882353,
      "grad_norm": 5.643123149871826,
      "learning_rate": 2.4308823529411767e-05,
      "loss": 0.4085,
      "step": 810
    },
    {
      "epoch": 11.926470588235293,
      "grad_norm": 3.9496898651123047,
      "learning_rate": 2.4264705882352942e-05,
      "loss": 0.3307,
      "step": 811
    },
    {
      "epoch": 11.941176470588236,
      "grad_norm": 2.6400113105773926,
      "learning_rate": 2.4220588235294118e-05,
      "loss": 0.3026,
      "step": 812
    },
    {
      "epoch": 11.955882352941176,
      "grad_norm": 4.762270450592041,
      "learning_rate": 2.4176470588235294e-05,
      "loss": 0.3542,
      "step": 813
    },
    {
      "epoch": 11.970588235294118,
      "grad_norm": 4.113474369049072,
      "learning_rate": 2.4132352941176473e-05,
      "loss": 0.3709,
      "step": 814
    },
    {
      "epoch": 11.985294117647058,
      "grad_norm": 3.1234068870544434,
      "learning_rate": 2.408823529411765e-05,
      "loss": 0.3009,
      "step": 815
    },
    {
      "epoch": 12.0,
      "grad_norm": 4.295464515686035,
      "learning_rate": 2.4044117647058825e-05,
      "loss": 0.385,
      "step": 816
    },
    {
      "epoch": 12.014705882352942,
      "grad_norm": 4.007558822631836,
      "learning_rate": 2.4e-05,
      "loss": 0.4005,
      "step": 817
    },
    {
      "epoch": 12.029411764705882,
      "grad_norm": 9.448382377624512,
      "learning_rate": 2.395588235294118e-05,
      "loss": 0.6147,
      "step": 818
    },
    {
      "epoch": 12.044117647058824,
      "grad_norm": 3.511439561843872,
      "learning_rate": 2.3911764705882356e-05,
      "loss": 0.3733,
      "step": 819
    },
    {
      "epoch": 12.058823529411764,
      "grad_norm": 4.657868385314941,
      "learning_rate": 2.3867647058823528e-05,
      "loss": 0.4042,
      "step": 820
    },
    {
      "epoch": 12.058823529411764,
      "eval_accuracy_Block": 0.6634591595596746,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6634591595596746,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.41675230860710144,
      "eval_mean_accuracy": 0.6634591595596746,
      "eval_mean_iou": 0.3317295797798373,
      "eval_overall_accuracy": 0.6634591595596746,
      "eval_runtime": 7.6668,
      "eval_samples_per_second": 17.739,
      "eval_steps_per_second": 2.217,
      "step": 820
    },
    {
      "epoch": 12.073529411764707,
      "grad_norm": 2.197143316268921,
      "learning_rate": 2.3823529411764704e-05,
      "loss": 0.3092,
      "step": 821
    },
    {
      "epoch": 12.088235294117647,
      "grad_norm": 1.8644604682922363,
      "learning_rate": 2.3779411764705883e-05,
      "loss": 0.2715,
      "step": 822
    },
    {
      "epoch": 12.102941176470589,
      "grad_norm": 2.0997557640075684,
      "learning_rate": 2.373529411764706e-05,
      "loss": 0.2511,
      "step": 823
    },
    {
      "epoch": 12.117647058823529,
      "grad_norm": 2.180330514907837,
      "learning_rate": 2.3691176470588235e-05,
      "loss": 0.2406,
      "step": 824
    },
    {
      "epoch": 12.132352941176471,
      "grad_norm": 3.4383087158203125,
      "learning_rate": 2.364705882352941e-05,
      "loss": 0.3033,
      "step": 825
    },
    {
      "epoch": 12.147058823529411,
      "grad_norm": 5.553060054779053,
      "learning_rate": 2.360294117647059e-05,
      "loss": 0.363,
      "step": 826
    },
    {
      "epoch": 12.161764705882353,
      "grad_norm": 2.397717237472534,
      "learning_rate": 2.3558823529411765e-05,
      "loss": 0.2672,
      "step": 827
    },
    {
      "epoch": 12.176470588235293,
      "grad_norm": 1.645395040512085,
      "learning_rate": 2.351470588235294e-05,
      "loss": 0.2323,
      "step": 828
    },
    {
      "epoch": 12.191176470588236,
      "grad_norm": 1.7844812870025635,
      "learning_rate": 2.3470588235294117e-05,
      "loss": 0.3043,
      "step": 829
    },
    {
      "epoch": 12.205882352941176,
      "grad_norm": 2.780580997467041,
      "learning_rate": 2.3426470588235296e-05,
      "loss": 0.2989,
      "step": 830
    },
    {
      "epoch": 12.220588235294118,
      "grad_norm": 1.4697116613388062,
      "learning_rate": 2.3382352941176472e-05,
      "loss": 0.3234,
      "step": 831
    },
    {
      "epoch": 12.235294117647058,
      "grad_norm": 2.3626511096954346,
      "learning_rate": 2.3338235294117648e-05,
      "loss": 0.3054,
      "step": 832
    },
    {
      "epoch": 12.25,
      "grad_norm": 1.6119046211242676,
      "learning_rate": 2.3294117647058824e-05,
      "loss": 0.2359,
      "step": 833
    },
    {
      "epoch": 12.264705882352942,
      "grad_norm": 2.4099314212799072,
      "learning_rate": 2.3250000000000003e-05,
      "loss": 0.2596,
      "step": 834
    },
    {
      "epoch": 12.279411764705882,
      "grad_norm": 1.2050119638442993,
      "learning_rate": 2.320588235294118e-05,
      "loss": 0.2405,
      "step": 835
    },
    {
      "epoch": 12.294117647058824,
      "grad_norm": 3.1632020473480225,
      "learning_rate": 2.3161764705882354e-05,
      "loss": 0.3757,
      "step": 836
    },
    {
      "epoch": 12.308823529411764,
      "grad_norm": 8.626383781433105,
      "learning_rate": 2.311764705882353e-05,
      "loss": 0.5045,
      "step": 837
    },
    {
      "epoch": 12.323529411764707,
      "grad_norm": 2.238410234451294,
      "learning_rate": 2.307352941176471e-05,
      "loss": 0.2958,
      "step": 838
    },
    {
      "epoch": 12.338235294117647,
      "grad_norm": 4.945526599884033,
      "learning_rate": 2.3029411764705885e-05,
      "loss": 0.3255,
      "step": 839
    },
    {
      "epoch": 12.352941176470589,
      "grad_norm": 8.756928443908691,
      "learning_rate": 2.298529411764706e-05,
      "loss": 0.7036,
      "step": 840
    },
    {
      "epoch": 12.352941176470589,
      "eval_accuracy_Block": 0.7656780388019493,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7656780388019493,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.3883034884929657,
      "eval_mean_accuracy": 0.7656780388019493,
      "eval_mean_iou": 0.38283901940097465,
      "eval_overall_accuracy": 0.7656780388019493,
      "eval_runtime": 7.5733,
      "eval_samples_per_second": 17.958,
      "eval_steps_per_second": 2.245,
      "step": 840
    },
    {
      "epoch": 12.367647058823529,
      "grad_norm": 4.799442291259766,
      "learning_rate": 2.2941176470588233e-05,
      "loss": 0.3109,
      "step": 841
    },
    {
      "epoch": 12.382352941176471,
      "grad_norm": 4.5026750564575195,
      "learning_rate": 2.2897058823529412e-05,
      "loss": 0.3947,
      "step": 842
    },
    {
      "epoch": 12.397058823529411,
      "grad_norm": 5.740487098693848,
      "learning_rate": 2.2852941176470588e-05,
      "loss": 0.4478,
      "step": 843
    },
    {
      "epoch": 12.411764705882353,
      "grad_norm": 3.9946560859680176,
      "learning_rate": 2.2808823529411764e-05,
      "loss": 0.2255,
      "step": 844
    },
    {
      "epoch": 12.426470588235293,
      "grad_norm": 2.780017614364624,
      "learning_rate": 2.276470588235294e-05,
      "loss": 0.2106,
      "step": 845
    },
    {
      "epoch": 12.441176470588236,
      "grad_norm": 5.416416645050049,
      "learning_rate": 2.272058823529412e-05,
      "loss": 0.3296,
      "step": 846
    },
    {
      "epoch": 12.455882352941176,
      "grad_norm": 3.6325597763061523,
      "learning_rate": 2.2676470588235295e-05,
      "loss": 0.3057,
      "step": 847
    },
    {
      "epoch": 12.470588235294118,
      "grad_norm": 3.7484190464019775,
      "learning_rate": 2.263235294117647e-05,
      "loss": 0.3944,
      "step": 848
    },
    {
      "epoch": 12.485294117647058,
      "grad_norm": 4.608418941497803,
      "learning_rate": 2.2588235294117646e-05,
      "loss": 0.3802,
      "step": 849
    },
    {
      "epoch": 12.5,
      "grad_norm": 3.0573108196258545,
      "learning_rate": 2.2544117647058826e-05,
      "loss": 0.3756,
      "step": 850
    },
    {
      "epoch": 12.514705882352942,
      "grad_norm": 4.513192176818848,
      "learning_rate": 2.25e-05,
      "loss": 0.4226,
      "step": 851
    },
    {
      "epoch": 12.529411764705882,
      "grad_norm": 3.8680508136749268,
      "learning_rate": 2.2455882352941177e-05,
      "loss": 0.3192,
      "step": 852
    },
    {
      "epoch": 12.544117647058824,
      "grad_norm": 3.1180198192596436,
      "learning_rate": 2.2411764705882353e-05,
      "loss": 0.2646,
      "step": 853
    },
    {
      "epoch": 12.558823529411764,
      "grad_norm": 8.209112167358398,
      "learning_rate": 2.236764705882353e-05,
      "loss": 0.5064,
      "step": 854
    },
    {
      "epoch": 12.573529411764707,
      "grad_norm": 1.4839191436767578,
      "learning_rate": 2.2323529411764708e-05,
      "loss": 0.3119,
      "step": 855
    },
    {
      "epoch": 12.588235294117647,
      "grad_norm": 1.8195860385894775,
      "learning_rate": 2.2279411764705884e-05,
      "loss": 0.2959,
      "step": 856
    },
    {
      "epoch": 12.602941176470589,
      "grad_norm": 3.7261407375335693,
      "learning_rate": 2.223529411764706e-05,
      "loss": 0.2571,
      "step": 857
    },
    {
      "epoch": 12.617647058823529,
      "grad_norm": 5.282172679901123,
      "learning_rate": 2.2191176470588235e-05,
      "loss": 0.4398,
      "step": 858
    },
    {
      "epoch": 12.632352941176471,
      "grad_norm": 3.5949301719665527,
      "learning_rate": 2.2147058823529415e-05,
      "loss": 0.3975,
      "step": 859
    },
    {
      "epoch": 12.647058823529411,
      "grad_norm": 3.3405518531799316,
      "learning_rate": 2.210294117647059e-05,
      "loss": 0.4354,
      "step": 860
    },
    {
      "epoch": 12.647058823529411,
      "eval_accuracy_Block": 0.6764873811986132,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6764873811986132,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.42565178871154785,
      "eval_mean_accuracy": 0.6764873811986132,
      "eval_mean_iou": 0.3382436905993066,
      "eval_overall_accuracy": 0.6764873811986132,
      "eval_runtime": 7.3116,
      "eval_samples_per_second": 18.601,
      "eval_steps_per_second": 2.325,
      "step": 860
    },
    {
      "epoch": 12.661764705882353,
      "grad_norm": 3.5420689582824707,
      "learning_rate": 2.2058823529411766e-05,
      "loss": 0.3023,
      "step": 861
    },
    {
      "epoch": 12.676470588235293,
      "grad_norm": 6.367462158203125,
      "learning_rate": 2.201470588235294e-05,
      "loss": 0.2897,
      "step": 862
    },
    {
      "epoch": 12.691176470588236,
      "grad_norm": 2.018934965133667,
      "learning_rate": 2.1970588235294118e-05,
      "loss": 0.3431,
      "step": 863
    },
    {
      "epoch": 12.705882352941176,
      "grad_norm": 1.1128897666931152,
      "learning_rate": 2.1926470588235294e-05,
      "loss": 0.2533,
      "step": 864
    },
    {
      "epoch": 12.720588235294118,
      "grad_norm": 5.545015811920166,
      "learning_rate": 2.188235294117647e-05,
      "loss": 0.3946,
      "step": 865
    },
    {
      "epoch": 12.735294117647058,
      "grad_norm": 2.5168497562408447,
      "learning_rate": 2.1838235294117645e-05,
      "loss": 0.2524,
      "step": 866
    },
    {
      "epoch": 12.75,
      "grad_norm": 3.40905499458313,
      "learning_rate": 2.1794117647058824e-05,
      "loss": 0.3411,
      "step": 867
    },
    {
      "epoch": 12.764705882352942,
      "grad_norm": 2.4508941173553467,
      "learning_rate": 2.175e-05,
      "loss": 0.3239,
      "step": 868
    },
    {
      "epoch": 12.779411764705882,
      "grad_norm": 2.6269280910491943,
      "learning_rate": 2.1705882352941176e-05,
      "loss": 0.3412,
      "step": 869
    },
    {
      "epoch": 12.794117647058824,
      "grad_norm": 6.1252264976501465,
      "learning_rate": 2.1661764705882352e-05,
      "loss": 0.3379,
      "step": 870
    },
    {
      "epoch": 12.808823529411764,
      "grad_norm": 1.8546316623687744,
      "learning_rate": 2.161764705882353e-05,
      "loss": 0.285,
      "step": 871
    },
    {
      "epoch": 12.823529411764707,
      "grad_norm": 11.361565589904785,
      "learning_rate": 2.1573529411764707e-05,
      "loss": 0.4338,
      "step": 872
    },
    {
      "epoch": 12.838235294117647,
      "grad_norm": 1.2072056531906128,
      "learning_rate": 2.1529411764705882e-05,
      "loss": 0.2003,
      "step": 873
    },
    {
      "epoch": 12.852941176470589,
      "grad_norm": 2.4492170810699463,
      "learning_rate": 2.1485294117647058e-05,
      "loss": 0.2695,
      "step": 874
    },
    {
      "epoch": 12.867647058823529,
      "grad_norm": 7.048218727111816,
      "learning_rate": 2.1441176470588237e-05,
      "loss": 0.6,
      "step": 875
    },
    {
      "epoch": 12.882352941176471,
      "grad_norm": 1.4561256170272827,
      "learning_rate": 2.1397058823529413e-05,
      "loss": 0.2061,
      "step": 876
    },
    {
      "epoch": 12.897058823529411,
      "grad_norm": 2.740661859512329,
      "learning_rate": 2.135294117647059e-05,
      "loss": 0.2839,
      "step": 877
    },
    {
      "epoch": 12.911764705882353,
      "grad_norm": 5.987096309661865,
      "learning_rate": 2.1308823529411765e-05,
      "loss": 0.3243,
      "step": 878
    },
    {
      "epoch": 12.926470588235293,
      "grad_norm": 9.38204288482666,
      "learning_rate": 2.1264705882352944e-05,
      "loss": 0.5248,
      "step": 879
    },
    {
      "epoch": 12.941176470588236,
      "grad_norm": 4.337345600128174,
      "learning_rate": 2.122058823529412e-05,
      "loss": 0.3368,
      "step": 880
    },
    {
      "epoch": 12.941176470588236,
      "eval_accuracy_Block": 0.6932507035898486,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6932507035898486,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.3951030969619751,
      "eval_mean_accuracy": 0.6932507035898486,
      "eval_mean_iou": 0.3466253517949243,
      "eval_overall_accuracy": 0.6932507035898486,
      "eval_runtime": 14.2875,
      "eval_samples_per_second": 9.519,
      "eval_steps_per_second": 1.19,
      "step": 880
    },
    {
      "epoch": 12.955882352941176,
      "grad_norm": 2.79669451713562,
      "learning_rate": 2.1176470588235296e-05,
      "loss": 0.3418,
      "step": 881
    },
    {
      "epoch": 12.970588235294118,
      "grad_norm": 1.8169095516204834,
      "learning_rate": 2.113235294117647e-05,
      "loss": 0.2485,
      "step": 882
    },
    {
      "epoch": 12.985294117647058,
      "grad_norm": 5.496483325958252,
      "learning_rate": 2.1088235294117647e-05,
      "loss": 0.3711,
      "step": 883
    },
    {
      "epoch": 13.0,
      "grad_norm": 2.9532628059387207,
      "learning_rate": 2.1044117647058823e-05,
      "loss": 0.3685,
      "step": 884
    },
    {
      "epoch": 13.014705882352942,
      "grad_norm": 3.39904522895813,
      "learning_rate": 2.1e-05,
      "loss": 0.2507,
      "step": 885
    },
    {
      "epoch": 13.029411764705882,
      "grad_norm": 1.9701470136642456,
      "learning_rate": 2.0955882352941175e-05,
      "loss": 0.2444,
      "step": 886
    },
    {
      "epoch": 13.044117647058824,
      "grad_norm": 2.5466437339782715,
      "learning_rate": 2.0911764705882354e-05,
      "loss": 0.32,
      "step": 887
    },
    {
      "epoch": 13.058823529411764,
      "grad_norm": 1.5075814723968506,
      "learning_rate": 2.086764705882353e-05,
      "loss": 0.1909,
      "step": 888
    },
    {
      "epoch": 13.073529411764707,
      "grad_norm": 6.329107761383057,
      "learning_rate": 2.0823529411764705e-05,
      "loss": 0.375,
      "step": 889
    },
    {
      "epoch": 13.088235294117647,
      "grad_norm": 5.757601737976074,
      "learning_rate": 2.077941176470588e-05,
      "loss": 0.2995,
      "step": 890
    },
    {
      "epoch": 13.102941176470589,
      "grad_norm": 1.6072996854782104,
      "learning_rate": 2.073529411764706e-05,
      "loss": 0.278,
      "step": 891
    },
    {
      "epoch": 13.117647058823529,
      "grad_norm": 2.772881507873535,
      "learning_rate": 2.0691176470588236e-05,
      "loss": 0.3451,
      "step": 892
    },
    {
      "epoch": 13.132352941176471,
      "grad_norm": 7.394339084625244,
      "learning_rate": 2.0647058823529412e-05,
      "loss": 0.4784,
      "step": 893
    },
    {
      "epoch": 13.147058823529411,
      "grad_norm": 13.182812690734863,
      "learning_rate": 2.0602941176470588e-05,
      "loss": 0.5941,
      "step": 894
    },
    {
      "epoch": 13.161764705882353,
      "grad_norm": 1.1143240928649902,
      "learning_rate": 2.0558823529411767e-05,
      "loss": 0.2722,
      "step": 895
    },
    {
      "epoch": 13.176470588235293,
      "grad_norm": 2.810133695602417,
      "learning_rate": 2.0514705882352943e-05,
      "loss": 0.2666,
      "step": 896
    },
    {
      "epoch": 13.191176470588236,
      "grad_norm": 1.3513802289962769,
      "learning_rate": 2.047058823529412e-05,
      "loss": 0.2895,
      "step": 897
    },
    {
      "epoch": 13.205882352941176,
      "grad_norm": 5.693620204925537,
      "learning_rate": 2.0426470588235294e-05,
      "loss": 0.3961,
      "step": 898
    },
    {
      "epoch": 13.220588235294118,
      "grad_norm": 9.147388458251953,
      "learning_rate": 2.0382352941176474e-05,
      "loss": 0.3887,
      "step": 899
    },
    {
      "epoch": 13.235294117647058,
      "grad_norm": 9.64598274230957,
      "learning_rate": 2.033823529411765e-05,
      "loss": 0.514,
      "step": 900
    },
    {
      "epoch": 13.235294117647058,
      "eval_accuracy_Block": 0.7194550215950817,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7194550215950817,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.3889026641845703,
      "eval_mean_accuracy": 0.7194550215950817,
      "eval_mean_iou": 0.35972751079754084,
      "eval_overall_accuracy": 0.7194550215950817,
      "eval_runtime": 7.3391,
      "eval_samples_per_second": 18.531,
      "eval_steps_per_second": 2.316,
      "step": 900
    },
    {
      "epoch": 13.25,
      "grad_norm": 3.3164470195770264,
      "learning_rate": 2.0294117647058825e-05,
      "loss": 0.2871,
      "step": 901
    },
    {
      "epoch": 13.264705882352942,
      "grad_norm": 2.8203563690185547,
      "learning_rate": 2.025e-05,
      "loss": 0.3143,
      "step": 902
    },
    {
      "epoch": 13.279411764705882,
      "grad_norm": 1.614999771118164,
      "learning_rate": 2.020588235294118e-05,
      "loss": 0.2708,
      "step": 903
    },
    {
      "epoch": 13.294117647058824,
      "grad_norm": 6.3696465492248535,
      "learning_rate": 2.0161764705882356e-05,
      "loss": 0.6406,
      "step": 904
    },
    {
      "epoch": 13.308823529411764,
      "grad_norm": 5.344701290130615,
      "learning_rate": 2.011764705882353e-05,
      "loss": 0.33,
      "step": 905
    },
    {
      "epoch": 13.323529411764707,
      "grad_norm": 5.7902116775512695,
      "learning_rate": 2.0073529411764704e-05,
      "loss": 0.4001,
      "step": 906
    },
    {
      "epoch": 13.338235294117647,
      "grad_norm": 1.9836827516555786,
      "learning_rate": 2.0029411764705883e-05,
      "loss": 0.2985,
      "step": 907
    },
    {
      "epoch": 13.352941176470589,
      "grad_norm": 1.8121873140335083,
      "learning_rate": 1.998529411764706e-05,
      "loss": 0.2101,
      "step": 908
    },
    {
      "epoch": 13.367647058823529,
      "grad_norm": 1.3953362703323364,
      "learning_rate": 1.9941176470588235e-05,
      "loss": 0.2366,
      "step": 909
    },
    {
      "epoch": 13.382352941176471,
      "grad_norm": 7.1492838859558105,
      "learning_rate": 1.989705882352941e-05,
      "loss": 0.4107,
      "step": 910
    },
    {
      "epoch": 13.397058823529411,
      "grad_norm": 2.744539737701416,
      "learning_rate": 1.9852941176470586e-05,
      "loss": 0.2931,
      "step": 911
    },
    {
      "epoch": 13.411764705882353,
      "grad_norm": 3.2877211570739746,
      "learning_rate": 1.9808823529411766e-05,
      "loss": 0.3924,
      "step": 912
    },
    {
      "epoch": 13.426470588235293,
      "grad_norm": 2.877521514892578,
      "learning_rate": 1.976470588235294e-05,
      "loss": 0.3756,
      "step": 913
    },
    {
      "epoch": 13.441176470588236,
      "grad_norm": 4.552645206451416,
      "learning_rate": 1.9720588235294117e-05,
      "loss": 0.3609,
      "step": 914
    },
    {
      "epoch": 13.455882352941176,
      "grad_norm": 4.328871250152588,
      "learning_rate": 1.9676470588235293e-05,
      "loss": 0.5125,
      "step": 915
    },
    {
      "epoch": 13.470588235294118,
      "grad_norm": 1.1619632244110107,
      "learning_rate": 1.9632352941176472e-05,
      "loss": 0.2197,
      "step": 916
    },
    {
      "epoch": 13.485294117647058,
      "grad_norm": 1.7626605033874512,
      "learning_rate": 1.9588235294117648e-05,
      "loss": 0.3112,
      "step": 917
    },
    {
      "epoch": 13.5,
      "grad_norm": 3.994223117828369,
      "learning_rate": 1.9544117647058824e-05,
      "loss": 0.3633,
      "step": 918
    },
    {
      "epoch": 13.514705882352942,
      "grad_norm": 8.500009536743164,
      "learning_rate": 1.95e-05,
      "loss": 0.4917,
      "step": 919
    },
    {
      "epoch": 13.529411764705882,
      "grad_norm": 3.4548120498657227,
      "learning_rate": 1.945588235294118e-05,
      "loss": 0.2061,
      "step": 920
    },
    {
      "epoch": 13.529411764705882,
      "eval_accuracy_Block": 0.7207920555882587,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7207920555882587,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.38291481137275696,
      "eval_mean_accuracy": 0.7207920555882587,
      "eval_mean_iou": 0.3603960277941293,
      "eval_overall_accuracy": 0.7207920555882587,
      "eval_runtime": 7.2921,
      "eval_samples_per_second": 18.65,
      "eval_steps_per_second": 2.331,
      "step": 920
    },
    {
      "epoch": 13.544117647058824,
      "grad_norm": 5.786914825439453,
      "learning_rate": 1.9411764705882355e-05,
      "loss": 0.4815,
      "step": 921
    },
    {
      "epoch": 13.558823529411764,
      "grad_norm": 7.738512992858887,
      "learning_rate": 1.936764705882353e-05,
      "loss": 0.6028,
      "step": 922
    },
    {
      "epoch": 13.573529411764707,
      "grad_norm": 7.018991947174072,
      "learning_rate": 1.9323529411764706e-05,
      "loss": 0.3867,
      "step": 923
    },
    {
      "epoch": 13.588235294117647,
      "grad_norm": 3.0259952545166016,
      "learning_rate": 1.9279411764705885e-05,
      "loss": 0.2089,
      "step": 924
    },
    {
      "epoch": 13.602941176470589,
      "grad_norm": 5.965742588043213,
      "learning_rate": 1.923529411764706e-05,
      "loss": 0.4029,
      "step": 925
    },
    {
      "epoch": 13.617647058823529,
      "grad_norm": 1.7218234539031982,
      "learning_rate": 1.9191176470588234e-05,
      "loss": 0.28,
      "step": 926
    },
    {
      "epoch": 13.632352941176471,
      "grad_norm": 1.459977388381958,
      "learning_rate": 1.914705882352941e-05,
      "loss": 0.1797,
      "step": 927
    },
    {
      "epoch": 13.647058823529411,
      "grad_norm": 4.779236793518066,
      "learning_rate": 1.910294117647059e-05,
      "loss": 0.3516,
      "step": 928
    },
    {
      "epoch": 13.661764705882353,
      "grad_norm": 2.7850868701934814,
      "learning_rate": 1.9058823529411764e-05,
      "loss": 0.3048,
      "step": 929
    },
    {
      "epoch": 13.676470588235293,
      "grad_norm": 4.16229772567749,
      "learning_rate": 1.901470588235294e-05,
      "loss": 0.3065,
      "step": 930
    },
    {
      "epoch": 13.691176470588236,
      "grad_norm": 2.6764347553253174,
      "learning_rate": 1.8970588235294116e-05,
      "loss": 0.3357,
      "step": 931
    },
    {
      "epoch": 13.705882352941176,
      "grad_norm": 6.2648725509643555,
      "learning_rate": 1.8926470588235295e-05,
      "loss": 0.4822,
      "step": 932
    },
    {
      "epoch": 13.720588235294118,
      "grad_norm": 6.128439903259277,
      "learning_rate": 1.888235294117647e-05,
      "loss": 0.4678,
      "step": 933
    },
    {
      "epoch": 13.735294117647058,
      "grad_norm": 7.352466583251953,
      "learning_rate": 1.8838235294117647e-05,
      "loss": 0.4635,
      "step": 934
    },
    {
      "epoch": 13.75,
      "grad_norm": 4.094783306121826,
      "learning_rate": 1.8794117647058823e-05,
      "loss": 0.3535,
      "step": 935
    },
    {
      "epoch": 13.764705882352942,
      "grad_norm": 3.1906960010528564,
      "learning_rate": 1.8750000000000002e-05,
      "loss": 0.3845,
      "step": 936
    },
    {
      "epoch": 13.779411764705882,
      "grad_norm": 2.0471341609954834,
      "learning_rate": 1.8705882352941178e-05,
      "loss": 0.3154,
      "step": 937
    },
    {
      "epoch": 13.794117647058824,
      "grad_norm": 5.959534168243408,
      "learning_rate": 1.8661764705882353e-05,
      "loss": 0.4577,
      "step": 938
    },
    {
      "epoch": 13.808823529411764,
      "grad_norm": 6.002290725708008,
      "learning_rate": 1.861764705882353e-05,
      "loss": 0.2592,
      "step": 939
    },
    {
      "epoch": 13.823529411764707,
      "grad_norm": 3.3519904613494873,
      "learning_rate": 1.857352941176471e-05,
      "loss": 0.3523,
      "step": 940
    },
    {
      "epoch": 13.823529411764707,
      "eval_accuracy_Block": 0.6980160298732228,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6980160298732228,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.39138540625572205,
      "eval_mean_accuracy": 0.6980160298732228,
      "eval_mean_iou": 0.3490080149366114,
      "eval_overall_accuracy": 0.6980160298732228,
      "eval_runtime": 7.8208,
      "eval_samples_per_second": 17.389,
      "eval_steps_per_second": 2.174,
      "step": 940
    },
    {
      "epoch": 13.838235294117647,
      "grad_norm": 4.127691745758057,
      "learning_rate": 1.8529411764705884e-05,
      "loss": 0.3698,
      "step": 941
    },
    {
      "epoch": 13.852941176470589,
      "grad_norm": 1.6414916515350342,
      "learning_rate": 1.848529411764706e-05,
      "loss": 0.2733,
      "step": 942
    },
    {
      "epoch": 13.867647058823529,
      "grad_norm": 5.311347484588623,
      "learning_rate": 1.8441176470588236e-05,
      "loss": 0.5456,
      "step": 943
    },
    {
      "epoch": 13.882352941176471,
      "grad_norm": 1.1928770542144775,
      "learning_rate": 1.8397058823529415e-05,
      "loss": 0.2952,
      "step": 944
    },
    {
      "epoch": 13.897058823529411,
      "grad_norm": 3.5346872806549072,
      "learning_rate": 1.835294117647059e-05,
      "loss": 0.3902,
      "step": 945
    },
    {
      "epoch": 13.911764705882353,
      "grad_norm": 9.64703369140625,
      "learning_rate": 1.8308823529411766e-05,
      "loss": 0.4345,
      "step": 946
    },
    {
      "epoch": 13.926470588235293,
      "grad_norm": 9.613994598388672,
      "learning_rate": 1.826470588235294e-05,
      "loss": 0.4625,
      "step": 947
    },
    {
      "epoch": 13.941176470588236,
      "grad_norm": 5.1879191398620605,
      "learning_rate": 1.8220588235294118e-05,
      "loss": 0.5559,
      "step": 948
    },
    {
      "epoch": 13.955882352941176,
      "grad_norm": 1.7524477243423462,
      "learning_rate": 1.8176470588235294e-05,
      "loss": 0.2756,
      "step": 949
    },
    {
      "epoch": 13.970588235294118,
      "grad_norm": 3.2686846256256104,
      "learning_rate": 1.813235294117647e-05,
      "loss": 0.2945,
      "step": 950
    },
    {
      "epoch": 13.985294117647058,
      "grad_norm": 2.0305800437927246,
      "learning_rate": 1.8088235294117645e-05,
      "loss": 0.295,
      "step": 951
    },
    {
      "epoch": 14.0,
      "grad_norm": 5.249725818634033,
      "learning_rate": 1.8044117647058825e-05,
      "loss": 0.3128,
      "step": 952
    },
    {
      "epoch": 14.014705882352942,
      "grad_norm": 2.2761802673339844,
      "learning_rate": 1.8e-05,
      "loss": 0.3781,
      "step": 953
    },
    {
      "epoch": 14.029411764705882,
      "grad_norm": 3.427618980407715,
      "learning_rate": 1.7955882352941176e-05,
      "loss": 0.2356,
      "step": 954
    },
    {
      "epoch": 14.044117647058824,
      "grad_norm": 5.029932975769043,
      "learning_rate": 1.7911764705882352e-05,
      "loss": 0.4032,
      "step": 955
    },
    {
      "epoch": 14.058823529411764,
      "grad_norm": 4.711363792419434,
      "learning_rate": 1.786764705882353e-05,
      "loss": 0.4029,
      "step": 956
    },
    {
      "epoch": 14.073529411764707,
      "grad_norm": 3.4685540199279785,
      "learning_rate": 1.7823529411764707e-05,
      "loss": 0.3161,
      "step": 957
    },
    {
      "epoch": 14.088235294117647,
      "grad_norm": 4.648894309997559,
      "learning_rate": 1.7779411764705883e-05,
      "loss": 0.3305,
      "step": 958
    },
    {
      "epoch": 14.102941176470589,
      "grad_norm": 2.5024383068084717,
      "learning_rate": 1.773529411764706e-05,
      "loss": 0.3506,
      "step": 959
    },
    {
      "epoch": 14.117647058823529,
      "grad_norm": 4.6559858322143555,
      "learning_rate": 1.7691176470588238e-05,
      "loss": 0.4335,
      "step": 960
    },
    {
      "epoch": 14.117647058823529,
      "eval_accuracy_Block": 0.6716583076369398,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.6716583076369398,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.4128626585006714,
      "eval_mean_accuracy": 0.6716583076369398,
      "eval_mean_iou": 0.3358291538184699,
      "eval_overall_accuracy": 0.6716583076369398,
      "eval_runtime": 11.0408,
      "eval_samples_per_second": 12.318,
      "eval_steps_per_second": 1.54,
      "step": 960
    },
    {
      "epoch": 14.132352941176471,
      "grad_norm": 3.4423110485076904,
      "learning_rate": 1.7647058823529414e-05,
      "loss": 0.4476,
      "step": 961
    },
    {
      "epoch": 14.147058823529411,
      "grad_norm": 3.781029462814331,
      "learning_rate": 1.760294117647059e-05,
      "loss": 0.308,
      "step": 962
    },
    {
      "epoch": 14.161764705882353,
      "grad_norm": 16.920103073120117,
      "learning_rate": 1.7558823529411765e-05,
      "loss": 0.3941,
      "step": 963
    },
    {
      "epoch": 14.176470588235293,
      "grad_norm": 3.28096604347229,
      "learning_rate": 1.751470588235294e-05,
      "loss": 0.3069,
      "step": 964
    },
    {
      "epoch": 14.191176470588236,
      "grad_norm": 2.7528209686279297,
      "learning_rate": 1.747058823529412e-05,
      "loss": 0.2963,
      "step": 965
    },
    {
      "epoch": 14.205882352941176,
      "grad_norm": 3.3268632888793945,
      "learning_rate": 1.7426470588235296e-05,
      "loss": 0.3384,
      "step": 966
    },
    {
      "epoch": 14.220588235294118,
      "grad_norm": 2.4861035346984863,
      "learning_rate": 1.7382352941176472e-05,
      "loss": 0.305,
      "step": 967
    },
    {
      "epoch": 14.235294117647058,
      "grad_norm": 2.133136510848999,
      "learning_rate": 1.7338235294117644e-05,
      "loss": 0.2724,
      "step": 968
    },
    {
      "epoch": 14.25,
      "grad_norm": 1.3993991613388062,
      "learning_rate": 1.7294117647058823e-05,
      "loss": 0.2039,
      "step": 969
    },
    {
      "epoch": 14.264705882352942,
      "grad_norm": 3.5598621368408203,
      "learning_rate": 1.725e-05,
      "loss": 0.2883,
      "step": 970
    },
    {
      "epoch": 14.279411764705882,
      "grad_norm": 2.512698173522949,
      "learning_rate": 1.7205882352941175e-05,
      "loss": 0.2262,
      "step": 971
    },
    {
      "epoch": 14.294117647058824,
      "grad_norm": 2.944683074951172,
      "learning_rate": 1.716176470588235e-05,
      "loss": 0.2783,
      "step": 972
    },
    {
      "epoch": 14.308823529411764,
      "grad_norm": 5.669200420379639,
      "learning_rate": 1.711764705882353e-05,
      "loss": 0.309,
      "step": 973
    },
    {
      "epoch": 14.323529411764707,
      "grad_norm": 1.5713857412338257,
      "learning_rate": 1.7073529411764706e-05,
      "loss": 0.2698,
      "step": 974
    },
    {
      "epoch": 14.338235294117647,
      "grad_norm": 2.9572534561157227,
      "learning_rate": 1.702941176470588e-05,
      "loss": 0.3094,
      "step": 975
    },
    {
      "epoch": 14.352941176470589,
      "grad_norm": 2.012754440307617,
      "learning_rate": 1.6985294117647057e-05,
      "loss": 0.2687,
      "step": 976
    },
    {
      "epoch": 14.367647058823529,
      "grad_norm": 12.78780746459961,
      "learning_rate": 1.6941176470588237e-05,
      "loss": 0.3964,
      "step": 977
    },
    {
      "epoch": 14.382352941176471,
      "grad_norm": 1.7809367179870605,
      "learning_rate": 1.6897058823529412e-05,
      "loss": 0.2172,
      "step": 978
    },
    {
      "epoch": 14.397058823529411,
      "grad_norm": 7.067376136779785,
      "learning_rate": 1.6852941176470588e-05,
      "loss": 0.3901,
      "step": 979
    },
    {
      "epoch": 14.411764705882353,
      "grad_norm": 1.4907413721084595,
      "learning_rate": 1.6808823529411764e-05,
      "loss": 0.2734,
      "step": 980
    },
    {
      "epoch": 14.411764705882353,
      "eval_accuracy_Block": 0.7342101862305247,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7342101862305247,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.3843681216239929,
      "eval_mean_accuracy": 0.7342101862305247,
      "eval_mean_iou": 0.36710509311526235,
      "eval_overall_accuracy": 0.7342101862305247,
      "eval_runtime": 7.9982,
      "eval_samples_per_second": 17.004,
      "eval_steps_per_second": 2.125,
      "step": 980
    },
    {
      "epoch": 14.426470588235293,
      "grad_norm": 4.481618881225586,
      "learning_rate": 1.6764705882352943e-05,
      "loss": 0.3459,
      "step": 981
    },
    {
      "epoch": 14.441176470588236,
      "grad_norm": 12.209174156188965,
      "learning_rate": 1.672058823529412e-05,
      "loss": 0.4412,
      "step": 982
    },
    {
      "epoch": 14.455882352941176,
      "grad_norm": 3.4366464614868164,
      "learning_rate": 1.6676470588235295e-05,
      "loss": 0.4067,
      "step": 983
    },
    {
      "epoch": 14.470588235294118,
      "grad_norm": 7.873444557189941,
      "learning_rate": 1.663235294117647e-05,
      "loss": 0.452,
      "step": 984
    },
    {
      "epoch": 14.485294117647058,
      "grad_norm": 3.1647651195526123,
      "learning_rate": 1.658823529411765e-05,
      "loss": 0.3168,
      "step": 985
    },
    {
      "epoch": 14.5,
      "grad_norm": 1.8695287704467773,
      "learning_rate": 1.6544117647058825e-05,
      "loss": 0.3563,
      "step": 986
    },
    {
      "epoch": 14.514705882352942,
      "grad_norm": 9.441082954406738,
      "learning_rate": 1.65e-05,
      "loss": 0.5019,
      "step": 987
    },
    {
      "epoch": 14.529411764705882,
      "grad_norm": 5.688622951507568,
      "learning_rate": 1.6455882352941177e-05,
      "loss": 0.2485,
      "step": 988
    },
    {
      "epoch": 14.544117647058824,
      "grad_norm": 1.8898823261260986,
      "learning_rate": 1.6411764705882356e-05,
      "loss": 0.298,
      "step": 989
    },
    {
      "epoch": 14.558823529411764,
      "grad_norm": 2.0125105381011963,
      "learning_rate": 1.636764705882353e-05,
      "loss": 0.2949,
      "step": 990
    },
    {
      "epoch": 14.573529411764707,
      "grad_norm": 3.832315683364868,
      "learning_rate": 1.6323529411764704e-05,
      "loss": 0.2696,
      "step": 991
    },
    {
      "epoch": 14.588235294117647,
      "grad_norm": 9.029705047607422,
      "learning_rate": 1.627941176470588e-05,
      "loss": 0.5435,
      "step": 992
    },
    {
      "epoch": 14.602941176470589,
      "grad_norm": 2.4272408485412598,
      "learning_rate": 1.623529411764706e-05,
      "loss": 0.1964,
      "step": 993
    },
    {
      "epoch": 14.617647058823529,
      "grad_norm": 3.2540695667266846,
      "learning_rate": 1.6191176470588235e-05,
      "loss": 0.2943,
      "step": 994
    },
    {
      "epoch": 14.632352941176471,
      "grad_norm": 3.1384825706481934,
      "learning_rate": 1.614705882352941e-05,
      "loss": 0.265,
      "step": 995
    },
    {
      "epoch": 14.647058823529411,
      "grad_norm": 1.1270328760147095,
      "learning_rate": 1.6102941176470587e-05,
      "loss": 0.2018,
      "step": 996
    },
    {
      "epoch": 14.661764705882353,
      "grad_norm": 4.86646032333374,
      "learning_rate": 1.6058823529411766e-05,
      "loss": 0.4634,
      "step": 997
    },
    {
      "epoch": 14.676470588235293,
      "grad_norm": 1.8194026947021484,
      "learning_rate": 1.6014705882352942e-05,
      "loss": 0.2697,
      "step": 998
    },
    {
      "epoch": 14.691176470588236,
      "grad_norm": 4.332056522369385,
      "learning_rate": 1.5970588235294118e-05,
      "loss": 0.3027,
      "step": 999
    },
    {
      "epoch": 14.705882352941176,
      "grad_norm": 4.563965797424316,
      "learning_rate": 1.5926470588235293e-05,
      "loss": 0.4172,
      "step": 1000
    },
    {
      "epoch": 14.705882352941176,
      "eval_accuracy_Block": 0.7592657103469022,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7592657103469022,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.39061489701271057,
      "eval_mean_accuracy": 0.7592657103469022,
      "eval_mean_iou": 0.3796328551734511,
      "eval_overall_accuracy": 0.7592657103469022,
      "eval_runtime": 7.5277,
      "eval_samples_per_second": 18.066,
      "eval_steps_per_second": 2.258,
      "step": 1000
    },
    {
      "epoch": 14.720588235294118,
      "grad_norm": 5.799431800842285,
      "learning_rate": 1.5882352941176473e-05,
      "loss": 0.4657,
      "step": 1001
    },
    {
      "epoch": 14.735294117647058,
      "grad_norm": 2.13348126411438,
      "learning_rate": 1.583823529411765e-05,
      "loss": 0.3449,
      "step": 1002
    },
    {
      "epoch": 14.75,
      "grad_norm": 1.3639110326766968,
      "learning_rate": 1.5794117647058824e-05,
      "loss": 0.2562,
      "step": 1003
    },
    {
      "epoch": 14.764705882352942,
      "grad_norm": 5.214173793792725,
      "learning_rate": 1.575e-05,
      "loss": 0.3035,
      "step": 1004
    },
    {
      "epoch": 14.779411764705882,
      "grad_norm": 4.024259567260742,
      "learning_rate": 1.570588235294118e-05,
      "loss": 0.2777,
      "step": 1005
    },
    {
      "epoch": 14.794117647058824,
      "grad_norm": 10.577939987182617,
      "learning_rate": 1.5661764705882355e-05,
      "loss": 0.4461,
      "step": 1006
    },
    {
      "epoch": 14.808823529411764,
      "grad_norm": 3.1152100563049316,
      "learning_rate": 1.561764705882353e-05,
      "loss": 0.309,
      "step": 1007
    },
    {
      "epoch": 14.823529411764707,
      "grad_norm": 2.282611608505249,
      "learning_rate": 1.5573529411764707e-05,
      "loss": 0.3174,
      "step": 1008
    },
    {
      "epoch": 14.838235294117647,
      "grad_norm": 4.629593372344971,
      "learning_rate": 1.5529411764705886e-05,
      "loss": 0.4196,
      "step": 1009
    },
    {
      "epoch": 14.852941176470589,
      "grad_norm": 4.023321151733398,
      "learning_rate": 1.548529411764706e-05,
      "loss": 0.2933,
      "step": 1010
    },
    {
      "epoch": 14.867647058823529,
      "grad_norm": 3.8542909622192383,
      "learning_rate": 1.5441176470588234e-05,
      "loss": 0.3003,
      "step": 1011
    },
    {
      "epoch": 14.882352941176471,
      "grad_norm": 2.9858672618865967,
      "learning_rate": 1.539705882352941e-05,
      "loss": 0.2879,
      "step": 1012
    },
    {
      "epoch": 14.897058823529411,
      "grad_norm": 4.906664848327637,
      "learning_rate": 1.535294117647059e-05,
      "loss": 0.4773,
      "step": 1013
    },
    {
      "epoch": 14.911764705882353,
      "grad_norm": 3.7672085762023926,
      "learning_rate": 1.5308823529411765e-05,
      "loss": 0.3934,
      "step": 1014
    },
    {
      "epoch": 14.926470588235293,
      "grad_norm": 6.1526007652282715,
      "learning_rate": 1.526470588235294e-05,
      "loss": 0.3314,
      "step": 1015
    },
    {
      "epoch": 14.941176470588236,
      "grad_norm": 4.232041835784912,
      "learning_rate": 1.5220588235294118e-05,
      "loss": 0.3521,
      "step": 1016
    },
    {
      "epoch": 14.955882352941176,
      "grad_norm": 3.4385287761688232,
      "learning_rate": 1.5176470588235294e-05,
      "loss": 0.3111,
      "step": 1017
    },
    {
      "epoch": 14.970588235294118,
      "grad_norm": 2.2611899375915527,
      "learning_rate": 1.5132352941176471e-05,
      "loss": 0.308,
      "step": 1018
    },
    {
      "epoch": 14.985294117647058,
      "grad_norm": 2.515713691711426,
      "learning_rate": 1.5088235294117647e-05,
      "loss": 0.3358,
      "step": 1019
    },
    {
      "epoch": 15.0,
      "grad_norm": 2.098095417022705,
      "learning_rate": 1.5044117647058825e-05,
      "loss": 0.3484,
      "step": 1020
    },
    {
      "epoch": 15.0,
      "eval_accuracy_Block": 0.7192800522996258,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7192800522996258,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.39943790435791016,
      "eval_mean_accuracy": 0.7192800522996258,
      "eval_mean_iou": 0.3596400261498129,
      "eval_overall_accuracy": 0.7192800522996258,
      "eval_runtime": 7.2331,
      "eval_samples_per_second": 18.803,
      "eval_steps_per_second": 2.35,
      "step": 1020
    },
    {
      "epoch": 15.014705882352942,
      "grad_norm": 3.141206741333008,
      "learning_rate": 1.5e-05,
      "loss": 0.2218,
      "step": 1021
    },
    {
      "epoch": 15.029411764705882,
      "grad_norm": 4.096024990081787,
      "learning_rate": 1.4955882352941176e-05,
      "loss": 0.3437,
      "step": 1022
    },
    {
      "epoch": 15.044117647058824,
      "grad_norm": 1.6842058897018433,
      "learning_rate": 1.4911764705882354e-05,
      "loss": 0.2613,
      "step": 1023
    },
    {
      "epoch": 15.058823529411764,
      "grad_norm": 7.819339752197266,
      "learning_rate": 1.486764705882353e-05,
      "loss": 0.4463,
      "step": 1024
    },
    {
      "epoch": 15.073529411764707,
      "grad_norm": 1.6868184804916382,
      "learning_rate": 1.4823529411764707e-05,
      "loss": 0.2619,
      "step": 1025
    },
    {
      "epoch": 15.088235294117647,
      "grad_norm": 4.977876663208008,
      "learning_rate": 1.4779411764705883e-05,
      "loss": 0.318,
      "step": 1026
    },
    {
      "epoch": 15.102941176470589,
      "grad_norm": 2.488771677017212,
      "learning_rate": 1.4735294117647059e-05,
      "loss": 0.3498,
      "step": 1027
    },
    {
      "epoch": 15.117647058823529,
      "grad_norm": 2.0916860103607178,
      "learning_rate": 1.4691176470588234e-05,
      "loss": 0.2162,
      "step": 1028
    },
    {
      "epoch": 15.132352941176471,
      "grad_norm": 7.054667949676514,
      "learning_rate": 1.4647058823529412e-05,
      "loss": 0.3785,
      "step": 1029
    },
    {
      "epoch": 15.147058823529411,
      "grad_norm": 1.340166449546814,
      "learning_rate": 1.4602941176470588e-05,
      "loss": 0.233,
      "step": 1030
    },
    {
      "epoch": 15.161764705882353,
      "grad_norm": 9.080992698669434,
      "learning_rate": 1.4558823529411765e-05,
      "loss": 0.3572,
      "step": 1031
    },
    {
      "epoch": 15.176470588235293,
      "grad_norm": 1.2424660921096802,
      "learning_rate": 1.4514705882352941e-05,
      "loss": 0.2068,
      "step": 1032
    },
    {
      "epoch": 15.191176470588236,
      "grad_norm": 3.433302640914917,
      "learning_rate": 1.4470588235294118e-05,
      "loss": 0.3328,
      "step": 1033
    },
    {
      "epoch": 15.205882352941176,
      "grad_norm": 2.4073259830474854,
      "learning_rate": 1.4426470588235294e-05,
      "loss": 0.294,
      "step": 1034
    },
    {
      "epoch": 15.220588235294118,
      "grad_norm": 2.12449049949646,
      "learning_rate": 1.4382352941176472e-05,
      "loss": 0.2715,
      "step": 1035
    },
    {
      "epoch": 15.235294117647058,
      "grad_norm": 6.637829780578613,
      "learning_rate": 1.4338235294117647e-05,
      "loss": 0.3808,
      "step": 1036
    },
    {
      "epoch": 15.25,
      "grad_norm": 8.2659273147583,
      "learning_rate": 1.4294117647058823e-05,
      "loss": 0.4928,
      "step": 1037
    },
    {
      "epoch": 15.264705882352942,
      "grad_norm": 4.632386207580566,
      "learning_rate": 1.4249999999999999e-05,
      "loss": 0.3477,
      "step": 1038
    },
    {
      "epoch": 15.279411764705882,
      "grad_norm": 4.293418884277344,
      "learning_rate": 1.4205882352941177e-05,
      "loss": 0.4339,
      "step": 1039
    },
    {
      "epoch": 15.294117647058824,
      "grad_norm": 2.442754030227661,
      "learning_rate": 1.4161764705882352e-05,
      "loss": 0.2519,
      "step": 1040
    },
    {
      "epoch": 15.294117647058824,
      "eval_accuracy_Block": 0.7302873193313661,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7302873193313661,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.4070414900779724,
      "eval_mean_accuracy": 0.7302873193313661,
      "eval_mean_iou": 0.3651436596656831,
      "eval_overall_accuracy": 0.7302873193313661,
      "eval_runtime": 12.1324,
      "eval_samples_per_second": 11.21,
      "eval_steps_per_second": 1.401,
      "step": 1040
    },
    {
      "epoch": 15.308823529411764,
      "grad_norm": 3.311051368713379,
      "learning_rate": 1.411764705882353e-05,
      "loss": 0.2639,
      "step": 1041
    },
    {
      "epoch": 15.323529411764707,
      "grad_norm": 3.7028496265411377,
      "learning_rate": 1.4073529411764706e-05,
      "loss": 0.3235,
      "step": 1042
    },
    {
      "epoch": 15.338235294117647,
      "grad_norm": 2.3021085262298584,
      "learning_rate": 1.4029411764705883e-05,
      "loss": 0.3473,
      "step": 1043
    },
    {
      "epoch": 15.352941176470589,
      "grad_norm": 5.576725959777832,
      "learning_rate": 1.3985294117647059e-05,
      "loss": 0.3305,
      "step": 1044
    },
    {
      "epoch": 15.367647058823529,
      "grad_norm": 2.9985415935516357,
      "learning_rate": 1.3941176470588236e-05,
      "loss": 0.403,
      "step": 1045
    },
    {
      "epoch": 15.382352941176471,
      "grad_norm": 7.663933277130127,
      "learning_rate": 1.3897058823529412e-05,
      "loss": 0.3935,
      "step": 1046
    },
    {
      "epoch": 15.397058823529411,
      "grad_norm": 2.9906086921691895,
      "learning_rate": 1.385294117647059e-05,
      "loss": 0.3443,
      "step": 1047
    },
    {
      "epoch": 15.411764705882353,
      "grad_norm": 1.0533660650253296,
      "learning_rate": 1.3808823529411764e-05,
      "loss": 0.1536,
      "step": 1048
    },
    {
      "epoch": 15.426470588235293,
      "grad_norm": 8.52389907836914,
      "learning_rate": 1.3764705882352941e-05,
      "loss": 0.3903,
      "step": 1049
    },
    {
      "epoch": 15.441176470588236,
      "grad_norm": 5.010533809661865,
      "learning_rate": 1.3720588235294117e-05,
      "loss": 0.2619,
      "step": 1050
    },
    {
      "epoch": 15.455882352941176,
      "grad_norm": 2.84602689743042,
      "learning_rate": 1.3676470588235295e-05,
      "loss": 0.2632,
      "step": 1051
    },
    {
      "epoch": 15.470588235294118,
      "grad_norm": 3.7212631702423096,
      "learning_rate": 1.363235294117647e-05,
      "loss": 0.3551,
      "step": 1052
    },
    {
      "epoch": 15.485294117647058,
      "grad_norm": 5.679340839385986,
      "learning_rate": 1.3588235294117648e-05,
      "loss": 0.4371,
      "step": 1053
    },
    {
      "epoch": 15.5,
      "grad_norm": 1.3461264371871948,
      "learning_rate": 1.3544117647058824e-05,
      "loss": 0.2698,
      "step": 1054
    },
    {
      "epoch": 15.514705882352942,
      "grad_norm": 2.661827802658081,
      "learning_rate": 1.3500000000000001e-05,
      "loss": 0.2559,
      "step": 1055
    },
    {
      "epoch": 15.529411764705882,
      "grad_norm": 2.3977856636047363,
      "learning_rate": 1.3455882352941177e-05,
      "loss": 0.2337,
      "step": 1056
    },
    {
      "epoch": 15.544117647058824,
      "grad_norm": 2.793245553970337,
      "learning_rate": 1.3411764705882354e-05,
      "loss": 0.2995,
      "step": 1057
    },
    {
      "epoch": 15.558823529411764,
      "grad_norm": 5.531558513641357,
      "learning_rate": 1.336764705882353e-05,
      "loss": 0.399,
      "step": 1058
    },
    {
      "epoch": 15.573529411764707,
      "grad_norm": 4.556326866149902,
      "learning_rate": 1.3323529411764706e-05,
      "loss": 0.4486,
      "step": 1059
    },
    {
      "epoch": 15.588235294117647,
      "grad_norm": 3.0740067958831787,
      "learning_rate": 1.3279411764705882e-05,
      "loss": 0.2762,
      "step": 1060
    },
    {
      "epoch": 15.588235294117647,
      "eval_accuracy_Block": 0.7158554726761944,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7158554726761944,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.3985230028629303,
      "eval_mean_accuracy": 0.7158554726761944,
      "eval_mean_iou": 0.3579277363380972,
      "eval_overall_accuracy": 0.7158554726761944,
      "eval_runtime": 7.904,
      "eval_samples_per_second": 17.206,
      "eval_steps_per_second": 2.151,
      "step": 1060
    },
    {
      "epoch": 15.602941176470589,
      "grad_norm": 15.082179069519043,
      "learning_rate": 1.323529411764706e-05,
      "loss": 0.3962,
      "step": 1061
    },
    {
      "epoch": 15.617647058823529,
      "grad_norm": 3.890019655227661,
      "learning_rate": 1.3191176470588235e-05,
      "loss": 0.5579,
      "step": 1062
    },
    {
      "epoch": 15.632352941176471,
      "grad_norm": 3.6443159580230713,
      "learning_rate": 1.3147058823529413e-05,
      "loss": 0.4084,
      "step": 1063
    },
    {
      "epoch": 15.647058823529411,
      "grad_norm": 2.8925890922546387,
      "learning_rate": 1.3102941176470588e-05,
      "loss": 0.254,
      "step": 1064
    },
    {
      "epoch": 15.661764705882353,
      "grad_norm": 3.1786961555480957,
      "learning_rate": 1.3058823529411766e-05,
      "loss": 0.2808,
      "step": 1065
    },
    {
      "epoch": 15.676470588235293,
      "grad_norm": 2.8338372707366943,
      "learning_rate": 1.3014705882352942e-05,
      "loss": 0.2824,
      "step": 1066
    },
    {
      "epoch": 15.691176470588236,
      "grad_norm": 8.721935272216797,
      "learning_rate": 1.297058823529412e-05,
      "loss": 0.382,
      "step": 1067
    },
    {
      "epoch": 15.705882352941176,
      "grad_norm": 1.1886457204818726,
      "learning_rate": 1.2926470588235295e-05,
      "loss": 0.158,
      "step": 1068
    },
    {
      "epoch": 15.720588235294118,
      "grad_norm": 6.428988933563232,
      "learning_rate": 1.288235294117647e-05,
      "loss": 0.3502,
      "step": 1069
    },
    {
      "epoch": 15.735294117647058,
      "grad_norm": 4.074215412139893,
      "learning_rate": 1.2838235294117647e-05,
      "loss": 0.5531,
      "step": 1070
    },
    {
      "epoch": 15.75,
      "grad_norm": 4.4588236808776855,
      "learning_rate": 1.2794117647058824e-05,
      "loss": 0.2149,
      "step": 1071
    },
    {
      "epoch": 15.764705882352942,
      "grad_norm": 4.631253242492676,
      "learning_rate": 1.275e-05,
      "loss": 0.3578,
      "step": 1072
    },
    {
      "epoch": 15.779411764705882,
      "grad_norm": 2.904345750808716,
      "learning_rate": 1.2705882352941177e-05,
      "loss": 0.3098,
      "step": 1073
    },
    {
      "epoch": 15.794117647058824,
      "grad_norm": 15.812152862548828,
      "learning_rate": 1.2661764705882353e-05,
      "loss": 0.5319,
      "step": 1074
    },
    {
      "epoch": 15.808823529411764,
      "grad_norm": 8.624838829040527,
      "learning_rate": 1.261764705882353e-05,
      "loss": 0.5861,
      "step": 1075
    },
    {
      "epoch": 15.823529411764707,
      "grad_norm": 2.6170687675476074,
      "learning_rate": 1.2573529411764706e-05,
      "loss": 0.2968,
      "step": 1076
    },
    {
      "epoch": 15.838235294117647,
      "grad_norm": 4.89028787612915,
      "learning_rate": 1.2529411764705884e-05,
      "loss": 0.2916,
      "step": 1077
    },
    {
      "epoch": 15.852941176470589,
      "grad_norm": 1.3535984754562378,
      "learning_rate": 1.248529411764706e-05,
      "loss": 0.3287,
      "step": 1078
    },
    {
      "epoch": 15.867647058823529,
      "grad_norm": 1.706959843635559,
      "learning_rate": 1.2441176470588236e-05,
      "loss": 0.2108,
      "step": 1079
    },
    {
      "epoch": 15.882352941176471,
      "grad_norm": 15.215846061706543,
      "learning_rate": 1.2397058823529411e-05,
      "loss": 0.5752,
      "step": 1080
    },
    {
      "epoch": 15.882352941176471,
      "eval_accuracy_Block": 0.7355236803365477,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7355236803365477,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.38096383213996887,
      "eval_mean_accuracy": 0.7355236803365477,
      "eval_mean_iou": 0.36776184016827385,
      "eval_overall_accuracy": 0.7355236803365477,
      "eval_runtime": 8.2378,
      "eval_samples_per_second": 16.509,
      "eval_steps_per_second": 2.064,
      "step": 1080
    },
    {
      "epoch": 15.897058823529411,
      "grad_norm": 2.7684524059295654,
      "learning_rate": 1.2352941176470587e-05,
      "loss": 0.3187,
      "step": 1081
    },
    {
      "epoch": 15.911764705882353,
      "grad_norm": 8.781790733337402,
      "learning_rate": 1.2308823529411765e-05,
      "loss": 0.3679,
      "step": 1082
    },
    {
      "epoch": 15.926470588235293,
      "grad_norm": 3.908919334411621,
      "learning_rate": 1.226470588235294e-05,
      "loss": 0.3817,
      "step": 1083
    },
    {
      "epoch": 15.941176470588236,
      "grad_norm": 4.833587169647217,
      "learning_rate": 1.2220588235294118e-05,
      "loss": 0.4421,
      "step": 1084
    },
    {
      "epoch": 15.955882352941176,
      "grad_norm": 3.9825305938720703,
      "learning_rate": 1.2176470588235294e-05,
      "loss": 0.3561,
      "step": 1085
    },
    {
      "epoch": 15.970588235294118,
      "grad_norm": 1.3673577308654785,
      "learning_rate": 1.2132352941176471e-05,
      "loss": 0.2551,
      "step": 1086
    },
    {
      "epoch": 15.985294117647058,
      "grad_norm": 1.2030965089797974,
      "learning_rate": 1.2088235294117647e-05,
      "loss": 0.2204,
      "step": 1087
    },
    {
      "epoch": 16.0,
      "grad_norm": 2.3257253170013428,
      "learning_rate": 1.2044117647058825e-05,
      "loss": 0.3215,
      "step": 1088
    },
    {
      "epoch": 16.014705882352942,
      "grad_norm": 4.4947733879089355,
      "learning_rate": 1.2e-05,
      "loss": 0.3853,
      "step": 1089
    },
    {
      "epoch": 16.029411764705884,
      "grad_norm": 2.1171438694000244,
      "learning_rate": 1.1955882352941178e-05,
      "loss": 0.327,
      "step": 1090
    },
    {
      "epoch": 16.044117647058822,
      "grad_norm": 2.384793996810913,
      "learning_rate": 1.1911764705882352e-05,
      "loss": 0.3062,
      "step": 1091
    },
    {
      "epoch": 16.058823529411764,
      "grad_norm": 2.297388792037964,
      "learning_rate": 1.186764705882353e-05,
      "loss": 0.3187,
      "step": 1092
    },
    {
      "epoch": 16.073529411764707,
      "grad_norm": 9.241503715515137,
      "learning_rate": 1.1823529411764705e-05,
      "loss": 0.4458,
      "step": 1093
    },
    {
      "epoch": 16.08823529411765,
      "grad_norm": 7.620763301849365,
      "learning_rate": 1.1779411764705883e-05,
      "loss": 0.2528,
      "step": 1094
    },
    {
      "epoch": 16.102941176470587,
      "grad_norm": 1.242668628692627,
      "learning_rate": 1.1735294117647058e-05,
      "loss": 0.2739,
      "step": 1095
    },
    {
      "epoch": 16.11764705882353,
      "grad_norm": 2.7394373416900635,
      "learning_rate": 1.1691176470588236e-05,
      "loss": 0.3953,
      "step": 1096
    },
    {
      "epoch": 16.13235294117647,
      "grad_norm": 8.598745346069336,
      "learning_rate": 1.1647058823529412e-05,
      "loss": 0.4218,
      "step": 1097
    },
    {
      "epoch": 16.147058823529413,
      "grad_norm": 4.101280689239502,
      "learning_rate": 1.160294117647059e-05,
      "loss": 0.2749,
      "step": 1098
    },
    {
      "epoch": 16.16176470588235,
      "grad_norm": 7.354691505432129,
      "learning_rate": 1.1558823529411765e-05,
      "loss": 0.461,
      "step": 1099
    },
    {
      "epoch": 16.176470588235293,
      "grad_norm": 1.9099608659744263,
      "learning_rate": 1.1514705882352943e-05,
      "loss": 0.2703,
      "step": 1100
    },
    {
      "epoch": 16.176470588235293,
      "eval_accuracy_Block": 0.733216455423827,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.733216455423827,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.3817281126976013,
      "eval_mean_accuracy": 0.733216455423827,
      "eval_mean_iou": 0.3666082277119135,
      "eval_overall_accuracy": 0.733216455423827,
      "eval_runtime": 8.1916,
      "eval_samples_per_second": 16.602,
      "eval_steps_per_second": 2.075,
      "step": 1100
    },
    {
      "epoch": 16.191176470588236,
      "grad_norm": 4.3755083084106445,
      "learning_rate": 1.1470588235294117e-05,
      "loss": 0.4198,
      "step": 1101
    },
    {
      "epoch": 16.205882352941178,
      "grad_norm": 4.952042102813721,
      "learning_rate": 1.1426470588235294e-05,
      "loss": 0.4288,
      "step": 1102
    },
    {
      "epoch": 16.220588235294116,
      "grad_norm": 4.547564506530762,
      "learning_rate": 1.138235294117647e-05,
      "loss": 0.449,
      "step": 1103
    },
    {
      "epoch": 16.235294117647058,
      "grad_norm": 4.691806316375732,
      "learning_rate": 1.1338235294117647e-05,
      "loss": 0.2988,
      "step": 1104
    },
    {
      "epoch": 16.25,
      "grad_norm": 1.9243124723434448,
      "learning_rate": 1.1294117647058823e-05,
      "loss": 0.3126,
      "step": 1105
    },
    {
      "epoch": 16.264705882352942,
      "grad_norm": 3.1678435802459717,
      "learning_rate": 1.125e-05,
      "loss": 0.3406,
      "step": 1106
    },
    {
      "epoch": 16.279411764705884,
      "grad_norm": 2.2879436016082764,
      "learning_rate": 1.1205882352941177e-05,
      "loss": 0.2609,
      "step": 1107
    },
    {
      "epoch": 16.294117647058822,
      "grad_norm": 4.806405544281006,
      "learning_rate": 1.1161764705882354e-05,
      "loss": 0.342,
      "step": 1108
    },
    {
      "epoch": 16.308823529411764,
      "grad_norm": 11.478001594543457,
      "learning_rate": 1.111764705882353e-05,
      "loss": 0.4532,
      "step": 1109
    },
    {
      "epoch": 16.323529411764707,
      "grad_norm": 3.2404003143310547,
      "learning_rate": 1.1073529411764707e-05,
      "loss": 0.3894,
      "step": 1110
    },
    {
      "epoch": 16.33823529411765,
      "grad_norm": 4.705269813537598,
      "learning_rate": 1.1029411764705883e-05,
      "loss": 0.3104,
      "step": 1111
    },
    {
      "epoch": 16.352941176470587,
      "grad_norm": 1.5396771430969238,
      "learning_rate": 1.0985294117647059e-05,
      "loss": 0.3107,
      "step": 1112
    },
    {
      "epoch": 16.36764705882353,
      "grad_norm": 3.336956739425659,
      "learning_rate": 1.0941176470588235e-05,
      "loss": 0.2737,
      "step": 1113
    },
    {
      "epoch": 16.38235294117647,
      "grad_norm": 3.2775321006774902,
      "learning_rate": 1.0897058823529412e-05,
      "loss": 0.3982,
      "step": 1114
    },
    {
      "epoch": 16.397058823529413,
      "grad_norm": 3.638141393661499,
      "learning_rate": 1.0852941176470588e-05,
      "loss": 0.3187,
      "step": 1115
    },
    {
      "epoch": 16.41176470588235,
      "grad_norm": 3.8974597454071045,
      "learning_rate": 1.0808823529411765e-05,
      "loss": 0.4162,
      "step": 1116
    },
    {
      "epoch": 16.426470588235293,
      "grad_norm": 0.7186762690544128,
      "learning_rate": 1.0764705882352941e-05,
      "loss": 0.2307,
      "step": 1117
    },
    {
      "epoch": 16.441176470588236,
      "grad_norm": 4.439827919006348,
      "learning_rate": 1.0720588235294119e-05,
      "loss": 0.3415,
      "step": 1118
    },
    {
      "epoch": 16.455882352941178,
      "grad_norm": 1.4422309398651123,
      "learning_rate": 1.0676470588235295e-05,
      "loss": 0.2479,
      "step": 1119
    },
    {
      "epoch": 16.470588235294116,
      "grad_norm": 2.704423427581787,
      "learning_rate": 1.0632352941176472e-05,
      "loss": 0.2325,
      "step": 1120
    },
    {
      "epoch": 16.470588235294116,
      "eval_accuracy_Block": 0.7505297264538724,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7505297264538724,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.38788357377052307,
      "eval_mean_accuracy": 0.7505297264538724,
      "eval_mean_iou": 0.3752648632269362,
      "eval_overall_accuracy": 0.7505297264538724,
      "eval_runtime": 16.1511,
      "eval_samples_per_second": 8.42,
      "eval_steps_per_second": 1.053,
      "step": 1120
    },
    {
      "epoch": 16.485294117647058,
      "grad_norm": 8.69204044342041,
      "learning_rate": 1.0588235294117648e-05,
      "loss": 0.3726,
      "step": 1121
    },
    {
      "epoch": 16.5,
      "grad_norm": 3.379373073577881,
      "learning_rate": 1.0544117647058824e-05,
      "loss": 0.4269,
      "step": 1122
    },
    {
      "epoch": 16.514705882352942,
      "grad_norm": 5.937386989593506,
      "learning_rate": 1.05e-05,
      "loss": 0.3472,
      "step": 1123
    },
    {
      "epoch": 16.529411764705884,
      "grad_norm": 13.263855934143066,
      "learning_rate": 1.0455882352941177e-05,
      "loss": 0.4873,
      "step": 1124
    },
    {
      "epoch": 16.544117647058822,
      "grad_norm": 2.713233232498169,
      "learning_rate": 1.0411764705882353e-05,
      "loss": 0.3276,
      "step": 1125
    },
    {
      "epoch": 16.558823529411764,
      "grad_norm": 3.671839952468872,
      "learning_rate": 1.036764705882353e-05,
      "loss": 0.2464,
      "step": 1126
    },
    {
      "epoch": 16.573529411764707,
      "grad_norm": 1.5390812158584595,
      "learning_rate": 1.0323529411764706e-05,
      "loss": 0.2533,
      "step": 1127
    },
    {
      "epoch": 16.58823529411765,
      "grad_norm": 3.290158987045288,
      "learning_rate": 1.0279411764705883e-05,
      "loss": 0.2893,
      "step": 1128
    },
    {
      "epoch": 16.602941176470587,
      "grad_norm": 2.1175005435943604,
      "learning_rate": 1.023529411764706e-05,
      "loss": 0.3651,
      "step": 1129
    },
    {
      "epoch": 16.61764705882353,
      "grad_norm": 5.360672473907471,
      "learning_rate": 1.0191176470588237e-05,
      "loss": 0.3764,
      "step": 1130
    },
    {
      "epoch": 16.63235294117647,
      "grad_norm": 14.48729133605957,
      "learning_rate": 1.0147058823529413e-05,
      "loss": 0.3606,
      "step": 1131
    },
    {
      "epoch": 16.647058823529413,
      "grad_norm": 3.290600299835205,
      "learning_rate": 1.010294117647059e-05,
      "loss": 0.1846,
      "step": 1132
    },
    {
      "epoch": 16.66176470588235,
      "grad_norm": 2.2723207473754883,
      "learning_rate": 1.0058823529411764e-05,
      "loss": 0.3177,
      "step": 1133
    },
    {
      "epoch": 16.676470588235293,
      "grad_norm": 2.5492420196533203,
      "learning_rate": 1.0014705882352942e-05,
      "loss": 0.3411,
      "step": 1134
    },
    {
      "epoch": 16.691176470588236,
      "grad_norm": 2.862948417663574,
      "learning_rate": 9.970588235294117e-06,
      "loss": 0.2517,
      "step": 1135
    },
    {
      "epoch": 16.705882352941178,
      "grad_norm": 2.2041819095611572,
      "learning_rate": 9.926470588235293e-06,
      "loss": 0.1685,
      "step": 1136
    },
    {
      "epoch": 16.720588235294116,
      "grad_norm": 3.7809994220733643,
      "learning_rate": 9.88235294117647e-06,
      "loss": 0.373,
      "step": 1137
    },
    {
      "epoch": 16.735294117647058,
      "grad_norm": 1.8530170917510986,
      "learning_rate": 9.838235294117647e-06,
      "loss": 0.2511,
      "step": 1138
    },
    {
      "epoch": 16.75,
      "grad_norm": 2.8146121501922607,
      "learning_rate": 9.794117647058824e-06,
      "loss": 0.2545,
      "step": 1139
    },
    {
      "epoch": 16.764705882352942,
      "grad_norm": 2.430485486984253,
      "learning_rate": 9.75e-06,
      "loss": 0.2771,
      "step": 1140
    },
    {
      "epoch": 16.764705882352942,
      "eval_accuracy_Block": 0.7389683241590967,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7389683241590967,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.38928845524787903,
      "eval_mean_accuracy": 0.7389683241590967,
      "eval_mean_iou": 0.3694841620795484,
      "eval_overall_accuracy": 0.7389683241590967,
      "eval_runtime": 7.1554,
      "eval_samples_per_second": 19.007,
      "eval_steps_per_second": 2.376,
      "step": 1140
    },
    {
      "epoch": 16.779411764705884,
      "grad_norm": 2.9907901287078857,
      "learning_rate": 9.705882352941177e-06,
      "loss": 0.3335,
      "step": 1141
    },
    {
      "epoch": 16.794117647058822,
      "grad_norm": 1.870598554611206,
      "learning_rate": 9.661764705882353e-06,
      "loss": 0.3387,
      "step": 1142
    },
    {
      "epoch": 16.808823529411764,
      "grad_norm": 2.497805118560791,
      "learning_rate": 9.61764705882353e-06,
      "loss": 0.3524,
      "step": 1143
    },
    {
      "epoch": 16.823529411764707,
      "grad_norm": 3.5971431732177734,
      "learning_rate": 9.573529411764705e-06,
      "loss": 0.3543,
      "step": 1144
    },
    {
      "epoch": 16.83823529411765,
      "grad_norm": 1.8943575620651245,
      "learning_rate": 9.529411764705882e-06,
      "loss": 0.2918,
      "step": 1145
    },
    {
      "epoch": 16.852941176470587,
      "grad_norm": 2.7309117317199707,
      "learning_rate": 9.485294117647058e-06,
      "loss": 0.2265,
      "step": 1146
    },
    {
      "epoch": 16.86764705882353,
      "grad_norm": 2.7823102474212646,
      "learning_rate": 9.441176470588235e-06,
      "loss": 0.3997,
      "step": 1147
    },
    {
      "epoch": 16.88235294117647,
      "grad_norm": 6.959811687469482,
      "learning_rate": 9.397058823529411e-06,
      "loss": 0.5196,
      "step": 1148
    },
    {
      "epoch": 16.897058823529413,
      "grad_norm": 3.330024242401123,
      "learning_rate": 9.352941176470589e-06,
      "loss": 0.3042,
      "step": 1149
    },
    {
      "epoch": 16.91176470588235,
      "grad_norm": 5.077792644500732,
      "learning_rate": 9.308823529411765e-06,
      "loss": 0.2717,
      "step": 1150
    },
    {
      "epoch": 16.926470588235293,
      "grad_norm": 3.486387252807617,
      "learning_rate": 9.264705882352942e-06,
      "loss": 0.3486,
      "step": 1151
    },
    {
      "epoch": 16.941176470588236,
      "grad_norm": 4.226751804351807,
      "learning_rate": 9.220588235294118e-06,
      "loss": 0.357,
      "step": 1152
    },
    {
      "epoch": 16.955882352941178,
      "grad_norm": 7.673964977264404,
      "learning_rate": 9.176470588235295e-06,
      "loss": 0.434,
      "step": 1153
    },
    {
      "epoch": 16.970588235294116,
      "grad_norm": 4.776634216308594,
      "learning_rate": 9.13235294117647e-06,
      "loss": 0.3919,
      "step": 1154
    },
    {
      "epoch": 16.985294117647058,
      "grad_norm": 2.8586134910583496,
      "learning_rate": 9.088235294117647e-06,
      "loss": 0.2396,
      "step": 1155
    },
    {
      "epoch": 17.0,
      "grad_norm": 1.3613561391830444,
      "learning_rate": 9.044117647058823e-06,
      "loss": 0.2509,
      "step": 1156
    },
    {
      "epoch": 17.014705882352942,
      "grad_norm": 1.5527348518371582,
      "learning_rate": 9e-06,
      "loss": 0.2747,
      "step": 1157
    },
    {
      "epoch": 17.029411764705884,
      "grad_norm": 3.6098341941833496,
      "learning_rate": 8.955882352941176e-06,
      "loss": 0.2903,
      "step": 1158
    },
    {
      "epoch": 17.044117647058822,
      "grad_norm": 6.259766578674316,
      "learning_rate": 8.911764705882354e-06,
      "loss": 0.4966,
      "step": 1159
    },
    {
      "epoch": 17.058823529411764,
      "grad_norm": 3.0645220279693604,
      "learning_rate": 8.86764705882353e-06,
      "loss": 0.3712,
      "step": 1160
    },
    {
      "epoch": 17.058823529411764,
      "eval_accuracy_Block": 0.7255068264092888,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7255068264092888,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.3968684673309326,
      "eval_mean_accuracy": 0.7255068264092888,
      "eval_mean_iou": 0.3627534132046444,
      "eval_overall_accuracy": 0.7255068264092888,
      "eval_runtime": 7.2626,
      "eval_samples_per_second": 18.726,
      "eval_steps_per_second": 2.341,
      "step": 1160
    },
    {
      "epoch": 17.073529411764707,
      "grad_norm": 1.7182718515396118,
      "learning_rate": 8.823529411764707e-06,
      "loss": 0.1786,
      "step": 1161
    },
    {
      "epoch": 17.08823529411765,
      "grad_norm": 5.149392127990723,
      "learning_rate": 8.779411764705883e-06,
      "loss": 0.4773,
      "step": 1162
    },
    {
      "epoch": 17.102941176470587,
      "grad_norm": 4.747697353363037,
      "learning_rate": 8.73529411764706e-06,
      "loss": 0.3865,
      "step": 1163
    },
    {
      "epoch": 17.11764705882353,
      "grad_norm": 10.167245864868164,
      "learning_rate": 8.691176470588236e-06,
      "loss": 0.5061,
      "step": 1164
    },
    {
      "epoch": 17.13235294117647,
      "grad_norm": 12.680440902709961,
      "learning_rate": 8.647058823529412e-06,
      "loss": 0.5083,
      "step": 1165
    },
    {
      "epoch": 17.147058823529413,
      "grad_norm": 2.1838862895965576,
      "learning_rate": 8.602941176470587e-06,
      "loss": 0.2063,
      "step": 1166
    },
    {
      "epoch": 17.16176470588235,
      "grad_norm": 2.4856975078582764,
      "learning_rate": 8.558823529411765e-06,
      "loss": 0.2432,
      "step": 1167
    },
    {
      "epoch": 17.176470588235293,
      "grad_norm": 1.5853853225708008,
      "learning_rate": 8.51470588235294e-06,
      "loss": 0.2598,
      "step": 1168
    },
    {
      "epoch": 17.191176470588236,
      "grad_norm": 5.470041751861572,
      "learning_rate": 8.470588235294118e-06,
      "loss": 0.4019,
      "step": 1169
    },
    {
      "epoch": 17.205882352941178,
      "grad_norm": 11.820735931396484,
      "learning_rate": 8.426470588235294e-06,
      "loss": 0.4363,
      "step": 1170
    },
    {
      "epoch": 17.220588235294116,
      "grad_norm": 1.5186094045639038,
      "learning_rate": 8.382352941176472e-06,
      "loss": 0.2276,
      "step": 1171
    },
    {
      "epoch": 17.235294117647058,
      "grad_norm": 2.0211586952209473,
      "learning_rate": 8.338235294117647e-06,
      "loss": 0.2375,
      "step": 1172
    },
    {
      "epoch": 17.25,
      "grad_norm": 3.222235679626465,
      "learning_rate": 8.294117647058825e-06,
      "loss": 0.325,
      "step": 1173
    },
    {
      "epoch": 17.264705882352942,
      "grad_norm": 5.151956558227539,
      "learning_rate": 8.25e-06,
      "loss": 0.3747,
      "step": 1174
    },
    {
      "epoch": 17.279411764705884,
      "grad_norm": 2.1140553951263428,
      "learning_rate": 8.205882352941178e-06,
      "loss": 0.1812,
      "step": 1175
    },
    {
      "epoch": 17.294117647058822,
      "grad_norm": 4.907489776611328,
      "learning_rate": 8.161764705882352e-06,
      "loss": 0.4455,
      "step": 1176
    },
    {
      "epoch": 17.308823529411764,
      "grad_norm": 4.989862442016602,
      "learning_rate": 8.11764705882353e-06,
      "loss": 0.241,
      "step": 1177
    },
    {
      "epoch": 17.323529411764707,
      "grad_norm": 1.4288684129714966,
      "learning_rate": 8.073529411764706e-06,
      "loss": 0.18,
      "step": 1178
    },
    {
      "epoch": 17.33823529411765,
      "grad_norm": 2.779975414276123,
      "learning_rate": 8.029411764705883e-06,
      "loss": 0.349,
      "step": 1179
    },
    {
      "epoch": 17.352941176470587,
      "grad_norm": 2.3567581176757812,
      "learning_rate": 7.985294117647059e-06,
      "loss": 0.2482,
      "step": 1180
    },
    {
      "epoch": 17.352941176470587,
      "eval_accuracy_Block": 0.7202331807506286,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7202331807506286,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.393373966217041,
      "eval_mean_accuracy": 0.7202331807506286,
      "eval_mean_iou": 0.3601165903753143,
      "eval_overall_accuracy": 0.7202331807506286,
      "eval_runtime": 7.1785,
      "eval_samples_per_second": 18.945,
      "eval_steps_per_second": 2.368,
      "step": 1180
    },
    {
      "epoch": 17.36764705882353,
      "grad_norm": 1.2170766592025757,
      "learning_rate": 7.941176470588236e-06,
      "loss": 0.2482,
      "step": 1181
    },
    {
      "epoch": 17.38235294117647,
      "grad_norm": 4.603384494781494,
      "learning_rate": 7.897058823529412e-06,
      "loss": 0.407,
      "step": 1182
    },
    {
      "epoch": 17.397058823529413,
      "grad_norm": 3.278851270675659,
      "learning_rate": 7.85294117647059e-06,
      "loss": 0.2503,
      "step": 1183
    },
    {
      "epoch": 17.41176470588235,
      "grad_norm": 2.9716007709503174,
      "learning_rate": 7.808823529411765e-06,
      "loss": 0.2646,
      "step": 1184
    },
    {
      "epoch": 17.426470588235293,
      "grad_norm": 1.9365530014038086,
      "learning_rate": 7.764705882352943e-06,
      "loss": 0.253,
      "step": 1185
    },
    {
      "epoch": 17.441176470588236,
      "grad_norm": 4.332315921783447,
      "learning_rate": 7.720588235294117e-06,
      "loss": 0.3686,
      "step": 1186
    },
    {
      "epoch": 17.455882352941178,
      "grad_norm": 4.14113712310791,
      "learning_rate": 7.676470588235294e-06,
      "loss": 0.3358,
      "step": 1187
    },
    {
      "epoch": 17.470588235294116,
      "grad_norm": 9.860833168029785,
      "learning_rate": 7.63235294117647e-06,
      "loss": 0.7263,
      "step": 1188
    },
    {
      "epoch": 17.485294117647058,
      "grad_norm": 2.6771962642669678,
      "learning_rate": 7.588235294117647e-06,
      "loss": 0.3664,
      "step": 1189
    },
    {
      "epoch": 17.5,
      "grad_norm": 1.9462090730667114,
      "learning_rate": 7.5441176470588235e-06,
      "loss": 0.2672,
      "step": 1190
    },
    {
      "epoch": 17.514705882352942,
      "grad_norm": 7.7845001220703125,
      "learning_rate": 7.5e-06,
      "loss": 0.4324,
      "step": 1191
    },
    {
      "epoch": 17.529411764705884,
      "grad_norm": 3.4790759086608887,
      "learning_rate": 7.455882352941177e-06,
      "loss": 0.2046,
      "step": 1192
    },
    {
      "epoch": 17.544117647058822,
      "grad_norm": 2.9798362255096436,
      "learning_rate": 7.4117647058823535e-06,
      "loss": 0.3425,
      "step": 1193
    },
    {
      "epoch": 17.558823529411764,
      "grad_norm": 4.742852210998535,
      "learning_rate": 7.367647058823529e-06,
      "loss": 0.2669,
      "step": 1194
    },
    {
      "epoch": 17.573529411764707,
      "grad_norm": 1.5339380502700806,
      "learning_rate": 7.323529411764706e-06,
      "loss": 0.2273,
      "step": 1195
    },
    {
      "epoch": 17.58823529411765,
      "grad_norm": 5.938824653625488,
      "learning_rate": 7.2794117647058826e-06,
      "loss": 0.3799,
      "step": 1196
    },
    {
      "epoch": 17.602941176470587,
      "grad_norm": 4.937719345092773,
      "learning_rate": 7.235294117647059e-06,
      "loss": 0.4314,
      "step": 1197
    },
    {
      "epoch": 17.61764705882353,
      "grad_norm": 10.587943077087402,
      "learning_rate": 7.191176470588236e-06,
      "loss": 0.3889,
      "step": 1198
    },
    {
      "epoch": 17.63235294117647,
      "grad_norm": 2.0188634395599365,
      "learning_rate": 7.147058823529412e-06,
      "loss": 0.2684,
      "step": 1199
    },
    {
      "epoch": 17.647058823529413,
      "grad_norm": 15.162798881530762,
      "learning_rate": 7.102941176470588e-06,
      "loss": 0.5257,
      "step": 1200
    },
    {
      "epoch": 17.647058823529413,
      "eval_accuracy_Block": 0.7287670217871924,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7287670217871924,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.3955579996109009,
      "eval_mean_accuracy": 0.7287670217871924,
      "eval_mean_iou": 0.3643835108935962,
      "eval_overall_accuracy": 0.7287670217871924,
      "eval_runtime": 7.2415,
      "eval_samples_per_second": 18.781,
      "eval_steps_per_second": 2.348,
      "step": 1200
    },
    {
      "epoch": 17.66176470588235,
      "grad_norm": 12.285737991333008,
      "learning_rate": 7.058823529411765e-06,
      "loss": 0.609,
      "step": 1201
    },
    {
      "epoch": 17.676470588235293,
      "grad_norm": 1.7355788946151733,
      "learning_rate": 7.014705882352942e-06,
      "loss": 0.2317,
      "step": 1202
    },
    {
      "epoch": 17.691176470588236,
      "grad_norm": 3.0854785442352295,
      "learning_rate": 6.970588235294118e-06,
      "loss": 0.2576,
      "step": 1203
    },
    {
      "epoch": 17.705882352941178,
      "grad_norm": 5.353426933288574,
      "learning_rate": 6.926470588235295e-06,
      "loss": 0.4243,
      "step": 1204
    },
    {
      "epoch": 17.720588235294116,
      "grad_norm": 1.5382786989212036,
      "learning_rate": 6.882352941176471e-06,
      "loss": 0.2227,
      "step": 1205
    },
    {
      "epoch": 17.735294117647058,
      "grad_norm": 2.3360514640808105,
      "learning_rate": 6.838235294117647e-06,
      "loss": 0.3423,
      "step": 1206
    },
    {
      "epoch": 17.75,
      "grad_norm": 2.520226240158081,
      "learning_rate": 6.794117647058824e-06,
      "loss": 0.2732,
      "step": 1207
    },
    {
      "epoch": 17.764705882352942,
      "grad_norm": 2.280880928039551,
      "learning_rate": 6.750000000000001e-06,
      "loss": 0.3189,
      "step": 1208
    },
    {
      "epoch": 17.779411764705884,
      "grad_norm": 2.9205174446105957,
      "learning_rate": 6.705882352941177e-06,
      "loss": 0.5453,
      "step": 1209
    },
    {
      "epoch": 17.794117647058822,
      "grad_norm": 1.2821725606918335,
      "learning_rate": 6.661764705882353e-06,
      "loss": 0.2989,
      "step": 1210
    },
    {
      "epoch": 17.808823529411764,
      "grad_norm": 3.588947296142578,
      "learning_rate": 6.61764705882353e-06,
      "loss": 0.3791,
      "step": 1211
    },
    {
      "epoch": 17.823529411764707,
      "grad_norm": 8.629546165466309,
      "learning_rate": 6.573529411764706e-06,
      "loss": 0.4252,
      "step": 1212
    },
    {
      "epoch": 17.83823529411765,
      "grad_norm": 6.207159519195557,
      "learning_rate": 6.529411764705883e-06,
      "loss": 0.4352,
      "step": 1213
    },
    {
      "epoch": 17.852941176470587,
      "grad_norm": 9.76968002319336,
      "learning_rate": 6.48529411764706e-06,
      "loss": 0.3371,
      "step": 1214
    },
    {
      "epoch": 17.86764705882353,
      "grad_norm": 3.080216884613037,
      "learning_rate": 6.441176470588235e-06,
      "loss": 0.2642,
      "step": 1215
    },
    {
      "epoch": 17.88235294117647,
      "grad_norm": 3.436915874481201,
      "learning_rate": 6.397058823529412e-06,
      "loss": 0.3394,
      "step": 1216
    },
    {
      "epoch": 17.897058823529413,
      "grad_norm": 1.9639222621917725,
      "learning_rate": 6.352941176470589e-06,
      "loss": 0.2809,
      "step": 1217
    },
    {
      "epoch": 17.91176470588235,
      "grad_norm": 1.7810899019241333,
      "learning_rate": 6.308823529411765e-06,
      "loss": 0.2426,
      "step": 1218
    },
    {
      "epoch": 17.926470588235293,
      "grad_norm": 3.521355390548706,
      "learning_rate": 6.264705882352942e-06,
      "loss": 0.2876,
      "step": 1219
    },
    {
      "epoch": 17.941176470588236,
      "grad_norm": 12.799812316894531,
      "learning_rate": 6.220588235294118e-06,
      "loss": 0.5115,
      "step": 1220
    },
    {
      "epoch": 17.941176470588236,
      "eval_accuracy_Block": 0.7520768815874163,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7520768815874163,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.39148005843162537,
      "eval_mean_accuracy": 0.7520768815874163,
      "eval_mean_iou": 0.37603844079370813,
      "eval_overall_accuracy": 0.7520768815874163,
      "eval_runtime": 7.1513,
      "eval_samples_per_second": 19.018,
      "eval_steps_per_second": 2.377,
      "step": 1220
    },
    {
      "epoch": 17.955882352941178,
      "grad_norm": 1.5060540437698364,
      "learning_rate": 6.176470588235294e-06,
      "loss": 0.23,
      "step": 1221
    },
    {
      "epoch": 17.970588235294116,
      "grad_norm": 1.8501695394515991,
      "learning_rate": 6.13235294117647e-06,
      "loss": 0.2016,
      "step": 1222
    },
    {
      "epoch": 17.985294117647058,
      "grad_norm": 1.5483713150024414,
      "learning_rate": 6.088235294117647e-06,
      "loss": 0.2444,
      "step": 1223
    },
    {
      "epoch": 18.0,
      "grad_norm": 5.7174482345581055,
      "learning_rate": 6.0441176470588235e-06,
      "loss": 0.3527,
      "step": 1224
    },
    {
      "epoch": 18.014705882352942,
      "grad_norm": 4.133686065673828,
      "learning_rate": 6e-06,
      "loss": 0.3678,
      "step": 1225
    },
    {
      "epoch": 18.029411764705884,
      "grad_norm": 7.069424152374268,
      "learning_rate": 5.955882352941176e-06,
      "loss": 0.3481,
      "step": 1226
    },
    {
      "epoch": 18.044117647058822,
      "grad_norm": 6.142938137054443,
      "learning_rate": 5.911764705882353e-06,
      "loss": 0.3153,
      "step": 1227
    },
    {
      "epoch": 18.058823529411764,
      "grad_norm": 4.1753387451171875,
      "learning_rate": 5.867647058823529e-06,
      "loss": 0.4001,
      "step": 1228
    },
    {
      "epoch": 18.073529411764707,
      "grad_norm": 6.031257152557373,
      "learning_rate": 5.823529411764706e-06,
      "loss": 0.3821,
      "step": 1229
    },
    {
      "epoch": 18.08823529411765,
      "grad_norm": 3.360244035720825,
      "learning_rate": 5.7794117647058825e-06,
      "loss": 0.3347,
      "step": 1230
    },
    {
      "epoch": 18.102941176470587,
      "grad_norm": 3.134967088699341,
      "learning_rate": 5.735294117647058e-06,
      "loss": 0.2825,
      "step": 1231
    },
    {
      "epoch": 18.11764705882353,
      "grad_norm": 1.925552487373352,
      "learning_rate": 5.691176470588235e-06,
      "loss": 0.3275,
      "step": 1232
    },
    {
      "epoch": 18.13235294117647,
      "grad_norm": 4.251407623291016,
      "learning_rate": 5.647058823529412e-06,
      "loss": 0.3523,
      "step": 1233
    },
    {
      "epoch": 18.147058823529413,
      "grad_norm": 3.455637216567993,
      "learning_rate": 5.602941176470588e-06,
      "loss": 0.309,
      "step": 1234
    },
    {
      "epoch": 18.16176470588235,
      "grad_norm": 2.157693862915039,
      "learning_rate": 5.558823529411765e-06,
      "loss": 0.3853,
      "step": 1235
    },
    {
      "epoch": 18.176470588235293,
      "grad_norm": 5.2465901374816895,
      "learning_rate": 5.5147058823529415e-06,
      "loss": 0.3768,
      "step": 1236
    },
    {
      "epoch": 18.191176470588236,
      "grad_norm": 3.4777536392211914,
      "learning_rate": 5.470588235294117e-06,
      "loss": 0.2304,
      "step": 1237
    },
    {
      "epoch": 18.205882352941178,
      "grad_norm": 2.3134255409240723,
      "learning_rate": 5.426470588235294e-06,
      "loss": 0.2262,
      "step": 1238
    },
    {
      "epoch": 18.220588235294116,
      "grad_norm": 3.6867332458496094,
      "learning_rate": 5.382352941176471e-06,
      "loss": 0.2625,
      "step": 1239
    },
    {
      "epoch": 18.235294117647058,
      "grad_norm": 7.029942512512207,
      "learning_rate": 5.338235294117647e-06,
      "loss": 0.6478,
      "step": 1240
    },
    {
      "epoch": 18.235294117647058,
      "eval_accuracy_Block": 0.7314963058175751,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7314963058175751,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.3908349573612213,
      "eval_mean_accuracy": 0.7314963058175751,
      "eval_mean_iou": 0.36574815290878754,
      "eval_overall_accuracy": 0.7314963058175751,
      "eval_runtime": 7.5796,
      "eval_samples_per_second": 17.943,
      "eval_steps_per_second": 2.243,
      "step": 1240
    },
    {
      "epoch": 18.25,
      "grad_norm": 2.235841751098633,
      "learning_rate": 5.294117647058824e-06,
      "loss": 0.2673,
      "step": 1241
    },
    {
      "epoch": 18.264705882352942,
      "grad_norm": 2.277468681335449,
      "learning_rate": 5.25e-06,
      "loss": 0.2769,
      "step": 1242
    },
    {
      "epoch": 18.279411764705884,
      "grad_norm": 4.882119655609131,
      "learning_rate": 5.205882352941176e-06,
      "loss": 0.4284,
      "step": 1243
    },
    {
      "epoch": 18.294117647058822,
      "grad_norm": 1.7573878765106201,
      "learning_rate": 5.161764705882353e-06,
      "loss": 0.2664,
      "step": 1244
    },
    {
      "epoch": 18.308823529411764,
      "grad_norm": 5.000166893005371,
      "learning_rate": 5.11764705882353e-06,
      "loss": 0.3037,
      "step": 1245
    },
    {
      "epoch": 18.323529411764707,
      "grad_norm": 6.831956386566162,
      "learning_rate": 5.073529411764706e-06,
      "loss": 0.4896,
      "step": 1246
    },
    {
      "epoch": 18.33823529411765,
      "grad_norm": 10.487800598144531,
      "learning_rate": 5.029411764705882e-06,
      "loss": 0.3844,
      "step": 1247
    },
    {
      "epoch": 18.352941176470587,
      "grad_norm": 2.0524394512176514,
      "learning_rate": 4.985294117647059e-06,
      "loss": 0.3908,
      "step": 1248
    },
    {
      "epoch": 18.36764705882353,
      "grad_norm": 3.661233425140381,
      "learning_rate": 4.941176470588235e-06,
      "loss": 0.2795,
      "step": 1249
    },
    {
      "epoch": 18.38235294117647,
      "grad_norm": 1.493295669555664,
      "learning_rate": 4.897058823529412e-06,
      "loss": 0.1983,
      "step": 1250
    },
    {
      "epoch": 18.397058823529413,
      "grad_norm": 2.5502359867095947,
      "learning_rate": 4.852941176470589e-06,
      "loss": 0.2561,
      "step": 1251
    },
    {
      "epoch": 18.41176470588235,
      "grad_norm": 2.260624885559082,
      "learning_rate": 4.808823529411765e-06,
      "loss": 0.2703,
      "step": 1252
    },
    {
      "epoch": 18.426470588235293,
      "grad_norm": 7.227351188659668,
      "learning_rate": 4.764705882352941e-06,
      "loss": 0.368,
      "step": 1253
    },
    {
      "epoch": 18.441176470588236,
      "grad_norm": 1.8540666103363037,
      "learning_rate": 4.720588235294118e-06,
      "loss": 0.2691,
      "step": 1254
    },
    {
      "epoch": 18.455882352941178,
      "grad_norm": 2.2280664443969727,
      "learning_rate": 4.676470588235294e-06,
      "loss": 0.3088,
      "step": 1255
    },
    {
      "epoch": 18.470588235294116,
      "grad_norm": 3.6607961654663086,
      "learning_rate": 4.632352941176471e-06,
      "loss": 0.2567,
      "step": 1256
    },
    {
      "epoch": 18.485294117647058,
      "grad_norm": 3.1673271656036377,
      "learning_rate": 4.588235294117648e-06,
      "loss": 0.3445,
      "step": 1257
    },
    {
      "epoch": 18.5,
      "grad_norm": 2.6085867881774902,
      "learning_rate": 4.5441176470588235e-06,
      "loss": 0.3206,
      "step": 1258
    },
    {
      "epoch": 18.514705882352942,
      "grad_norm": 1.69126558303833,
      "learning_rate": 4.5e-06,
      "loss": 0.2614,
      "step": 1259
    },
    {
      "epoch": 18.529411764705884,
      "grad_norm": 4.111086845397949,
      "learning_rate": 4.455882352941177e-06,
      "loss": 0.3069,
      "step": 1260
    },
    {
      "epoch": 18.529411764705884,
      "eval_accuracy_Block": 0.723196994730541,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.723196994730541,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.3874683380126953,
      "eval_mean_accuracy": 0.723196994730541,
      "eval_mean_iou": 0.3615984973652705,
      "eval_overall_accuracy": 0.723196994730541,
      "eval_runtime": 7.6415,
      "eval_samples_per_second": 17.797,
      "eval_steps_per_second": 2.225,
      "step": 1260
    },
    {
      "epoch": 18.544117647058822,
      "grad_norm": 3.5817699432373047,
      "learning_rate": 4.411764705882353e-06,
      "loss": 0.4065,
      "step": 1261
    },
    {
      "epoch": 18.558823529411764,
      "grad_norm": 3.7546873092651367,
      "learning_rate": 4.36764705882353e-06,
      "loss": 0.3755,
      "step": 1262
    },
    {
      "epoch": 18.573529411764707,
      "grad_norm": 3.1615383625030518,
      "learning_rate": 4.323529411764706e-06,
      "loss": 0.2841,
      "step": 1263
    },
    {
      "epoch": 18.58823529411765,
      "grad_norm": 5.97607946395874,
      "learning_rate": 4.2794117647058825e-06,
      "loss": 0.2884,
      "step": 1264
    },
    {
      "epoch": 18.602941176470587,
      "grad_norm": 1.355897068977356,
      "learning_rate": 4.235294117647059e-06,
      "loss": 0.2006,
      "step": 1265
    },
    {
      "epoch": 18.61764705882353,
      "grad_norm": 5.531363010406494,
      "learning_rate": 4.191176470588236e-06,
      "loss": 0.3329,
      "step": 1266
    },
    {
      "epoch": 18.63235294117647,
      "grad_norm": 2.146713972091675,
      "learning_rate": 4.147058823529412e-06,
      "loss": 0.195,
      "step": 1267
    },
    {
      "epoch": 18.647058823529413,
      "grad_norm": 1.616208553314209,
      "learning_rate": 4.102941176470589e-06,
      "loss": 0.3466,
      "step": 1268
    },
    {
      "epoch": 18.66176470588235,
      "grad_norm": 2.90224552154541,
      "learning_rate": 4.058823529411765e-06,
      "loss": 0.3202,
      "step": 1269
    },
    {
      "epoch": 18.676470588235293,
      "grad_norm": 3.5277130603790283,
      "learning_rate": 4.0147058823529415e-06,
      "loss": 0.263,
      "step": 1270
    },
    {
      "epoch": 18.691176470588236,
      "grad_norm": 14.238890647888184,
      "learning_rate": 3.970588235294118e-06,
      "loss": 0.5175,
      "step": 1271
    },
    {
      "epoch": 18.705882352941178,
      "grad_norm": 1.8997098207473755,
      "learning_rate": 3.926470588235295e-06,
      "loss": 0.2894,
      "step": 1272
    },
    {
      "epoch": 18.720588235294116,
      "grad_norm": 4.2487030029296875,
      "learning_rate": 3.8823529411764714e-06,
      "loss": 0.3538,
      "step": 1273
    },
    {
      "epoch": 18.735294117647058,
      "grad_norm": 2.045811653137207,
      "learning_rate": 3.838235294117647e-06,
      "loss": 0.3493,
      "step": 1274
    },
    {
      "epoch": 18.75,
      "grad_norm": 11.330219268798828,
      "learning_rate": 3.7941176470588235e-06,
      "loss": 0.4501,
      "step": 1275
    },
    {
      "epoch": 18.764705882352942,
      "grad_norm": 4.825479984283447,
      "learning_rate": 3.75e-06,
      "loss": 0.3134,
      "step": 1276
    },
    {
      "epoch": 18.779411764705884,
      "grad_norm": 5.654344081878662,
      "learning_rate": 3.7058823529411767e-06,
      "loss": 0.2747,
      "step": 1277
    },
    {
      "epoch": 18.794117647058822,
      "grad_norm": 5.207969665527344,
      "learning_rate": 3.661764705882353e-06,
      "loss": 0.4331,
      "step": 1278
    },
    {
      "epoch": 18.808823529411764,
      "grad_norm": 2.3352138996124268,
      "learning_rate": 3.6176470588235296e-06,
      "loss": 0.2392,
      "step": 1279
    },
    {
      "epoch": 18.823529411764707,
      "grad_norm": 3.092306613922119,
      "learning_rate": 3.573529411764706e-06,
      "loss": 0.2753,
      "step": 1280
    },
    {
      "epoch": 18.823529411764707,
      "eval_accuracy_Block": 0.7156857169127928,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7156857169127928,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.38749632239341736,
      "eval_mean_accuracy": 0.7156857169127928,
      "eval_mean_iou": 0.3578428584563964,
      "eval_overall_accuracy": 0.7156857169127928,
      "eval_runtime": 9.2179,
      "eval_samples_per_second": 14.754,
      "eval_steps_per_second": 1.844,
      "step": 1280
    },
    {
      "epoch": 18.83823529411765,
      "grad_norm": 3.2355189323425293,
      "learning_rate": 3.5294117647058825e-06,
      "loss": 0.407,
      "step": 1281
    },
    {
      "epoch": 18.852941176470587,
      "grad_norm": 2.565418004989624,
      "learning_rate": 3.485294117647059e-06,
      "loss": 0.304,
      "step": 1282
    },
    {
      "epoch": 18.86764705882353,
      "grad_norm": 5.218067169189453,
      "learning_rate": 3.4411764705882353e-06,
      "loss": 0.2889,
      "step": 1283
    },
    {
      "epoch": 18.88235294117647,
      "grad_norm": 2.2729134559631348,
      "learning_rate": 3.397058823529412e-06,
      "loss": 0.2842,
      "step": 1284
    },
    {
      "epoch": 18.897058823529413,
      "grad_norm": 2.7195537090301514,
      "learning_rate": 3.3529411764705886e-06,
      "loss": 0.2995,
      "step": 1285
    },
    {
      "epoch": 18.91176470588235,
      "grad_norm": 3.535395622253418,
      "learning_rate": 3.308823529411765e-06,
      "loss": 0.2733,
      "step": 1286
    },
    {
      "epoch": 18.926470588235293,
      "grad_norm": 2.0548176765441895,
      "learning_rate": 3.2647058823529415e-06,
      "loss": 0.2303,
      "step": 1287
    },
    {
      "epoch": 18.941176470588236,
      "grad_norm": 3.879162311553955,
      "learning_rate": 3.2205882352941177e-06,
      "loss": 0.3724,
      "step": 1288
    },
    {
      "epoch": 18.955882352941178,
      "grad_norm": 1.3626614809036255,
      "learning_rate": 3.1764705882352943e-06,
      "loss": 0.1399,
      "step": 1289
    },
    {
      "epoch": 18.970588235294116,
      "grad_norm": 4.901987075805664,
      "learning_rate": 3.132352941176471e-06,
      "loss": 0.3237,
      "step": 1290
    },
    {
      "epoch": 18.985294117647058,
      "grad_norm": 2.216238021850586,
      "learning_rate": 3.088235294117647e-06,
      "loss": 0.3522,
      "step": 1291
    },
    {
      "epoch": 19.0,
      "grad_norm": 2.663891077041626,
      "learning_rate": 3.0441176470588234e-06,
      "loss": 0.2779,
      "step": 1292
    },
    {
      "epoch": 19.014705882352942,
      "grad_norm": 3.701603651046753,
      "learning_rate": 3e-06,
      "loss": 0.4031,
      "step": 1293
    },
    {
      "epoch": 19.029411764705884,
      "grad_norm": 2.5769760608673096,
      "learning_rate": 2.9558823529411763e-06,
      "loss": 0.3124,
      "step": 1294
    },
    {
      "epoch": 19.044117647058822,
      "grad_norm": 2.505765199661255,
      "learning_rate": 2.911764705882353e-06,
      "loss": 0.2909,
      "step": 1295
    },
    {
      "epoch": 19.058823529411764,
      "grad_norm": 2.496469020843506,
      "learning_rate": 2.867647058823529e-06,
      "loss": 0.2269,
      "step": 1296
    },
    {
      "epoch": 19.073529411764707,
      "grad_norm": 3.383185625076294,
      "learning_rate": 2.823529411764706e-06,
      "loss": 0.3606,
      "step": 1297
    },
    {
      "epoch": 19.08823529411765,
      "grad_norm": 5.35085391998291,
      "learning_rate": 2.7794117647058824e-06,
      "loss": 0.506,
      "step": 1298
    },
    {
      "epoch": 19.102941176470587,
      "grad_norm": 3.7399306297302246,
      "learning_rate": 2.7352941176470587e-06,
      "loss": 0.2897,
      "step": 1299
    },
    {
      "epoch": 19.11764705882353,
      "grad_norm": 3.7469124794006348,
      "learning_rate": 2.6911764705882353e-06,
      "loss": 0.3764,
      "step": 1300
    },
    {
      "epoch": 19.11764705882353,
      "eval_accuracy_Block": 0.7274067638785013,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7274067638785013,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.38606536388397217,
      "eval_mean_accuracy": 0.7274067638785013,
      "eval_mean_iou": 0.36370338193925067,
      "eval_overall_accuracy": 0.7274067638785013,
      "eval_runtime": 7.77,
      "eval_samples_per_second": 17.503,
      "eval_steps_per_second": 2.188,
      "step": 1300
    },
    {
      "epoch": 19.13235294117647,
      "grad_norm": 7.217954158782959,
      "learning_rate": 2.647058823529412e-06,
      "loss": 0.2599,
      "step": 1301
    },
    {
      "epoch": 19.147058823529413,
      "grad_norm": 1.1546980142593384,
      "learning_rate": 2.602941176470588e-06,
      "loss": 0.2135,
      "step": 1302
    },
    {
      "epoch": 19.16176470588235,
      "grad_norm": 3.802074432373047,
      "learning_rate": 2.558823529411765e-06,
      "loss": 0.3364,
      "step": 1303
    },
    {
      "epoch": 19.176470588235293,
      "grad_norm": 1.6520755290985107,
      "learning_rate": 2.514705882352941e-06,
      "loss": 0.2787,
      "step": 1304
    },
    {
      "epoch": 19.191176470588236,
      "grad_norm": 2.9437665939331055,
      "learning_rate": 2.4705882352941177e-06,
      "loss": 0.4271,
      "step": 1305
    },
    {
      "epoch": 19.205882352941178,
      "grad_norm": 1.9901810884475708,
      "learning_rate": 2.4264705882352943e-06,
      "loss": 0.2511,
      "step": 1306
    },
    {
      "epoch": 19.220588235294116,
      "grad_norm": 2.931597948074341,
      "learning_rate": 2.3823529411764705e-06,
      "loss": 0.2925,
      "step": 1307
    },
    {
      "epoch": 19.235294117647058,
      "grad_norm": 5.581594467163086,
      "learning_rate": 2.338235294117647e-06,
      "loss": 0.2741,
      "step": 1308
    },
    {
      "epoch": 19.25,
      "grad_norm": 1.9993919134140015,
      "learning_rate": 2.294117647058824e-06,
      "loss": 0.2665,
      "step": 1309
    },
    {
      "epoch": 19.264705882352942,
      "grad_norm": 4.023317337036133,
      "learning_rate": 2.25e-06,
      "loss": 0.3762,
      "step": 1310
    },
    {
      "epoch": 19.279411764705884,
      "grad_norm": 9.451655387878418,
      "learning_rate": 2.2058823529411767e-06,
      "loss": 0.4032,
      "step": 1311
    },
    {
      "epoch": 19.294117647058822,
      "grad_norm": 1.5543383359909058,
      "learning_rate": 2.161764705882353e-06,
      "loss": 0.2355,
      "step": 1312
    },
    {
      "epoch": 19.308823529411764,
      "grad_norm": 4.614034175872803,
      "learning_rate": 2.1176470588235296e-06,
      "loss": 0.2697,
      "step": 1313
    },
    {
      "epoch": 19.323529411764707,
      "grad_norm": 1.9741668701171875,
      "learning_rate": 2.073529411764706e-06,
      "loss": 0.2954,
      "step": 1314
    },
    {
      "epoch": 19.33823529411765,
      "grad_norm": 1.4026235342025757,
      "learning_rate": 2.0294117647058824e-06,
      "loss": 0.1752,
      "step": 1315
    },
    {
      "epoch": 19.352941176470587,
      "grad_norm": 6.551075458526611,
      "learning_rate": 1.985294117647059e-06,
      "loss": 0.3959,
      "step": 1316
    },
    {
      "epoch": 19.36764705882353,
      "grad_norm": 5.232642650604248,
      "learning_rate": 1.9411764705882357e-06,
      "loss": 0.3848,
      "step": 1317
    },
    {
      "epoch": 19.38235294117647,
      "grad_norm": 2.6195132732391357,
      "learning_rate": 1.8970588235294117e-06,
      "loss": 0.3166,
      "step": 1318
    },
    {
      "epoch": 19.397058823529413,
      "grad_norm": 4.697692394256592,
      "learning_rate": 1.8529411764705884e-06,
      "loss": 0.2674,
      "step": 1319
    },
    {
      "epoch": 19.41176470588235,
      "grad_norm": 5.179147243499756,
      "learning_rate": 1.8088235294117648e-06,
      "loss": 0.6012,
      "step": 1320
    },
    {
      "epoch": 19.41176470588235,
      "eval_accuracy_Block": 0.7130565168992692,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7130565168992692,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.3908013701438904,
      "eval_mean_accuracy": 0.7130565168992692,
      "eval_mean_iou": 0.3565282584496346,
      "eval_overall_accuracy": 0.7130565168992692,
      "eval_runtime": 8.3843,
      "eval_samples_per_second": 16.221,
      "eval_steps_per_second": 2.028,
      "step": 1320
    },
    {
      "epoch": 19.426470588235293,
      "grad_norm": 1.4294567108154297,
      "learning_rate": 1.7647058823529412e-06,
      "loss": 0.2646,
      "step": 1321
    },
    {
      "epoch": 19.441176470588236,
      "grad_norm": 2.54256534576416,
      "learning_rate": 1.7205882352941177e-06,
      "loss": 0.1892,
      "step": 1322
    },
    {
      "epoch": 19.455882352941178,
      "grad_norm": 1.7811092138290405,
      "learning_rate": 1.6764705882352943e-06,
      "loss": 0.2817,
      "step": 1323
    },
    {
      "epoch": 19.470588235294116,
      "grad_norm": 3.37136173248291,
      "learning_rate": 1.6323529411764707e-06,
      "loss": 0.3468,
      "step": 1324
    },
    {
      "epoch": 19.485294117647058,
      "grad_norm": 1.2902114391326904,
      "learning_rate": 1.5882352941176472e-06,
      "loss": 0.1923,
      "step": 1325
    },
    {
      "epoch": 19.5,
      "grad_norm": 1.6120328903198242,
      "learning_rate": 1.5441176470588234e-06,
      "loss": 0.1943,
      "step": 1326
    },
    {
      "epoch": 19.514705882352942,
      "grad_norm": 2.0710244178771973,
      "learning_rate": 1.5e-06,
      "loss": 0.2949,
      "step": 1327
    },
    {
      "epoch": 19.529411764705884,
      "grad_norm": 1.599725604057312,
      "learning_rate": 1.4558823529411765e-06,
      "loss": 0.2331,
      "step": 1328
    },
    {
      "epoch": 19.544117647058822,
      "grad_norm": 10.814518928527832,
      "learning_rate": 1.411764705882353e-06,
      "loss": 0.392,
      "step": 1329
    },
    {
      "epoch": 19.558823529411764,
      "grad_norm": 3.0561885833740234,
      "learning_rate": 1.3676470588235293e-06,
      "loss": 0.4214,
      "step": 1330
    },
    {
      "epoch": 19.573529411764707,
      "grad_norm": 4.1591949462890625,
      "learning_rate": 1.323529411764706e-06,
      "loss": 0.2878,
      "step": 1331
    },
    {
      "epoch": 19.58823529411765,
      "grad_norm": 14.313727378845215,
      "learning_rate": 1.2794117647058824e-06,
      "loss": 0.4914,
      "step": 1332
    },
    {
      "epoch": 19.602941176470587,
      "grad_norm": 2.2986600399017334,
      "learning_rate": 1.2352941176470588e-06,
      "loss": 0.3143,
      "step": 1333
    },
    {
      "epoch": 19.61764705882353,
      "grad_norm": 8.585990905761719,
      "learning_rate": 1.1911764705882353e-06,
      "loss": 0.4531,
      "step": 1334
    },
    {
      "epoch": 19.63235294117647,
      "grad_norm": 2.8919572830200195,
      "learning_rate": 1.147058823529412e-06,
      "loss": 0.2914,
      "step": 1335
    },
    {
      "epoch": 19.647058823529413,
      "grad_norm": 3.412015676498413,
      "learning_rate": 1.1029411764705884e-06,
      "loss": 0.3348,
      "step": 1336
    },
    {
      "epoch": 19.66176470588235,
      "grad_norm": 2.395785093307495,
      "learning_rate": 1.0588235294117648e-06,
      "loss": 0.2257,
      "step": 1337
    },
    {
      "epoch": 19.676470588235293,
      "grad_norm": 2.618844509124756,
      "learning_rate": 1.0147058823529412e-06,
      "loss": 0.3112,
      "step": 1338
    },
    {
      "epoch": 19.691176470588236,
      "grad_norm": 11.343180656433105,
      "learning_rate": 9.705882352941179e-07,
      "loss": 0.4373,
      "step": 1339
    },
    {
      "epoch": 19.705882352941178,
      "grad_norm": 10.076000213623047,
      "learning_rate": 9.264705882352942e-07,
      "loss": 0.7445,
      "step": 1340
    },
    {
      "epoch": 19.705882352941178,
      "eval_accuracy_Block": 0.7172778980049866,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7172778980049866,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.3916900157928467,
      "eval_mean_accuracy": 0.7172778980049866,
      "eval_mean_iou": 0.3586389490024933,
      "eval_overall_accuracy": 0.7172778980049866,
      "eval_runtime": 7.9376,
      "eval_samples_per_second": 17.134,
      "eval_steps_per_second": 2.142,
      "step": 1340
    },
    {
      "epoch": 19.720588235294116,
      "grad_norm": 2.76446533203125,
      "learning_rate": 8.823529411764706e-07,
      "loss": 0.289,
      "step": 1341
    },
    {
      "epoch": 19.735294117647058,
      "grad_norm": 3.8096132278442383,
      "learning_rate": 8.382352941176472e-07,
      "loss": 0.365,
      "step": 1342
    },
    {
      "epoch": 19.75,
      "grad_norm": 3.4826791286468506,
      "learning_rate": 7.941176470588236e-07,
      "loss": 0.3296,
      "step": 1343
    },
    {
      "epoch": 19.764705882352942,
      "grad_norm": 3.1175026893615723,
      "learning_rate": 7.5e-07,
      "loss": 0.315,
      "step": 1344
    },
    {
      "epoch": 19.779411764705884,
      "grad_norm": 5.9342522621154785,
      "learning_rate": 7.058823529411765e-07,
      "loss": 0.3783,
      "step": 1345
    },
    {
      "epoch": 19.794117647058822,
      "grad_norm": 2.4634249210357666,
      "learning_rate": 6.61764705882353e-07,
      "loss": 0.3624,
      "step": 1346
    },
    {
      "epoch": 19.808823529411764,
      "grad_norm": 3.0953574180603027,
      "learning_rate": 6.176470588235294e-07,
      "loss": 0.316,
      "step": 1347
    },
    {
      "epoch": 19.823529411764707,
      "grad_norm": 7.2534637451171875,
      "learning_rate": 5.73529411764706e-07,
      "loss": 0.4216,
      "step": 1348
    },
    {
      "epoch": 19.83823529411765,
      "grad_norm": 1.7747427225112915,
      "learning_rate": 5.294117647058824e-07,
      "loss": 0.2062,
      "step": 1349
    },
    {
      "epoch": 19.852941176470587,
      "grad_norm": 3.511174440383911,
      "learning_rate": 4.852941176470589e-07,
      "loss": 0.3739,
      "step": 1350
    },
    {
      "epoch": 19.86764705882353,
      "grad_norm": 2.289268970489502,
      "learning_rate": 4.411764705882353e-07,
      "loss": 0.2706,
      "step": 1351
    },
    {
      "epoch": 19.88235294117647,
      "grad_norm": 5.348330020904541,
      "learning_rate": 3.970588235294118e-07,
      "loss": 0.3137,
      "step": 1352
    },
    {
      "epoch": 19.897058823529413,
      "grad_norm": 3.9420688152313232,
      "learning_rate": 3.529411764705882e-07,
      "loss": 0.3712,
      "step": 1353
    },
    {
      "epoch": 19.91176470588235,
      "grad_norm": 2.92063307762146,
      "learning_rate": 3.088235294117647e-07,
      "loss": 0.3368,
      "step": 1354
    },
    {
      "epoch": 19.926470588235293,
      "grad_norm": 8.793731689453125,
      "learning_rate": 2.647058823529412e-07,
      "loss": 0.3975,
      "step": 1355
    },
    {
      "epoch": 19.941176470588236,
      "grad_norm": 5.300964832305908,
      "learning_rate": 2.2058823529411765e-07,
      "loss": 0.3126,
      "step": 1356
    },
    {
      "epoch": 19.955882352941178,
      "grad_norm": 2.584123134613037,
      "learning_rate": 1.764705882352941e-07,
      "loss": 0.312,
      "step": 1357
    },
    {
      "epoch": 19.970588235294116,
      "grad_norm": 2.4153668880462646,
      "learning_rate": 1.323529411764706e-07,
      "loss": 0.3646,
      "step": 1358
    },
    {
      "epoch": 19.985294117647058,
      "grad_norm": 2.471644878387451,
      "learning_rate": 8.823529411764706e-08,
      "loss": 0.2813,
      "step": 1359
    },
    {
      "epoch": 20.0,
      "grad_norm": 4.131327152252197,
      "learning_rate": 4.411764705882353e-08,
      "loss": 0.302,
      "step": 1360
    },
    {
      "epoch": 20.0,
      "eval_accuracy_Block": 0.7303474329358094,
      "eval_accuracy_unlabeled": NaN,
      "eval_iou_Block": 0.7303474329358094,
      "eval_iou_unlabeled": 0.0,
      "eval_loss": 0.38645705580711365,
      "eval_mean_accuracy": 0.7303474329358094,
      "eval_mean_iou": 0.3651737164679047,
      "eval_overall_accuracy": 0.7303474329358094,
      "eval_runtime": 17.5835,
      "eval_samples_per_second": 7.735,
      "eval_steps_per_second": 0.967,
      "step": 1360
    }
  ],
  "logging_steps": 1,
  "max_steps": 1360,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 20,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.9000303785345024e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
